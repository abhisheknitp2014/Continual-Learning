{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279.35290160430094\n"
     ]
    }
   ],
   "source": [
    "import sys,os,json\n",
    "import collections,math\n",
    "import time,datetime,pytz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "# from textblob import TextBlob\n",
    "# from polyglot.detect import Detector\n",
    "import operator\n",
    "# import PlotUtil\n",
    "from scipy.stats import linregress\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# warnings.filterwarnings(action='once')\n",
    "# import foursq_helper as foursq\n",
    "# from yelp_helper import *\n",
    "\n",
    "############################################\n",
    "########## Plot Style Declaration ##########\n",
    "# Set the style globally\n",
    "# Alternatives include bmh, fivethirtyeight, ggplot,\n",
    "# dark_background, seaborn-deep, etc\n",
    "# plt.style.use('ggplot')\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "plt.rcParams['font.family'] = 'times new roman'\n",
    "# plt.rcParams['font.serif'] = 'Ubuntu'\n",
    "# plt.rcParams['font.monospace'] = 'Ubuntu Mono'\n",
    "plt.rcParams['font.size'] = 15\n",
    "plt.rcParams['axes.labelsize'] = 15\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titlesize'] = 15\n",
    "plt.rcParams['xtick.labelsize'] = 15\n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "plt.rcParams['figure.titlesize'] = 15\n",
    "plt.rcParams['lines.linewidth'] = 3\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "##########################################\n",
    "########## data set declaration ##########\n",
    "path_processed = \"data/processed/\"\n",
    "path_final = \"data/final/\"\n",
    "\n",
    "##################################\n",
    "########## End of Setup ##########\n",
    "\n",
    "##### Geographical Change #####\n",
    "import geopy\n",
    "from geopy import distance as geopy_distance\n",
    "coords_1 = (52.2296756, 21.0122287)\n",
    "coords_2 = (52.406374, 16.9251681)\n",
    "print (geopy.distance.distance(coords_1, coords_2).km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"data/opp_X_train.npy\")\n",
    "X_test = np.load(\"data/opp_X_test.npy\")\n",
    "y_train = np.load(\"data/opp_y_train.npy\")\n",
    "y_test = np.load(\"data/opp_y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from matplotlib import pyplot\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.metrics import fbeta_score\n",
    "from keras import backend as K\n",
    "\n",
    "def auroc(y_true, y_pred):\n",
    "    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDataD2OneClass(class_num, X_train, y_train, X_test, y_test):\n",
    "    X_train = X_train[y_train[:]>0]\n",
    "    y_train = y_train[y_train[:]>0]\n",
    "    y_train = y_train[:] - 1\n",
    "\n",
    "    X_test = X_test[y_test[:]>0]\n",
    "    y_test = y_test[y_test[:]>0]\n",
    "    y_test = y_test[:] - 1\n",
    "\n",
    "    X_train_D1 = X_train[y_train[:]<=8]\n",
    "    X_train_D2 = X_train[y_train[:]>8]\n",
    "\n",
    "    y_train_D1 = y_train[y_train[:]<=8]\n",
    "    y_train_D2 = y_train[y_train[:]>8]\n",
    "\n",
    "    X_test_D1 = X_test[y_test[:]<=8]\n",
    "    X_test_D2 = X_test[y_test[:]>8]\n",
    "\n",
    "    y_test_D1 = y_test[y_test[:]<=8]\n",
    "    y_test_D2 = y_test[y_test[:]>8]\n",
    "    \n",
    "    \n",
    "    return X_train_D1, y_train_D1, X_train_D2, y_train_D2, X_test_D1, y_test_D1, X_test_D2, y_test_D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[y_train[:]>0]\n",
    "y_train = y_train[y_train[:]>0]\n",
    "y_train = y_train[:] - 1\n",
    "\n",
    "X_test = X_test[y_test[:]>0]\n",
    "y_test = y_test[y_test[:]>0]\n",
    "y_test = y_test[:] - 1\n",
    "\n",
    "X_train_D1 = X_train[y_train[:]<=8]\n",
    "X_train_D2 = X_train[y_train[:]>8]\n",
    "\n",
    "y_train_D1 = y_train[y_train[:]<=8]\n",
    "y_train_D2 = y_train[y_train[:]>8]\n",
    "\n",
    "X_test_D1 = X_test[y_test[:]<=8]\n",
    "X_test_D2 = X_test[y_test[:]>8]\n",
    "\n",
    "y_test_D1 = y_test[y_test[:]<=8]\n",
    "y_test_D2 = y_test[y_test[:]>8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_l = {9, 10, 11, 12, 13, 14, 15, 16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:]>8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [True if s in class_l else False for s in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = y_train[:]>8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_D2_ = X_train[[True if s in class_l else False for s in y_train]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_D2 = X_train[y_train[:]>8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7189, 24, 113)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_D2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7189, 24, 113)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_D2_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v1, v2 in zip(a, b):\n",
    "    if v1 != v2:\n",
    "        print(\"not same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_D1 = X_train[y_train[:] is in class_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDataD2OneClass(class_num_D2, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    X_train_D1 = X_train[y_train[:] != class_num_D2]\n",
    "    X_train_D2 = X_train[y_train[:] == class_num_D2]\n",
    "\n",
    "    y_train_D1 = y_train[y_train[:] != class_num_D2]\n",
    "    y_train_D2 = y_train[y_train[:] == class_num_D2]\n",
    "\n",
    "    X_test_D1 = X_test[y_test[:] != class_num_D2]\n",
    "    X_test_D2 = X_test[y_test[:] == class_num_D2]\n",
    "\n",
    "    y_test_D1 = y_test[y_test[:] != class_num_D2]\n",
    "    y_test_D2 = y_test[y_test[:] == class_num_D2]\n",
    "    \n",
    "    return X_train_D1, y_train_D1, X_train_D2, y_train_D2, X_test_D1, y_test_D1, X_test_D2, y_test_D2\n",
    "\n",
    "# [True if s in class_l else False for s in y_train]\n",
    "def makeDataD2HalfClasses(class_dict_D1, class_dict_D2, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    X_train_D1 = X_train[[True if x in class_dict_D1 else False for x in y_train]]\n",
    "    X_train_D2 = X_train[[True if x in class_dict_D2 else False for x in y_train]]\n",
    "\n",
    "    y_train_D1 = y_train[[True if x in class_dict_D1 else False for x in y_train]]\n",
    "    y_train_D2 = y_train[[True if x in class_dict_D2 else False for x in y_train]]\n",
    "\n",
    "    X_test_D1 = X_test[[True if x in class_dict_D1 else False for x in y_test]]\n",
    "    X_test_D2 = X_test[[True if x in class_dict_D2 else False for x in y_test]]\n",
    "\n",
    "    y_test_D1 = y_test[[True if x in class_dict_D1 else False for x in y_test]]\n",
    "    y_test_D2 = y_test[[True if x in class_dict_D2 else False for x in y_test]]\n",
    "    \n",
    "    return X_train_D1, y_train_D1, X_train_D2, y_train_D2, X_test_D1, y_test_D1, X_test_D2, y_test_D2\n",
    "\n",
    "def makeClassDictD1(class_dict_D2, num_classes):\n",
    "    class_list = []\n",
    "    for i in range(num_classes):\n",
    "        if i not in class_dict_D2:\n",
    "            class_list.append(i)\n",
    "    return set(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPrepare(rand, df_l):\n",
    "\ttrain_ratio = 0.9\n",
    "\tX_temp, y_res = df_l[0], df_l[1]\n",
    "\tcut = int(X_temp.shape[0] * train_ratio)\n",
    "    \n",
    "\t#labelencoder_y_1 = LabelEncoder()\n",
    "\t#y_res = labelencoder_y_1.fit_transform(y_res)\n",
    "    \n",
    "\ttrain_y = y_res[:cut]\n",
    "\ttest_y = y_res[cut:]\n",
    "\ttrain_X = X_temp[:cut]\n",
    "\ttest_X = X_temp[cut:]\n",
    "\n",
    "\t# train_X = StandardScaler().fit_transform(train_X)\n",
    "\t# test_X = StandardScaler().fit_transform(test_X)\n",
    "\n",
    "\ttrain_X = np.reshape(train_X, (len(train_X),timesteps,-1) )\n",
    "\ttest_X = np.reshape(test_X, (len(test_X),timesteps,-1) )\n",
    "\n",
    "\treturn train_X, train_y, test_X, test_y\n",
    "\n",
    "def runKerasModels(data_name, num_stack, hidden_layer_size, df_l):\n",
    "\tauc_l = []\n",
    "\thist_acc = []\n",
    "\thist_prec = []\n",
    "\thist_rec = []\n",
    "\thist_f1 = []\n",
    "\tpath_name = 'data/mlresultsV_sanity/'\n",
    "\tfor rand in range(1):\n",
    "\t\tbest_model_name = path_name+data_name+'_'+str(rand)+'_best_model_'+str(timesteps)+'0_'+str(num_stack)+'_'+str(hidden_layer_size)+'.h5'\n",
    "\t\ttrain_X, train_y, test_X, test_y = dataPrepare(rand, df_l)\n",
    "\t\tprint(train_X.shape, train_y.shape)\n",
    "        # X = [input_size, timesteps, data_dim]\n",
    "        # y = [input_size, num_classes]\n",
    "\t\tif num_stack == 1:\n",
    "\t\t\t# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "\t\t\tmodel = Sequential()\n",
    "\t\t\tmodel.add(LSTM(hidden_layer_size,input_shape=(timesteps, data_dim),init='glorot_normal'))  # return a single vector of dimension 32\n",
    "\t\t\tmodel.add(Dropout(0.2))\n",
    "\t\t\tmodel.add(Dense(num_classes, activation='softmax', init='glorot_normal'))\n",
    "\t\telif num_stack == 2:\n",
    "\t\t\tmodel = Sequential()\n",
    "\t\t\tmodel.add(LSTM(hidden_layer_size,return_sequences=True,input_shape=(timesteps, data_dim),init='glorot_normal'))  # returns a sequence of vectors of dimension 32\n",
    "\t\t\tmodel.add(LSTM(hidden_layer_size,init='glorot_normal'))  # return a single vector of dimension 32\n",
    "\t\t\tmodel.add(Dropout(0.2))\n",
    "\t\t\tmodel.add(Dense(num_classes, activation='softmax',init='glorot_normal'))\n",
    "\t\telif num_stack == 4:\n",
    "\t\t\tmodel = Sequential()\n",
    "\t\t\tmodel.add(LSTM(hidden_layer_size,return_sequences=True,input_shape=(timesteps, data_dim),init='glorot_normal'))  # returns a sequence of vectors of dimension 32\n",
    "\t\t\tmodel.add(LSTM(hidden_layer_size,return_sequences=True,init='glorot_normal'))  # returns a sequence of vectors of dimension 32\n",
    "\t\t\tmodel.add(LSTM(hidden_layer_size,return_sequences=True,init='glorot_normal'))  # returns a sequence of vectors of dimension 32\n",
    "\t\t\tmodel.add(LSTM(hidden_layer_size,init='glorot_normal'))  # return a single vector of dimension 32\n",
    "\t\t\tmodel.add(Dropout(0.2))\n",
    "\t\t\tmodel.add(Dense(num_classes, activation='softmax',init='glorot_normal'))\n",
    "\t\telse:\n",
    "\t\t\tprint(\"specify the number of stacks\")\n",
    "\t\t# model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "# \t\tmodel.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=[fbeta])\n",
    "\t\tmodel.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['sparse_categorical_accuracy'])\n",
    "\t\t# simple early stopping\n",
    "\t\tes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=60)\n",
    "\t\tmc = ModelCheckpoint(best_model_name, monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\t\thistory = model.fit(train_X, train_y, validation_data=(test_X, test_y),epochs=10,batch_size=64,verbose=0, callbacks=[es, mc])\n",
    "\t\tsaved_model = load_model(best_model_name)\n",
    "\t\ttest_pred = np.argmax(saved_model.predict(test_X), axis=1)\n",
    "\t\tacc = accuracy_score(test_y, test_pred)\n",
    "\t\tprfs = precision_recall_fscore_support(test_y, test_pred)\n",
    "\t\tprint(\"Epoch \", t, \"acc / prec / recall / f1 / supp : \", acc,\" \", prfs)\n",
    "\t\thist_acc.append(acc)\n",
    "\t\thist_prec.append(prfs[0])\n",
    "\t\thist_rec.append(prfs[1])\n",
    "\t\thist_f1.append(prfs[2])        \n",
    "# \t\tauc_score = roc_auc_score(test_y, saved_model.predict(test_X, verbose=0))\n",
    "# \t\tauc_l.append(auc_score)\n",
    "# \t\tprint('AUC score: %f' %(auc_score))\n",
    "\treturn hist_acc, hist_prec, hist_rec, hist_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = 113 # (# features)\n",
    "num_classes = 17\n",
    "\n",
    "# params\n",
    "timesteps = 24\n",
    "num_stack = 1\n",
    "hidden_layer_size = 128\n",
    "\n",
    "# train_X, train_y, test_X, test_y = dataPrepare(1, [X_train_D1, y_train_D1])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(hidden_layer_size,input_shape=(timesteps, data_dim),init='glorot_normal'))  # return a single vector of dimension 32\n",
    "# model.add(LSTM(hidden_layer_size,return_sequences=True,input_shape=(timesteps, data_dim),init='glorot_normal'))  # returns a sequence of vectors of dimension 32\n",
    "# model.add(LSTM(hidden_layer_size,init='glorot_normal'))  # return a single vector of dimension 32\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax',init='glorot_normal'))\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1657, 24, 113)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_linear = X_train.reshape(-1, timesteps*data_dim)\n",
    "X_test_linear = X_test.reshape(-1, timesteps*data_dim)\n",
    "\n",
    "X_train_D1_linear = X_train_D1.reshape(-1, timesteps*data_dim)\n",
    "X_test_D1_linear = X_test_D1.reshape(-1, timesteps*data_dim)\n",
    "\n",
    "X_train_D2_linear = X_train_D2.reshape(-1, timesteps*data_dim)\n",
    "X_test_D2_linear = X_test_D2.reshape(-1, timesteps*data_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1657, 2712)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_linear.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='tanh', input_shape=(data_dim*timesteps,)))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='tanh'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax',init='glorot_normal'))\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14147 samples, validate on 1657 samples\n",
      "Epoch 1/100\n",
      "14147/14147 [==============================] - 17s 1ms/step - loss: 3.1398 - sparse_categorical_accuracy: 0.2601 - val_loss: 3.4401 - val_sparse_categorical_accuracy: 0.1907\n",
      "Epoch 2/100\n",
      "14147/14147 [==============================] - 10s 728us/step - loss: 2.5858 - sparse_categorical_accuracy: 0.3597 - val_loss: 3.3623 - val_sparse_categorical_accuracy: 0.3241\n",
      "Epoch 3/100\n",
      "14147/14147 [==============================] - 9s 634us/step - loss: 2.3801 - sparse_categorical_accuracy: 0.4170 - val_loss: 2.2367 - val_sparse_categorical_accuracy: 0.2945\n",
      "Epoch 4/100\n",
      "14147/14147 [==============================] - 9s 651us/step - loss: 1.4669 - sparse_categorical_accuracy: 0.4672 - val_loss: 1.8043 - val_sparse_categorical_accuracy: 0.3651\n",
      "Epoch 5/100\n",
      "14147/14147 [==============================] - 11s 775us/step - loss: 1.3273 - sparse_categorical_accuracy: 0.4976 - val_loss: 1.6742 - val_sparse_categorical_accuracy: 0.4448\n",
      "Epoch 6/100\n",
      "14147/14147 [==============================] - 10s 727us/step - loss: 1.2504 - sparse_categorical_accuracy: 0.5073 - val_loss: 1.5948 - val_sparse_categorical_accuracy: 0.4683\n",
      "Epoch 7/100\n",
      "14147/14147 [==============================] - 9s 668us/step - loss: 1.1955 - sparse_categorical_accuracy: 0.5201 - val_loss: 1.5835 - val_sparse_categorical_accuracy: 0.4550\n",
      "Epoch 8/100\n",
      "14147/14147 [==============================] - 9s 652us/step - loss: 1.1245 - sparse_categorical_accuracy: 0.5383 - val_loss: 1.6384 - val_sparse_categorical_accuracy: 0.4062\n",
      "Epoch 9/100\n",
      "14147/14147 [==============================] - 16s 1ms/step - loss: 1.0853 - sparse_categorical_accuracy: 0.5521 - val_loss: 1.6499 - val_sparse_categorical_accuracy: 0.3989\n",
      "Epoch 10/100\n",
      "14147/14147 [==============================] - 10s 697us/step - loss: 1.1023 - sparse_categorical_accuracy: 0.5503 - val_loss: 1.6031 - val_sparse_categorical_accuracy: 0.4436\n",
      "Epoch 11/100\n",
      "14147/14147 [==============================] - 12s 851us/step - loss: 1.0311 - sparse_categorical_accuracy: 0.5683 - val_loss: 1.4943 - val_sparse_categorical_accuracy: 0.4737\n",
      "Epoch 12/100\n",
      "14147/14147 [==============================] - 12s 814us/step - loss: 1.0049 - sparse_categorical_accuracy: 0.5757 - val_loss: 1.5708 - val_sparse_categorical_accuracy: 0.4152\n",
      "Epoch 13/100\n",
      "14147/14147 [==============================] - 11s 799us/step - loss: 0.9888 - sparse_categorical_accuracy: 0.5743 - val_loss: 1.4565 - val_sparse_categorical_accuracy: 0.4719\n",
      "Epoch 14/100\n",
      "14147/14147 [==============================] - 10s 685us/step - loss: 0.9821 - sparse_categorical_accuracy: 0.5791 - val_loss: 1.3877 - val_sparse_categorical_accuracy: 0.4677\n",
      "Epoch 15/100\n",
      "14147/14147 [==============================] - 10s 716us/step - loss: 1.0279 - sparse_categorical_accuracy: 0.5749 - val_loss: 1.3902 - val_sparse_categorical_accuracy: 0.5075\n",
      "Epoch 16/100\n",
      "14147/14147 [==============================] - 9s 632us/step - loss: 0.9760 - sparse_categorical_accuracy: 0.5820 - val_loss: 1.3032 - val_sparse_categorical_accuracy: 0.5184\n",
      "Epoch 17/100\n",
      "14147/14147 [==============================] - 13s 911us/step - loss: 0.9648 - sparse_categorical_accuracy: 0.5834 - val_loss: 1.5402 - val_sparse_categorical_accuracy: 0.3899\n",
      "Epoch 18/100\n",
      "14147/14147 [==============================] - 16s 1ms/step - loss: 1.0811 - sparse_categorical_accuracy: 0.5534 - val_loss: 1.3695 - val_sparse_categorical_accuracy: 0.4725\n",
      "Epoch 19/100\n",
      "14147/14147 [==============================] - 20s 1ms/step - loss: 1.0375 - sparse_categorical_accuracy: 0.5636 - val_loss: 1.5261 - val_sparse_categorical_accuracy: 0.4351\n",
      "Epoch 20/100\n",
      "14147/14147 [==============================] - 12s 839us/step - loss: 1.0452 - sparse_categorical_accuracy: 0.5599 - val_loss: 1.2938 - val_sparse_categorical_accuracy: 0.5148\n",
      "Epoch 21/100\n",
      "14147/14147 [==============================] - 13s 889us/step - loss: 1.0194 - sparse_categorical_accuracy: 0.5674 - val_loss: 1.8442 - val_sparse_categorical_accuracy: 0.3084\n",
      "Epoch 22/100\n",
      "14147/14147 [==============================] - 11s 798us/step - loss: 1.0618 - sparse_categorical_accuracy: 0.5580 - val_loss: 1.4291 - val_sparse_categorical_accuracy: 0.4804\n",
      "Epoch 23/100\n",
      "14147/14147 [==============================] - 11s 794us/step - loss: 1.0135 - sparse_categorical_accuracy: 0.5741 - val_loss: 1.3506 - val_sparse_categorical_accuracy: 0.4906\n",
      "Epoch 24/100\n",
      "14147/14147 [==============================] - 11s 800us/step - loss: 1.0348 - sparse_categorical_accuracy: 0.5551 - val_loss: 1.4167 - val_sparse_categorical_accuracy: 0.4768\n",
      "Epoch 25/100\n",
      "14147/14147 [==============================] - 9s 633us/step - loss: 0.9978 - sparse_categorical_accuracy: 0.5728 - val_loss: 1.3665 - val_sparse_categorical_accuracy: 0.4400\n",
      "Epoch 26/100\n",
      "14147/14147 [==============================] - 10s 712us/step - loss: 1.0093 - sparse_categorical_accuracy: 0.5687 - val_loss: 1.3172 - val_sparse_categorical_accuracy: 0.5033\n",
      "Epoch 27/100\n",
      "14147/14147 [==============================] - 14s 996us/step - loss: 0.9594 - sparse_categorical_accuracy: 0.5863 - val_loss: 1.3204 - val_sparse_categorical_accuracy: 0.5160\n",
      "Epoch 28/100\n",
      "14147/14147 [==============================] - 9s 655us/step - loss: 0.9623 - sparse_categorical_accuracy: 0.5790 - val_loss: 1.2490 - val_sparse_categorical_accuracy: 0.4762\n",
      "Epoch 29/100\n",
      "14147/14147 [==============================] - 15s 1ms/step - loss: 0.9648 - sparse_categorical_accuracy: 0.5819 - val_loss: 1.3922 - val_sparse_categorical_accuracy: 0.4816\n",
      "Epoch 30/100\n",
      "14147/14147 [==============================] - 10s 678us/step - loss: 0.9846 - sparse_categorical_accuracy: 0.5878 - val_loss: 1.3481 - val_sparse_categorical_accuracy: 0.4852\n",
      "Epoch 31/100\n",
      "14147/14147 [==============================] - 9s 611us/step - loss: 0.9912 - sparse_categorical_accuracy: 0.5789 - val_loss: 1.9015 - val_sparse_categorical_accuracy: 0.3742\n",
      "Epoch 32/100\n",
      "14147/14147 [==============================] - 9s 670us/step - loss: 0.9832 - sparse_categorical_accuracy: 0.5772 - val_loss: 1.3161 - val_sparse_categorical_accuracy: 0.4701\n",
      "Epoch 33/100\n",
      "14147/14147 [==============================] - 10s 683us/step - loss: 0.9451 - sparse_categorical_accuracy: 0.5933 - val_loss: 1.6273 - val_sparse_categorical_accuracy: 0.3989\n",
      "Epoch 34/100\n",
      "14147/14147 [==============================] - 9s 626us/step - loss: 0.9441 - sparse_categorical_accuracy: 0.5910 - val_loss: 1.3722 - val_sparse_categorical_accuracy: 0.4599\n",
      "Epoch 35/100\n",
      "14147/14147 [==============================] - 10s 687us/step - loss: 0.9173 - sparse_categorical_accuracy: 0.5968 - val_loss: 1.3419 - val_sparse_categorical_accuracy: 0.5081\n",
      "Epoch 36/100\n",
      "14147/14147 [==============================] - 9s 614us/step - loss: 0.9104 - sparse_categorical_accuracy: 0.6078 - val_loss: 1.4682 - val_sparse_categorical_accuracy: 0.4846\n",
      "Epoch 37/100\n",
      "14147/14147 [==============================] - 10s 733us/step - loss: 0.9241 - sparse_categorical_accuracy: 0.5998 - val_loss: 1.4125 - val_sparse_categorical_accuracy: 0.4568\n",
      "Epoch 38/100\n",
      "14147/14147 [==============================] - 15s 1ms/step - loss: 0.9312 - sparse_categorical_accuracy: 0.5955 - val_loss: 1.3136 - val_sparse_categorical_accuracy: 0.4846\n",
      "Epoch 39/100\n",
      "14147/14147 [==============================] - 13s 884us/step - loss: 0.9124 - sparse_categorical_accuracy: 0.6086 - val_loss: 1.4477 - val_sparse_categorical_accuracy: 0.4695\n",
      "Epoch 40/100\n",
      "14147/14147 [==============================] - 13s 899us/step - loss: 0.8950 - sparse_categorical_accuracy: 0.6094 - val_loss: 1.3806 - val_sparse_categorical_accuracy: 0.4967\n",
      "Epoch 41/100\n",
      "14147/14147 [==============================] - 14s 996us/step - loss: 0.9035 - sparse_categorical_accuracy: 0.6038 - val_loss: 1.2334 - val_sparse_categorical_accuracy: 0.5293\n",
      "Epoch 42/100\n",
      "14147/14147 [==============================] - 16s 1ms/step - loss: 0.9224 - sparse_categorical_accuracy: 0.5993 - val_loss: 1.2390 - val_sparse_categorical_accuracy: 0.5196\n",
      "Epoch 43/100\n",
      "14147/14147 [==============================] - 8s 601us/step - loss: 0.8778 - sparse_categorical_accuracy: 0.6131 - val_loss: 1.2537 - val_sparse_categorical_accuracy: 0.5395\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14147/14147 [==============================] - 8s 563us/step - loss: 0.8811 - sparse_categorical_accuracy: 0.6117 - val_loss: 1.5456 - val_sparse_categorical_accuracy: 0.4412\n",
      "Epoch 45/100\n",
      "14147/14147 [==============================] - 8s 580us/step - loss: 0.9078 - sparse_categorical_accuracy: 0.6096 - val_loss: 1.2954 - val_sparse_categorical_accuracy: 0.4888\n",
      "Epoch 46/100\n",
      "14147/14147 [==============================] - 8s 587us/step - loss: 0.8946 - sparse_categorical_accuracy: 0.6071 - val_loss: 1.3903 - val_sparse_categorical_accuracy: 0.4605\n",
      "Epoch 47/100\n",
      "14147/14147 [==============================] - 8s 582us/step - loss: 0.9311 - sparse_categorical_accuracy: 0.6020 - val_loss: 1.5253 - val_sparse_categorical_accuracy: 0.5027\n",
      "Epoch 48/100\n",
      "14147/14147 [==============================] - 8s 581us/step - loss: 0.8694 - sparse_categorical_accuracy: 0.6186 - val_loss: 1.4715 - val_sparse_categorical_accuracy: 0.4478\n",
      "Epoch 49/100\n",
      "14147/14147 [==============================] - 8s 577us/step - loss: 0.9523 - sparse_categorical_accuracy: 0.5979 - val_loss: 1.5011 - val_sparse_categorical_accuracy: 0.4562\n",
      "Epoch 50/100\n",
      "14147/14147 [==============================] - 11s 781us/step - loss: 0.9096 - sparse_categorical_accuracy: 0.6083 - val_loss: 1.5047 - val_sparse_categorical_accuracy: 0.4412\n",
      "Epoch 51/100\n",
      "14147/14147 [==============================] - 8s 590us/step - loss: 0.9157 - sparse_categorical_accuracy: 0.6020 - val_loss: 1.2756 - val_sparse_categorical_accuracy: 0.5057\n",
      "Epoch 52/100\n",
      "14147/14147 [==============================] - 9s 665us/step - loss: 0.8983 - sparse_categorical_accuracy: 0.6090 - val_loss: 1.2589 - val_sparse_categorical_accuracy: 0.4780\n",
      "Epoch 53/100\n",
      "14147/14147 [==============================] - 11s 742us/step - loss: 0.8556 - sparse_categorical_accuracy: 0.6162 - val_loss: 1.4085 - val_sparse_categorical_accuracy: 0.4822\n",
      "Epoch 54/100\n",
      "14147/14147 [==============================] - 10s 741us/step - loss: 0.9087 - sparse_categorical_accuracy: 0.6064 - val_loss: 1.3092 - val_sparse_categorical_accuracy: 0.4822\n",
      "Epoch 55/100\n",
      "14147/14147 [==============================] - 9s 602us/step - loss: 0.9312 - sparse_categorical_accuracy: 0.6020 - val_loss: 1.2494 - val_sparse_categorical_accuracy: 0.5263\n",
      "Epoch 56/100\n",
      "14147/14147 [==============================] - 10s 728us/step - loss: 0.8689 - sparse_categorical_accuracy: 0.6197 - val_loss: 1.4819 - val_sparse_categorical_accuracy: 0.4713\n",
      "Epoch 57/100\n",
      "14147/14147 [==============================] - 11s 799us/step - loss: 0.8754 - sparse_categorical_accuracy: 0.6074 - val_loss: 1.2470 - val_sparse_categorical_accuracy: 0.5244\n",
      "Epoch 58/100\n",
      "14147/14147 [==============================] - 9s 649us/step - loss: 0.8509 - sparse_categorical_accuracy: 0.6196 - val_loss: 1.4091 - val_sparse_categorical_accuracy: 0.4822\n",
      "Epoch 59/100\n",
      "14147/14147 [==============================] - 9s 615us/step - loss: 0.9069 - sparse_categorical_accuracy: 0.6096 - val_loss: 1.6477 - val_sparse_categorical_accuracy: 0.4393\n",
      "Epoch 60/100\n",
      "14147/14147 [==============================] - 9s 658us/step - loss: 0.8974 - sparse_categorical_accuracy: 0.6062 - val_loss: 1.2941 - val_sparse_categorical_accuracy: 0.5142\n",
      "Epoch 61/100\n",
      "14147/14147 [==============================] - 9s 652us/step - loss: 0.8740 - sparse_categorical_accuracy: 0.6129 - val_loss: 1.1773 - val_sparse_categorical_accuracy: 0.5401\n",
      "Epoch 62/100\n",
      "14147/14147 [==============================] - 15s 1ms/step - loss: 0.9043 - sparse_categorical_accuracy: 0.6112 - val_loss: 1.2782 - val_sparse_categorical_accuracy: 0.5377\n",
      "Epoch 63/100\n",
      "14147/14147 [==============================] - 10s 729us/step - loss: 0.9064 - sparse_categorical_accuracy: 0.6097 - val_loss: 2.3460 - val_sparse_categorical_accuracy: 0.3603\n",
      "Epoch 64/100\n",
      "14147/14147 [==============================] - 13s 915us/step - loss: 1.3706 - sparse_categorical_accuracy: 0.4653 - val_loss: 1.5609 - val_sparse_categorical_accuracy: 0.4182\n",
      "Epoch 65/100\n",
      "14147/14147 [==============================] - 9s 605us/step - loss: 1.3055 - sparse_categorical_accuracy: 0.4773 - val_loss: 1.5932 - val_sparse_categorical_accuracy: 0.3959\n",
      "Epoch 66/100\n",
      "14147/14147 [==============================] - 8s 596us/step - loss: 1.2630 - sparse_categorical_accuracy: 0.4831 - val_loss: 1.5777 - val_sparse_categorical_accuracy: 0.4333\n",
      "Epoch 67/100\n",
      "14147/14147 [==============================] - 8s 573us/step - loss: 1.2585 - sparse_categorical_accuracy: 0.4864 - val_loss: 1.4898 - val_sparse_categorical_accuracy: 0.4943\n",
      "Epoch 68/100\n",
      "14147/14147 [==============================] - 10s 686us/step - loss: 1.2470 - sparse_categorical_accuracy: 0.4903 - val_loss: 1.5788 - val_sparse_categorical_accuracy: 0.4641\n",
      "Epoch 69/100\n",
      "14147/14147 [==============================] - 9s 633us/step - loss: 1.2385 - sparse_categorical_accuracy: 0.4921 - val_loss: 1.5250 - val_sparse_categorical_accuracy: 0.4164\n",
      "Epoch 70/100\n",
      "14147/14147 [==============================] - 8s 587us/step - loss: 1.2102 - sparse_categorical_accuracy: 0.5027 - val_loss: 2.0277 - val_sparse_categorical_accuracy: 0.4285\n",
      "Epoch 71/100\n",
      "14147/14147 [==============================] - 9s 646us/step - loss: 1.6843 - sparse_categorical_accuracy: 0.4057 - val_loss: 1.8613 - val_sparse_categorical_accuracy: 0.3941\n",
      "Epoch 72/100\n",
      "14147/14147 [==============================] - 8s 591us/step - loss: 1.5990 - sparse_categorical_accuracy: 0.4129 - val_loss: 1.8541 - val_sparse_categorical_accuracy: 0.3675\n",
      "Epoch 73/100\n",
      "14147/14147 [==============================] - 8s 560us/step - loss: 1.5834 - sparse_categorical_accuracy: 0.4175 - val_loss: 1.9022 - val_sparse_categorical_accuracy: 0.3036\n",
      "Epoch 74/100\n",
      "14147/14147 [==============================] - 8s 597us/step - loss: 1.5692 - sparse_categorical_accuracy: 0.4174 - val_loss: 2.0812 - val_sparse_categorical_accuracy: 0.2704\n",
      "Epoch 75/100\n",
      "14147/14147 [==============================] - 8s 578us/step - loss: 1.5510 - sparse_categorical_accuracy: 0.4232 - val_loss: 2.0169 - val_sparse_categorical_accuracy: 0.2975\n",
      "Epoch 76/100\n",
      "14147/14147 [==============================] - 8s 594us/step - loss: 1.5477 - sparse_categorical_accuracy: 0.4305 - val_loss: 1.8478 - val_sparse_categorical_accuracy: 0.3814\n",
      "Epoch 77/100\n",
      "14147/14147 [==============================] - 8s 581us/step - loss: 1.5195 - sparse_categorical_accuracy: 0.4349 - val_loss: 1.9300 - val_sparse_categorical_accuracy: 0.3241\n",
      "Epoch 78/100\n",
      "14147/14147 [==============================] - 8s 582us/step - loss: 1.5378 - sparse_categorical_accuracy: 0.4271 - val_loss: 1.9684 - val_sparse_categorical_accuracy: 0.3241\n",
      "Epoch 79/100\n",
      "14147/14147 [==============================] - 8s 571us/step - loss: 1.5125 - sparse_categorical_accuracy: 0.4312 - val_loss: 1.9723 - val_sparse_categorical_accuracy: 0.3096\n",
      "Epoch 80/100\n",
      "14147/14147 [==============================] - 8s 572us/step - loss: 1.5306 - sparse_categorical_accuracy: 0.4374 - val_loss: 1.8502 - val_sparse_categorical_accuracy: 0.3482\n",
      "Epoch 81/100\n",
      "14147/14147 [==============================] - 8s 578us/step - loss: 1.5143 - sparse_categorical_accuracy: 0.4338 - val_loss: 1.9364 - val_sparse_categorical_accuracy: 0.3144\n",
      "Epoch 82/100\n",
      "14147/14147 [==============================] - 9s 634us/step - loss: 1.5037 - sparse_categorical_accuracy: 0.4346 - val_loss: 1.8762 - val_sparse_categorical_accuracy: 0.3530\n",
      "Epoch 83/100\n",
      "14147/14147 [==============================] - 9s 639us/step - loss: 1.4779 - sparse_categorical_accuracy: 0.4434 - val_loss: 1.8830 - val_sparse_categorical_accuracy: 0.3440\n",
      "Epoch 84/100\n",
      "14147/14147 [==============================] - 10s 740us/step - loss: 1.4577 - sparse_categorical_accuracy: 0.4474 - val_loss: 2.0474 - val_sparse_categorical_accuracy: 0.2637\n",
      "Epoch 85/100\n",
      "14147/14147 [==============================] - 10s 706us/step - loss: 1.4576 - sparse_categorical_accuracy: 0.4476 - val_loss: 1.8902 - val_sparse_categorical_accuracy: 0.3090\n",
      "Epoch 86/100\n",
      "14147/14147 [==============================] - 10s 693us/step - loss: 1.4935 - sparse_categorical_accuracy: 0.4412 - val_loss: 1.7405 - val_sparse_categorical_accuracy: 0.3724\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14147/14147 [==============================] - 8s 593us/step - loss: 1.4432 - sparse_categorical_accuracy: 0.4575 - val_loss: 1.9174 - val_sparse_categorical_accuracy: 0.3211\n",
      "Epoch 88/100\n",
      "14147/14147 [==============================] - 9s 651us/step - loss: 1.4230 - sparse_categorical_accuracy: 0.4598 - val_loss: 2.0044 - val_sparse_categorical_accuracy: 0.3259\n",
      "Epoch 89/100\n",
      "14147/14147 [==============================] - 9s 605us/step - loss: 1.4074 - sparse_categorical_accuracy: 0.4676 - val_loss: 1.9349 - val_sparse_categorical_accuracy: 0.3337\n",
      "Epoch 90/100\n",
      "14147/14147 [==============================] - 9s 613us/step - loss: 1.4020 - sparse_categorical_accuracy: 0.4721 - val_loss: 1.8418 - val_sparse_categorical_accuracy: 0.4056\n",
      "Epoch 91/100\n",
      "14147/14147 [==============================] - 9s 641us/step - loss: 1.3919 - sparse_categorical_accuracy: 0.4773 - val_loss: 1.7729 - val_sparse_categorical_accuracy: 0.3730\n",
      "Epoch 92/100\n",
      "14147/14147 [==============================] - 9s 666us/step - loss: 1.3568 - sparse_categorical_accuracy: 0.4923 - val_loss: 1.9344 - val_sparse_categorical_accuracy: 0.3211\n",
      "Epoch 93/100\n",
      "14147/14147 [==============================] - 8s 596us/step - loss: 1.3735 - sparse_categorical_accuracy: 0.4842 - val_loss: 1.7430 - val_sparse_categorical_accuracy: 0.4200\n",
      "Epoch 94/100\n",
      "14147/14147 [==============================] - 8s 598us/step - loss: 1.3254 - sparse_categorical_accuracy: 0.4939 - val_loss: 1.9387 - val_sparse_categorical_accuracy: 0.3669\n",
      "Epoch 95/100\n",
      "14147/14147 [==============================] - 9s 616us/step - loss: 1.4532 - sparse_categorical_accuracy: 0.4609 - val_loss: 1.8127 - val_sparse_categorical_accuracy: 0.3826\n",
      "Epoch 96/100\n",
      "14147/14147 [==============================] - 9s 602us/step - loss: 1.3197 - sparse_categorical_accuracy: 0.5029 - val_loss: 1.7973 - val_sparse_categorical_accuracy: 0.4430\n",
      "Epoch 97/100\n",
      "14147/14147 [==============================] - 8s 585us/step - loss: 1.3226 - sparse_categorical_accuracy: 0.5002 - val_loss: 1.8802 - val_sparse_categorical_accuracy: 0.3856\n",
      "Epoch 98/100\n",
      "14147/14147 [==============================] - 9s 602us/step - loss: 1.3347 - sparse_categorical_accuracy: 0.4961 - val_loss: 1.9687 - val_sparse_categorical_accuracy: 0.3132\n",
      "Epoch 99/100\n",
      "14147/14147 [==============================] - 9s 616us/step - loss: 1.3244 - sparse_categorical_accuracy: 0.4899 - val_loss: 1.8449 - val_sparse_categorical_accuracy: 0.3850\n",
      "Epoch 100/100\n",
      "14147/14147 [==============================] - 9s 604us/step - loss: 1.3444 - sparse_categorical_accuracy: 0.4950 - val_loss: 1.9501 - val_sparse_categorical_accuracy: 0.3730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c442dbc88>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### MLPs Offilne baseline\n",
    "model.fit(X_train_linear, y_train, validation_data=(X_test_linear, y_test),\n",
    "                    epochs=100,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='tanh', input_shape=(data_dim*timesteps,)))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='tanh'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax',init='glorot_normal'))\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10901 samples, validate on 1340 samples\n",
      "Epoch 1/100\n",
      "10901/10901 [==============================] - 12s 1ms/step - loss: 2.5983 - sparse_categorical_accuracy: 0.1270 - val_loss: 2.2987 - val_sparse_categorical_accuracy: 0.1000\n",
      "Epoch 2/100\n",
      "10901/10901 [==============================] - 10s 903us/step - loss: 2.1562 - sparse_categorical_accuracy: 0.2048 - val_loss: 2.0009 - val_sparse_categorical_accuracy: 0.2993\n",
      "Epoch 3/100\n",
      "10901/10901 [==============================] - 8s 747us/step - loss: 1.9024 - sparse_categorical_accuracy: 0.2872 - val_loss: 1.9006 - val_sparse_categorical_accuracy: 0.3425\n",
      "Epoch 4/100\n",
      "10901/10901 [==============================] - 8s 760us/step - loss: 1.7003 - sparse_categorical_accuracy: 0.3308 - val_loss: 1.7281 - val_sparse_categorical_accuracy: 0.3493\n",
      "Epoch 5/100\n",
      "10901/10901 [==============================] - 8s 778us/step - loss: 1.6113 - sparse_categorical_accuracy: 0.3474 - val_loss: 1.6885 - val_sparse_categorical_accuracy: 0.3537\n",
      "Epoch 6/100\n",
      "10901/10901 [==============================] - 8s 716us/step - loss: 1.5192 - sparse_categorical_accuracy: 0.3747 - val_loss: 1.6851 - val_sparse_categorical_accuracy: 0.3799\n",
      "Epoch 7/100\n",
      "10901/10901 [==============================] - 8s 756us/step - loss: 1.4325 - sparse_categorical_accuracy: 0.4025 - val_loss: 1.6195 - val_sparse_categorical_accuracy: 0.3052\n",
      "Epoch 8/100\n",
      "10901/10901 [==============================] - 7s 680us/step - loss: 1.3721 - sparse_categorical_accuracy: 0.4185 - val_loss: 1.4729 - val_sparse_categorical_accuracy: 0.3642\n",
      "Epoch 9/100\n",
      "10901/10901 [==============================] - 8s 723us/step - loss: 1.3119 - sparse_categorical_accuracy: 0.4345 - val_loss: 1.4886 - val_sparse_categorical_accuracy: 0.3933\n",
      "Epoch 10/100\n",
      "10901/10901 [==============================] - 7s 668us/step - loss: 1.2750 - sparse_categorical_accuracy: 0.4466 - val_loss: 1.6838 - val_sparse_categorical_accuracy: 0.3425\n",
      "Epoch 11/100\n",
      "10901/10901 [==============================] - 8s 728us/step - loss: 1.2545 - sparse_categorical_accuracy: 0.4598 - val_loss: 1.4650 - val_sparse_categorical_accuracy: 0.3948\n",
      "Epoch 12/100\n",
      "10901/10901 [==============================] - 8s 729us/step - loss: 1.2535 - sparse_categorical_accuracy: 0.4600 - val_loss: 1.3634 - val_sparse_categorical_accuracy: 0.3933\n",
      "Epoch 13/100\n",
      "10901/10901 [==============================] - 9s 808us/step - loss: 1.1899 - sparse_categorical_accuracy: 0.4789 - val_loss: 1.3606 - val_sparse_categorical_accuracy: 0.4119\n",
      "Epoch 14/100\n",
      "10901/10901 [==============================] - 7s 600us/step - loss: 1.1856 - sparse_categorical_accuracy: 0.4819 - val_loss: 1.2960 - val_sparse_categorical_accuracy: 0.4560\n",
      "Epoch 15/100\n",
      "10901/10901 [==============================] - 6s 591us/step - loss: 1.1626 - sparse_categorical_accuracy: 0.4906 - val_loss: 1.4429 - val_sparse_categorical_accuracy: 0.3993\n",
      "Epoch 16/100\n",
      "10901/10901 [==============================] - 9s 792us/step - loss: 1.1318 - sparse_categorical_accuracy: 0.5049 - val_loss: 1.3520 - val_sparse_categorical_accuracy: 0.4142\n",
      "Epoch 17/100\n",
      "10901/10901 [==============================] - 9s 832us/step - loss: 1.1008 - sparse_categorical_accuracy: 0.5164 - val_loss: 1.4550 - val_sparse_categorical_accuracy: 0.4045\n",
      "Epoch 18/100\n",
      "10901/10901 [==============================] - 9s 845us/step - loss: 1.0865 - sparse_categorical_accuracy: 0.5190 - val_loss: 1.3107 - val_sparse_categorical_accuracy: 0.4567\n",
      "Epoch 19/100\n",
      "10901/10901 [==============================] - 11s 1ms/step - loss: 1.0894 - sparse_categorical_accuracy: 0.5165 - val_loss: 1.5257 - val_sparse_categorical_accuracy: 0.4284\n",
      "Epoch 20/100\n",
      "10901/10901 [==============================] - 11s 976us/step - loss: 1.0851 - sparse_categorical_accuracy: 0.5213 - val_loss: 1.3059 - val_sparse_categorical_accuracy: 0.4530\n",
      "Epoch 21/100\n",
      " 3904/10901 [=========>....................] - ETA: 6s - loss: 1.0662 - sparse_categorical_accuracy: 0.5269"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-b82f54881167>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m##### MLPs Offilne baseline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model.fit(X_train_D1_linear, y_train_D1, validation_data=(X_test_D1_linear, y_test_D1),\n\u001b[0;32m----> 3\u001b[0;31m                     epochs=100,batch_size=64)\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/py354/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda2/envs/py354/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py354/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py354/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py354/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##### MLPs Offilne baseline\n",
    "model.fit(X_train_D1_linear, y_train_D1, validation_data=(X_test_D1_linear, y_test_D1),\n",
    "                    epochs=100,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2712,)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_linear[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 97, 3: 281, 5: 665, 12: 246, 14: 83, 15: 214, 16: 71})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 58,\n",
       "         1: 95,\n",
       "         2: 60,\n",
       "         3: 83,\n",
       "         4: 228,\n",
       "         5: 160,\n",
       "         6: 100,\n",
       "         7: 77,\n",
       "         8: 39,\n",
       "         9: 42,\n",
       "         10: 40,\n",
       "         11: 26,\n",
       "         12: 67,\n",
       "         13: 61,\n",
       "         14: 99,\n",
       "         15: 317,\n",
       "         16: 105})"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 52,\n",
       "         1: 40,\n",
       "         2: 332,\n",
       "         3: 166,\n",
       "         4: 104,\n",
       "         5: 205,\n",
       "         6: 3,\n",
       "         7: 374,\n",
       "         8: 43,\n",
       "         11: 27,\n",
       "         13: 120,\n",
       "         14: 147,\n",
       "         16: 44})"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3035606517803259"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = np.argmax(model.predict(X_test_linear), axis=1)\n",
    "accuracy_score(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14147 samples, validate on 1657 samples\n",
      "Epoch 1/100\n",
      "14147/14147 [==============================] - 11s 766us/step - loss: 1.4098 - sparse_categorical_accuracy: 0.5345 - val_loss: 1.3480 - val_sparse_categorical_accuracy: 0.5963\n",
      "Epoch 2/100\n",
      "14147/14147 [==============================] - 10s 722us/step - loss: 0.7282 - sparse_categorical_accuracy: 0.7192 - val_loss: 1.1549 - val_sparse_categorical_accuracy: 0.6150\n",
      "Epoch 3/100\n",
      "14147/14147 [==============================] - 11s 781us/step - loss: 0.6107 - sparse_categorical_accuracy: 0.7679 - val_loss: 0.9708 - val_sparse_categorical_accuracy: 0.6566\n",
      "Epoch 4/100\n",
      "14147/14147 [==============================] - 11s 764us/step - loss: 0.5572 - sparse_categorical_accuracy: 0.7861 - val_loss: 0.9715 - val_sparse_categorical_accuracy: 0.6729\n",
      "Epoch 5/100\n",
      "14147/14147 [==============================] - 11s 775us/step - loss: 0.5101 - sparse_categorical_accuracy: 0.8029 - val_loss: 1.2193 - val_sparse_categorical_accuracy: 0.5969\n",
      "Epoch 6/100\n",
      "14147/14147 [==============================] - 11s 766us/step - loss: 0.5275 - sparse_categorical_accuracy: 0.7974 - val_loss: 0.9664 - val_sparse_categorical_accuracy: 0.6729\n",
      "Epoch 7/100\n",
      "14147/14147 [==============================] - 11s 766us/step - loss: 0.4802 - sparse_categorical_accuracy: 0.8109 - val_loss: 1.0053 - val_sparse_categorical_accuracy: 0.6687\n",
      "Epoch 8/100\n",
      "14147/14147 [==============================] - 11s 780us/step - loss: 0.4549 - sparse_categorical_accuracy: 0.8259 - val_loss: 0.9820 - val_sparse_categorical_accuracy: 0.6608\n",
      "Epoch 9/100\n",
      "14147/14147 [==============================] - 11s 778us/step - loss: 0.4454 - sparse_categorical_accuracy: 0.8273 - val_loss: 0.8179 - val_sparse_categorical_accuracy: 0.7158\n",
      "Epoch 10/100\n",
      "14147/14147 [==============================] - 12s 816us/step - loss: 0.4289 - sparse_categorical_accuracy: 0.8342 - val_loss: 0.8918 - val_sparse_categorical_accuracy: 0.6964\n",
      "Epoch 11/100\n",
      "14147/14147 [==============================] - 12s 824us/step - loss: 0.4131 - sparse_categorical_accuracy: 0.8402 - val_loss: 0.9454 - val_sparse_categorical_accuracy: 0.6844\n",
      "Epoch 12/100\n",
      "14147/14147 [==============================] - 12s 879us/step - loss: 0.3908 - sparse_categorical_accuracy: 0.8506 - val_loss: 0.7721 - val_sparse_categorical_accuracy: 0.7351\n",
      "Epoch 13/100\n",
      "14147/14147 [==============================] - 13s 932us/step - loss: 0.3784 - sparse_categorical_accuracy: 0.8542 - val_loss: 0.9426 - val_sparse_categorical_accuracy: 0.6904\n",
      "Epoch 14/100\n",
      "14147/14147 [==============================] - 15s 1ms/step - loss: 0.4045 - sparse_categorical_accuracy: 0.8443 - val_loss: 0.7109 - val_sparse_categorical_accuracy: 0.7628\n",
      "Epoch 15/100\n",
      "14147/14147 [==============================] - 16s 1ms/step - loss: 0.3828 - sparse_categorical_accuracy: 0.8508 - val_loss: 0.7917 - val_sparse_categorical_accuracy: 0.7357\n",
      "Epoch 16/100\n",
      "14147/14147 [==============================] - 12s 837us/step - loss: 0.3552 - sparse_categorical_accuracy: 0.8567 - val_loss: 0.7599 - val_sparse_categorical_accuracy: 0.7580\n",
      "Epoch 17/100\n",
      "14147/14147 [==============================] - 14s 999us/step - loss: 0.3533 - sparse_categorical_accuracy: 0.8608 - val_loss: 0.9519 - val_sparse_categorical_accuracy: 0.6982\n",
      "Epoch 18/100\n",
      "14147/14147 [==============================] - 19s 1ms/step - loss: 0.3655 - sparse_categorical_accuracy: 0.8583 - val_loss: 0.8881 - val_sparse_categorical_accuracy: 0.7272\n",
      "Epoch 19/100\n",
      "14147/14147 [==============================] - 12s 884us/step - loss: 0.3588 - sparse_categorical_accuracy: 0.8648 - val_loss: 0.8923 - val_sparse_categorical_accuracy: 0.7115\n",
      "Epoch 20/100\n",
      "14147/14147 [==============================] - 12s 840us/step - loss: 0.3424 - sparse_categorical_accuracy: 0.8689 - val_loss: 0.8567 - val_sparse_categorical_accuracy: 0.7109\n",
      "Epoch 21/100\n",
      "14147/14147 [==============================] - 12s 843us/step - loss: 0.3203 - sparse_categorical_accuracy: 0.8774 - val_loss: 0.8422 - val_sparse_categorical_accuracy: 0.7278\n",
      "Epoch 22/100\n",
      "14147/14147 [==============================] - 17s 1ms/step - loss: 0.3332 - sparse_categorical_accuracy: 0.8717 - val_loss: 0.8841 - val_sparse_categorical_accuracy: 0.7266\n",
      "Epoch 23/100\n",
      "14147/14147 [==============================] - 12s 846us/step - loss: 0.3184 - sparse_categorical_accuracy: 0.8766 - val_loss: 0.8915 - val_sparse_categorical_accuracy: 0.7079\n",
      "Epoch 24/100\n",
      "14147/14147 [==============================] - 12s 839us/step - loss: 0.3825 - sparse_categorical_accuracy: 0.8528 - val_loss: 0.8308 - val_sparse_categorical_accuracy: 0.7188\n",
      "Epoch 25/100\n",
      "14147/14147 [==============================] - 16s 1ms/step - loss: 0.2985 - sparse_categorical_accuracy: 0.8841 - val_loss: 0.8608 - val_sparse_categorical_accuracy: 0.7405\n",
      "Epoch 26/100\n",
      "14147/14147 [==============================] - 12s 837us/step - loss: 0.3091 - sparse_categorical_accuracy: 0.8812 - val_loss: 0.8135 - val_sparse_categorical_accuracy: 0.7369\n",
      "Epoch 27/100\n",
      "14147/14147 [==============================] - 12s 855us/step - loss: 0.3000 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.7431 - val_sparse_categorical_accuracy: 0.7598\n",
      "Epoch 28/100\n",
      "14147/14147 [==============================] - 12s 841us/step - loss: 0.3034 - sparse_categorical_accuracy: 0.8838 - val_loss: 0.9463 - val_sparse_categorical_accuracy: 0.7103\n",
      "Epoch 29/100\n",
      "14147/14147 [==============================] - 12s 853us/step - loss: 0.3282 - sparse_categorical_accuracy: 0.8728 - val_loss: 1.0553 - val_sparse_categorical_accuracy: 0.7103\n",
      "Epoch 30/100\n",
      "14147/14147 [==============================] - 12s 845us/step - loss: 0.3904 - sparse_categorical_accuracy: 0.8535 - val_loss: 0.7470 - val_sparse_categorical_accuracy: 0.7441\n",
      "Epoch 31/100\n",
      "14147/14147 [==============================] - 16s 1ms/step - loss: 0.2779 - sparse_categorical_accuracy: 0.8939 - val_loss: 0.8717 - val_sparse_categorical_accuracy: 0.7393\n",
      "Epoch 32/100\n",
      "14147/14147 [==============================] - 11s 776us/step - loss: 0.2989 - sparse_categorical_accuracy: 0.8873 - val_loss: 0.8165 - val_sparse_categorical_accuracy: 0.7562\n",
      "Epoch 33/100\n",
      "14147/14147 [==============================] - 12s 854us/step - loss: 0.2946 - sparse_categorical_accuracy: 0.8887 - val_loss: 0.8788 - val_sparse_categorical_accuracy: 0.7266\n",
      "Epoch 34/100\n",
      "14147/14147 [==============================] - 13s 888us/step - loss: 0.2638 - sparse_categorical_accuracy: 0.8987 - val_loss: 0.8926 - val_sparse_categorical_accuracy: 0.7242\n",
      "Epoch 35/100\n",
      "14147/14147 [==============================] - 15s 1ms/step - loss: 0.3298 - sparse_categorical_accuracy: 0.8763 - val_loss: 0.9081 - val_sparse_categorical_accuracy: 0.7145\n",
      "Epoch 36/100\n",
      "14147/14147 [==============================] - 12s 869us/step - loss: 0.2675 - sparse_categorical_accuracy: 0.8963 - val_loss: 0.7786 - val_sparse_categorical_accuracy: 0.7622\n",
      "Epoch 37/100\n",
      "14147/14147 [==============================] - 12s 865us/step - loss: 0.2546 - sparse_categorical_accuracy: 0.9037 - val_loss: 0.9082 - val_sparse_categorical_accuracy: 0.7164\n",
      "Epoch 38/100\n",
      "14147/14147 [==============================] - 12s 854us/step - loss: 0.2929 - sparse_categorical_accuracy: 0.8890 - val_loss: 0.7466 - val_sparse_categorical_accuracy: 0.7670\n",
      "Epoch 39/100\n",
      "14147/14147 [==============================] - 12s 841us/step - loss: 0.2612 - sparse_categorical_accuracy: 0.9020 - val_loss: 0.8818 - val_sparse_categorical_accuracy: 0.7477\n",
      "Epoch 40/100\n",
      "14147/14147 [==============================] - 13s 884us/step - loss: 0.2559 - sparse_categorical_accuracy: 0.9044 - val_loss: 0.8459 - val_sparse_categorical_accuracy: 0.7423\n",
      "Epoch 41/100\n",
      "14147/14147 [==============================] - 16s 1ms/step - loss: 0.2387 - sparse_categorical_accuracy: 0.9107 - val_loss: 0.7206 - val_sparse_categorical_accuracy: 0.7670\n",
      "Epoch 42/100\n",
      "14147/14147 [==============================] - 12s 853us/step - loss: 0.2434 - sparse_categorical_accuracy: 0.9069 - val_loss: 0.7948 - val_sparse_categorical_accuracy: 0.7441\n",
      "Epoch 43/100\n",
      "14147/14147 [==============================] - 12s 849us/step - loss: 0.2990 - sparse_categorical_accuracy: 0.8887 - val_loss: 0.9191 - val_sparse_categorical_accuracy: 0.7236\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14147/14147 [==============================] - 16s 1ms/step - loss: 0.2439 - sparse_categorical_accuracy: 0.9076 - val_loss: 0.7797 - val_sparse_categorical_accuracy: 0.7719\n",
      "Epoch 45/100\n",
      "14147/14147 [==============================] - 12s 846us/step - loss: 0.2388 - sparse_categorical_accuracy: 0.9105 - val_loss: 0.8734 - val_sparse_categorical_accuracy: 0.7465\n",
      "Epoch 46/100\n",
      "14147/14147 [==============================] - 12s 836us/step - loss: 0.2327 - sparse_categorical_accuracy: 0.9108 - val_loss: 0.8742 - val_sparse_categorical_accuracy: 0.7532\n",
      "Epoch 47/100\n",
      "14147/14147 [==============================] - 12s 840us/step - loss: 0.2627 - sparse_categorical_accuracy: 0.9001 - val_loss: 0.7694 - val_sparse_categorical_accuracy: 0.7526\n",
      "Epoch 48/100\n",
      "14147/14147 [==============================] - 12s 829us/step - loss: 0.2066 - sparse_categorical_accuracy: 0.9229 - val_loss: 0.9745 - val_sparse_categorical_accuracy: 0.7417\n",
      "Epoch 49/100\n",
      "14147/14147 [==============================] - 12s 856us/step - loss: 0.2178 - sparse_categorical_accuracy: 0.9181 - val_loss: 0.8142 - val_sparse_categorical_accuracy: 0.7713\n",
      "Epoch 50/100\n",
      "14147/14147 [==============================] - 16s 1ms/step - loss: 0.2474 - sparse_categorical_accuracy: 0.9085 - val_loss: 0.9377 - val_sparse_categorical_accuracy: 0.7272\n",
      "Epoch 51/100\n",
      "14147/14147 [==============================] - 12s 845us/step - loss: 0.2546 - sparse_categorical_accuracy: 0.9046 - val_loss: 0.7644 - val_sparse_categorical_accuracy: 0.7725\n",
      "Epoch 52/100\n",
      "14147/14147 [==============================] - 12s 844us/step - loss: 0.2140 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.7664 - val_sparse_categorical_accuracy: 0.7622\n",
      "Epoch 53/100\n",
      "14147/14147 [==============================] - 15s 1ms/step - loss: 0.1991 - sparse_categorical_accuracy: 0.9263 - val_loss: 0.7884 - val_sparse_categorical_accuracy: 0.7773\n",
      "Epoch 54/100\n",
      "14147/14147 [==============================] - 13s 900us/step - loss: 0.2082 - sparse_categorical_accuracy: 0.9227 - val_loss: 0.8099 - val_sparse_categorical_accuracy: 0.7598\n",
      "Epoch 55/100\n",
      "14147/14147 [==============================] - 12s 831us/step - loss: 0.2412 - sparse_categorical_accuracy: 0.9086 - val_loss: 0.7541 - val_sparse_categorical_accuracy: 0.8045\n",
      "Epoch 56/100\n",
      "14147/14147 [==============================] - 12s 854us/step - loss: 0.1939 - sparse_categorical_accuracy: 0.9262 - val_loss: 0.8488 - val_sparse_categorical_accuracy: 0.7598\n",
      "Epoch 57/100\n",
      "14147/14147 [==============================] - 12s 838us/step - loss: 0.2028 - sparse_categorical_accuracy: 0.9243 - val_loss: 0.8197 - val_sparse_categorical_accuracy: 0.7725\n",
      "Epoch 58/100\n",
      "14147/14147 [==============================] - 12s 837us/step - loss: 0.2197 - sparse_categorical_accuracy: 0.9172 - val_loss: 0.7831 - val_sparse_categorical_accuracy: 0.7737\n",
      "Epoch 59/100\n",
      "14147/14147 [==============================] - 14s 981us/step - loss: 0.2107 - sparse_categorical_accuracy: 0.9201 - val_loss: 0.7954 - val_sparse_categorical_accuracy: 0.7719\n",
      "Epoch 60/100\n",
      "14147/14147 [==============================] - 14s 1ms/step - loss: 0.1827 - sparse_categorical_accuracy: 0.9312 - val_loss: 0.8189 - val_sparse_categorical_accuracy: 0.7725\n",
      "Epoch 61/100\n",
      "14147/14147 [==============================] - 12s 847us/step - loss: 0.1903 - sparse_categorical_accuracy: 0.9283 - val_loss: 0.8058 - val_sparse_categorical_accuracy: 0.7779\n",
      "Epoch 62/100\n",
      "14147/14147 [==============================] - 11s 770us/step - loss: 0.2073 - sparse_categorical_accuracy: 0.9222 - val_loss: 0.8194 - val_sparse_categorical_accuracy: 0.7713\n",
      "Epoch 63/100\n",
      "14147/14147 [==============================] - 9s 625us/step - loss: 0.1929 - sparse_categorical_accuracy: 0.9258 - val_loss: 1.0025 - val_sparse_categorical_accuracy: 0.7049\n",
      "Epoch 64/100\n",
      "14147/14147 [==============================] - 7s 507us/step - loss: 0.2898 - sparse_categorical_accuracy: 0.8943 - val_loss: 0.8441 - val_sparse_categorical_accuracy: 0.7761\n",
      "Epoch 65/100\n",
      "14147/14147 [==============================] - 8s 551us/step - loss: 0.2034 - sparse_categorical_accuracy: 0.9280 - val_loss: 1.2613 - val_sparse_categorical_accuracy: 0.6940\n",
      "Epoch 66/100\n",
      "14147/14147 [==============================] - 8s 579us/step - loss: 0.4098 - sparse_categorical_accuracy: 0.8528 - val_loss: 0.7462 - val_sparse_categorical_accuracy: 0.7755\n",
      "Epoch 67/100\n",
      "14147/14147 [==============================] - 8s 567us/step - loss: 0.2084 - sparse_categorical_accuracy: 0.9239 - val_loss: 0.7941 - val_sparse_categorical_accuracy: 0.7743\n",
      "Epoch 68/100\n",
      "14147/14147 [==============================] - 8s 547us/step - loss: 0.1871 - sparse_categorical_accuracy: 0.9302 - val_loss: 0.8143 - val_sparse_categorical_accuracy: 0.7785\n",
      "Epoch 69/100\n",
      "14147/14147 [==============================] - 8s 534us/step - loss: 0.1946 - sparse_categorical_accuracy: 0.9285 - val_loss: 0.8283 - val_sparse_categorical_accuracy: 0.7689\n",
      "Epoch 70/100\n",
      "14147/14147 [==============================] - 7s 520us/step - loss: 0.1711 - sparse_categorical_accuracy: 0.9360 - val_loss: 0.9382 - val_sparse_categorical_accuracy: 0.7586\n",
      "Epoch 71/100\n",
      "14147/14147 [==============================] - 7s 498us/step - loss: 0.1899 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.7515 - val_sparse_categorical_accuracy: 0.7846\n",
      "Epoch 72/100\n",
      "14147/14147 [==============================] - 7s 494us/step - loss: 0.1763 - sparse_categorical_accuracy: 0.9338 - val_loss: 0.8106 - val_sparse_categorical_accuracy: 0.7864\n",
      "Epoch 73/100\n",
      "14147/14147 [==============================] - 10s 729us/step - loss: 0.1700 - sparse_categorical_accuracy: 0.9386 - val_loss: 1.0306 - val_sparse_categorical_accuracy: 0.7308\n",
      "Epoch 74/100\n",
      "14147/14147 [==============================] - 7s 475us/step - loss: 0.2791 - sparse_categorical_accuracy: 0.9010 - val_loss: 0.7950 - val_sparse_categorical_accuracy: 0.7640\n",
      "Epoch 75/100\n",
      "14147/14147 [==============================] - 6s 459us/step - loss: 0.1871 - sparse_categorical_accuracy: 0.9313 - val_loss: 0.8894 - val_sparse_categorical_accuracy: 0.7604\n",
      "Epoch 76/100\n",
      "14147/14147 [==============================] - 7s 484us/step - loss: 0.1753 - sparse_categorical_accuracy: 0.9360 - val_loss: 0.7954 - val_sparse_categorical_accuracy: 0.7833\n",
      "Epoch 77/100\n",
      "14147/14147 [==============================] - 7s 487us/step - loss: 0.1645 - sparse_categorical_accuracy: 0.9386 - val_loss: 0.8992 - val_sparse_categorical_accuracy: 0.7526\n",
      "Epoch 78/100\n",
      "14147/14147 [==============================] - 7s 476us/step - loss: 0.1756 - sparse_categorical_accuracy: 0.9369 - val_loss: 0.7139 - val_sparse_categorical_accuracy: 0.7990\n",
      "Epoch 79/100\n",
      "14147/14147 [==============================] - 7s 479us/step - loss: 0.2033 - sparse_categorical_accuracy: 0.9263 - val_loss: 0.7640 - val_sparse_categorical_accuracy: 0.7634\n",
      "Epoch 80/100\n",
      "14147/14147 [==============================] - 7s 515us/step - loss: 0.1425 - sparse_categorical_accuracy: 0.9465 - val_loss: 0.8999 - val_sparse_categorical_accuracy: 0.7646\n",
      "Epoch 81/100\n",
      "14147/14147 [==============================] - 7s 518us/step - loss: 0.1638 - sparse_categorical_accuracy: 0.9378 - val_loss: 0.7742 - val_sparse_categorical_accuracy: 0.7984\n",
      "Epoch 82/100\n",
      "14147/14147 [==============================] - 7s 513us/step - loss: 0.2031 - sparse_categorical_accuracy: 0.9262 - val_loss: 0.8732 - val_sparse_categorical_accuracy: 0.7526\n",
      "Epoch 83/100\n",
      "14147/14147 [==============================] - 7s 464us/step - loss: 0.1456 - sparse_categorical_accuracy: 0.9470 - val_loss: 0.9387 - val_sparse_categorical_accuracy: 0.7646\n",
      "Epoch 84/100\n",
      "14147/14147 [==============================] - 7s 477us/step - loss: 0.2204 - sparse_categorical_accuracy: 0.9215 - val_loss: 0.7837 - val_sparse_categorical_accuracy: 0.7827\n",
      "Epoch 85/100\n",
      "14147/14147 [==============================] - 7s 464us/step - loss: 0.1311 - sparse_categorical_accuracy: 0.9515 - val_loss: 0.7725 - val_sparse_categorical_accuracy: 0.7978\n",
      "Epoch 86/100\n",
      "14147/14147 [==============================] - 8s 535us/step - loss: 0.2110 - sparse_categorical_accuracy: 0.9216 - val_loss: 1.2445 - val_sparse_categorical_accuracy: 0.6765\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14147/14147 [==============================] - 8s 553us/step - loss: 0.4123 - sparse_categorical_accuracy: 0.8474 - val_loss: 0.8842 - val_sparse_categorical_accuracy: 0.7477\n",
      "Epoch 88/100\n",
      "14147/14147 [==============================] - 7s 512us/step - loss: 0.3034 - sparse_categorical_accuracy: 0.8859 - val_loss: 1.0936 - val_sparse_categorical_accuracy: 0.6982\n",
      "Epoch 89/100\n",
      "14147/14147 [==============================] - 9s 640us/step - loss: 0.3633 - sparse_categorical_accuracy: 0.8694 - val_loss: 0.7590 - val_sparse_categorical_accuracy: 0.7749\n",
      "Epoch 90/100\n",
      "14147/14147 [==============================] - 9s 639us/step - loss: 0.2162 - sparse_categorical_accuracy: 0.9208 - val_loss: 0.8109 - val_sparse_categorical_accuracy: 0.7713\n",
      "Epoch 91/100\n",
      "14147/14147 [==============================] - 7s 529us/step - loss: 0.1836 - sparse_categorical_accuracy: 0.9331 - val_loss: 0.8864 - val_sparse_categorical_accuracy: 0.7598\n",
      "Epoch 92/100\n",
      "14147/14147 [==============================] - 7s 466us/step - loss: 0.2042 - sparse_categorical_accuracy: 0.9246 - val_loss: 0.9305 - val_sparse_categorical_accuracy: 0.7526\n",
      "Epoch 93/100\n",
      "14147/14147 [==============================] - 7s 528us/step - loss: 0.1498 - sparse_categorical_accuracy: 0.9441 - val_loss: 0.8884 - val_sparse_categorical_accuracy: 0.7610\n",
      "Epoch 94/100\n",
      "14147/14147 [==============================] - 9s 609us/step - loss: 0.1442 - sparse_categorical_accuracy: 0.9479 - val_loss: 0.7902 - val_sparse_categorical_accuracy: 0.8063\n",
      "Epoch 95/100\n",
      "14147/14147 [==============================] - 7s 507us/step - loss: 0.1461 - sparse_categorical_accuracy: 0.9466 - val_loss: 0.7483 - val_sparse_categorical_accuracy: 0.8021\n",
      "Epoch 96/100\n",
      "14147/14147 [==============================] - 7s 507us/step - loss: 0.1650 - sparse_categorical_accuracy: 0.9389 - val_loss: 1.0125 - val_sparse_categorical_accuracy: 0.7284\n",
      "Epoch 97/100\n",
      "14147/14147 [==============================] - 7s 478us/step - loss: 0.3149 - sparse_categorical_accuracy: 0.8897 - val_loss: 1.0725 - val_sparse_categorical_accuracy: 0.7272\n",
      "Epoch 98/100\n",
      "14147/14147 [==============================] - 7s 472us/step - loss: 0.1521 - sparse_categorical_accuracy: 0.9435 - val_loss: 0.8576 - val_sparse_categorical_accuracy: 0.7809\n",
      "Epoch 99/100\n",
      "14147/14147 [==============================] - 8s 548us/step - loss: 0.1543 - sparse_categorical_accuracy: 0.9426 - val_loss: 0.8985 - val_sparse_categorical_accuracy: 0.7640\n",
      "Epoch 100/100\n",
      "14147/14147 [==============================] - 7s 473us/step - loss: 0.1526 - sparse_categorical_accuracy: 0.9440 - val_loss: 0.8786 - val_sparse_categorical_accuracy: 0.7797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c3c2f4198>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### LSTMs offline baseline\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                    epochs=100,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilaLSTMs():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hidden_layer_size,input_shape=(timesteps, data_dim),init='glorot_normal'))  # return a single vector of dimension 32\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation='softmax',init='glorot_normal'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['sparse_categorical_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = 113 # (# features)\n",
    "num_classes = 17\n",
    "\n",
    "# params\n",
    "timesteps = 24\n",
    "num_stack = 1\n",
    "hidden_layer_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 864,\n",
       "         1: 887,\n",
       "         2: 806,\n",
       "         3: 846,\n",
       "         4: 921,\n",
       "         5: 850,\n",
       "         6: 666,\n",
       "         7: 628,\n",
       "         8: 490,\n",
       "         9: 413,\n",
       "         10: 457,\n",
       "         11: 416,\n",
       "         12: 566,\n",
       "         13: 564,\n",
       "         14: 904,\n",
       "         15: 3246,\n",
       "         16: 623})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==== Baseline model performance ====\")\n",
    "model = vanilaLSTMs()\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                        epochs=100,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Adding One More Class ====\n",
      "class num D2: 0\n",
      "Train on 13283 samples, validate on 1599 samples\n",
      "Epoch 1/30\n",
      "13283/13283 [==============================] - 10s 723us/step - loss: 1.7548 - sparse_categorical_accuracy: 0.3969 - val_loss: 1.6526 - val_sparse_categorical_accuracy: 0.4378\n",
      "Epoch 2/30\n",
      "13283/13283 [==============================] - 8s 567us/step - loss: 1.2415 - sparse_categorical_accuracy: 0.5375 - val_loss: 1.4795 - val_sparse_categorical_accuracy: 0.4415\n",
      "Epoch 3/30\n",
      "13283/13283 [==============================] - 8s 593us/step - loss: 1.0091 - sparse_categorical_accuracy: 0.6104 - val_loss: 1.2266 - val_sparse_categorical_accuracy: 0.5629\n",
      "Epoch 4/30\n",
      "13283/13283 [==============================] - 8s 607us/step - loss: 0.8854 - sparse_categorical_accuracy: 0.6560 - val_loss: 1.2101 - val_sparse_categorical_accuracy: 0.5560\n",
      "Epoch 5/30\n",
      "13283/13283 [==============================] - 7s 520us/step - loss: 0.8240 - sparse_categorical_accuracy: 0.6740 - val_loss: 1.0588 - val_sparse_categorical_accuracy: 0.5966\n",
      "Epoch 6/30\n",
      "13283/13283 [==============================] - 8s 572us/step - loss: 0.7826 - sparse_categorical_accuracy: 0.6860 - val_loss: 1.0296 - val_sparse_categorical_accuracy: 0.5935\n",
      "Epoch 7/30\n",
      "13283/13283 [==============================] - 8s 587us/step - loss: 0.7465 - sparse_categorical_accuracy: 0.7006 - val_loss: 1.0499 - val_sparse_categorical_accuracy: 0.6060\n",
      "Epoch 8/30\n",
      "13283/13283 [==============================] - 7s 522us/step - loss: 0.6945 - sparse_categorical_accuracy: 0.7189 - val_loss: 0.9719 - val_sparse_categorical_accuracy: 0.6160\n",
      "Epoch 9/30\n",
      "13283/13283 [==============================] - 7s 506us/step - loss: 0.6602 - sparse_categorical_accuracy: 0.7288 - val_loss: 0.9612 - val_sparse_categorical_accuracy: 0.6385\n",
      "Epoch 10/30\n",
      "13283/13283 [==============================] - 7s 494us/step - loss: 0.6400 - sparse_categorical_accuracy: 0.7370 - val_loss: 0.9843 - val_sparse_categorical_accuracy: 0.6260\n",
      "Epoch 11/30\n",
      "13283/13283 [==============================] - 6s 472us/step - loss: 0.5882 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.8427 - val_sparse_categorical_accuracy: 0.6660\n",
      "Epoch 12/30\n",
      "13283/13283 [==============================] - 6s 486us/step - loss: 0.5916 - sparse_categorical_accuracy: 0.7620 - val_loss: 0.9111 - val_sparse_categorical_accuracy: 0.6667\n",
      "Epoch 13/30\n",
      "13283/13283 [==============================] - 7s 491us/step - loss: 0.5940 - sparse_categorical_accuracy: 0.7577 - val_loss: 0.8769 - val_sparse_categorical_accuracy: 0.6773\n",
      "Epoch 14/30\n",
      "13283/13283 [==============================] - 8s 628us/step - loss: 0.5595 - sparse_categorical_accuracy: 0.7757 - val_loss: 0.7842 - val_sparse_categorical_accuracy: 0.7136\n",
      "Epoch 15/30\n",
      "13283/13283 [==============================] - 6s 473us/step - loss: 0.5574 - sparse_categorical_accuracy: 0.7710 - val_loss: 0.8106 - val_sparse_categorical_accuracy: 0.6854\n",
      "Epoch 16/30\n",
      "13283/13283 [==============================] - 6s 451us/step - loss: 0.5434 - sparse_categorical_accuracy: 0.7796 - val_loss: 1.0606 - val_sparse_categorical_accuracy: 0.6216\n",
      "Epoch 17/30\n",
      "13283/13283 [==============================] - 6s 466us/step - loss: 0.5342 - sparse_categorical_accuracy: 0.7863 - val_loss: 0.8198 - val_sparse_categorical_accuracy: 0.6929\n",
      "Epoch 18/30\n",
      "13283/13283 [==============================] - 6s 461us/step - loss: 0.5195 - sparse_categorical_accuracy: 0.7869 - val_loss: 0.8242 - val_sparse_categorical_accuracy: 0.6998\n",
      "Epoch 19/30\n",
      "13283/13283 [==============================] - 6s 475us/step - loss: 0.4885 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.7910 - val_sparse_categorical_accuracy: 0.7173\n",
      "Epoch 20/30\n",
      "13283/13283 [==============================] - 6s 460us/step - loss: 0.5100 - sparse_categorical_accuracy: 0.7930 - val_loss: 0.7650 - val_sparse_categorical_accuracy: 0.7255\n",
      "Epoch 21/30\n",
      "13283/13283 [==============================] - 9s 699us/step - loss: 0.4891 - sparse_categorical_accuracy: 0.8028 - val_loss: 0.8198 - val_sparse_categorical_accuracy: 0.7129\n",
      "Epoch 22/30\n",
      "13283/13283 [==============================] - 6s 454us/step - loss: 0.4675 - sparse_categorical_accuracy: 0.8106 - val_loss: 0.8230 - val_sparse_categorical_accuracy: 0.7073\n",
      "Epoch 23/30\n",
      "13283/13283 [==============================] - 6s 461us/step - loss: 0.4608 - sparse_categorical_accuracy: 0.8153 - val_loss: 0.8883 - val_sparse_categorical_accuracy: 0.6929\n",
      "Epoch 24/30\n",
      "13283/13283 [==============================] - 6s 448us/step - loss: 0.4440 - sparse_categorical_accuracy: 0.8217 - val_loss: 0.8758 - val_sparse_categorical_accuracy: 0.6723\n",
      "Epoch 25/30\n",
      "13283/13283 [==============================] - 7s 507us/step - loss: 0.4446 - sparse_categorical_accuracy: 0.8186 - val_loss: 0.9703 - val_sparse_categorical_accuracy: 0.6673\n",
      "Epoch 26/30\n",
      "13283/13283 [==============================] - 7s 501us/step - loss: 0.4429 - sparse_categorical_accuracy: 0.8237 - val_loss: 0.8694 - val_sparse_categorical_accuracy: 0.7036\n",
      "Epoch 27/30\n",
      "13283/13283 [==============================] - 6s 483us/step - loss: 0.4167 - sparse_categorical_accuracy: 0.8314 - val_loss: 0.7199 - val_sparse_categorical_accuracy: 0.7436\n",
      "Epoch 28/30\n",
      "13283/13283 [==============================] - 6s 483us/step - loss: 0.4278 - sparse_categorical_accuracy: 0.8275 - val_loss: 0.7611 - val_sparse_categorical_accuracy: 0.7348\n",
      "Epoch 29/30\n",
      "13283/13283 [==============================] - 6s 461us/step - loss: 0.3905 - sparse_categorical_accuracy: 0.8434 - val_loss: 0.7518 - val_sparse_categorical_accuracy: 0.7236\n",
      "Epoch 30/30\n",
      "13283/13283 [==============================] - 6s 471us/step - loss: 0.3949 - sparse_categorical_accuracy: 0.8442 - val_loss: 0.8385 - val_sparse_categorical_accuracy: 0.7061\n",
      "Train on 864 samples, validate on 1657 samples\n",
      "Epoch 1/1\n",
      "864/864 [==============================] - 1s 723us/step - loss: 2.0120 - sparse_categorical_accuracy: 0.7083 - val_loss: 9.2538 - val_sparse_categorical_accuracy: 0.0350\n",
      "Performances after Epoch: 1\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 1.000000\n",
      "Train on 864 samples, validate on 1657 samples\n",
      "Epoch 1/9\n",
      "864/864 [==============================] - 1s 675us/step - loss: 0.0016 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.2166 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 2/9\n",
      "864/864 [==============================] - 1s 732us/step - loss: 5.5989e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.6288 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 3/9\n",
      "864/864 [==============================] - 1s 707us/step - loss: 4.7518e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.7706 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 4/9\n",
      "864/864 [==============================] - 1s 729us/step - loss: 3.9377e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.8547 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 5/9\n",
      "864/864 [==============================] - 1s 785us/step - loss: 3.3607e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.9173 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 6/9\n",
      "864/864 [==============================] - 1s 825us/step - loss: 3.9258e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.9778 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 7/9\n",
      "864/864 [==============================] - 1s 773us/step - loss: 4.1547e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.0399 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 8/9\n",
      "864/864 [==============================] - 1s 804us/step - loss: 3.2239e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.0927 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 9/9\n",
      "864/864 [==============================] - 1s 730us/step - loss: 2.7462e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.1438 - val_sparse_categorical_accuracy: 0.0350\n",
      "Performances after Epoch: 10\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 1.000000\n",
      "Train on 864 samples, validate on 1657 samples\n",
      "Epoch 1/20\n",
      "864/864 [==============================] - 1s 738us/step - loss: 2.9106e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.1956 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 2/20\n",
      "864/864 [==============================] - 1s 740us/step - loss: 2.5293e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.2465 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 1s 761us/step - loss: 3.1004e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.2959 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 4/20\n",
      "864/864 [==============================] - 1s 732us/step - loss: 2.5711e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.3481 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 5/20\n",
      "864/864 [==============================] - 1s 772us/step - loss: 2.4931e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.3971 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 6/20\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 2.3913e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.4453 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 7/20\n",
      "864/864 [==============================] - 1s 982us/step - loss: 1.9979e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.4883 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 8/20\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 2.0274e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.5267 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 9/20\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 1.9825e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.5656 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 10/20\n",
      "864/864 [==============================] - 1s 2ms/step - loss: 2.0171e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.6040 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 11/20\n",
      "864/864 [==============================] - 1s 901us/step - loss: 1.8281e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.6409 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 12/20\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 1.6384e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.6768 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 13/20\n",
      "864/864 [==============================] - 1s 1ms/step - loss: 1.9087e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.7093 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 14/20\n",
      "864/864 [==============================] - 1s 717us/step - loss: 2.0707e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.7477 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 15/20\n",
      "864/864 [==============================] - 1s 777us/step - loss: 1.9914e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.7837 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 16/20\n",
      "864/864 [==============================] - 1s 765us/step - loss: 1.7776e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.8183 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 17/20\n",
      "864/864 [==============================] - 1s 727us/step - loss: 1.4898e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.8513 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 18/20\n",
      "864/864 [==============================] - 1s 670us/step - loss: 1.6279e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.8808 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 19/20\n",
      "864/864 [==============================] - 1s 695us/step - loss: 1.5529e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.9096 - val_sparse_categorical_accuracy: 0.0350\n",
      "Epoch 20/20\n",
      "864/864 [==============================] - 1s 712us/step - loss: 1.4355e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.9375 - val_sparse_categorical_accuracy: 0.0350\n",
      "Performances after Epoch: 30\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 1.000000\n"
     ]
    }
   ],
   "source": [
    "class_num_l = [0,4,8,14,15]\n",
    "\n",
    "class_num_D2=0\n",
    "print(\"==== Adding One More Class ====\")\n",
    "print(\"class num D2: %d\" %(class_num_D2))\n",
    "X_train_D1, y_train_D1, X_train_D2, y_train_D2, X_test_D1, y_test_D1, X_test_D2, y_test_D2 = makeDataD2OneClass(class_num_D2, X_train, y_train, X_test, y_test)\n",
    "model = vanilaLSTMs()\n",
    "model.fit(X_train_D1, y_train_D1, validation_data=(X_test_D1, y_test_D1),\n",
    "                    epochs=30,batch_size=64)\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=1,batch_size=64)\n",
    "print(\"Performances after Epoch: 1\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=9,batch_size=64)\n",
    "print(\"Performances after Epoch: 10\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=20,batch_size=64)\n",
    "print(\"Performances after Epoch: 30\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Adding One More Class ====\n",
      "class num D2: 4\n",
      "Train on 13226 samples, validate on 1429 samples\n",
      "Epoch 1/30\n",
      "13226/13226 [==============================] - 8s 627us/step - loss: 1.7727 - sparse_categorical_accuracy: 0.3808 - val_loss: 1.7145 - val_sparse_categorical_accuracy: 0.4059\n",
      "Epoch 2/30\n",
      "13226/13226 [==============================] - 6s 478us/step - loss: 1.2566 - sparse_categorical_accuracy: 0.5197 - val_loss: 1.5621 - val_sparse_categorical_accuracy: 0.4808\n",
      "Epoch 3/30\n",
      "13226/13226 [==============================] - 6s 482us/step - loss: 1.0273 - sparse_categorical_accuracy: 0.5962 - val_loss: 1.3871 - val_sparse_categorical_accuracy: 0.5122\n",
      "Epoch 4/30\n",
      "13226/13226 [==============================] - 6s 486us/step - loss: 0.9070 - sparse_categorical_accuracy: 0.6412 - val_loss: 1.2353 - val_sparse_categorical_accuracy: 0.5563\n",
      "Epoch 5/30\n",
      "13226/13226 [==============================] - 7s 527us/step - loss: 0.8159 - sparse_categorical_accuracy: 0.6706 - val_loss: 1.1321 - val_sparse_categorical_accuracy: 0.5948\n",
      "Epoch 6/30\n",
      "13226/13226 [==============================] - 6s 478us/step - loss: 0.7644 - sparse_categorical_accuracy: 0.6896 - val_loss: 1.2078 - val_sparse_categorical_accuracy: 0.5794\n",
      "Epoch 7/30\n",
      "13226/13226 [==============================] - 6s 489us/step - loss: 0.7202 - sparse_categorical_accuracy: 0.7137 - val_loss: 1.0239 - val_sparse_categorical_accuracy: 0.6277\n",
      "Epoch 8/30\n",
      "13226/13226 [==============================] - 6s 461us/step - loss: 0.6737 - sparse_categorical_accuracy: 0.7277 - val_loss: 0.9966 - val_sparse_categorical_accuracy: 0.6284\n",
      "Epoch 9/30\n",
      "13226/13226 [==============================] - 6s 458us/step - loss: 0.6364 - sparse_categorical_accuracy: 0.7467 - val_loss: 0.9250 - val_sparse_categorical_accuracy: 0.6536\n",
      "Epoch 10/30\n",
      "13226/13226 [==============================] - 6s 481us/step - loss: 0.6460 - sparse_categorical_accuracy: 0.7410 - val_loss: 0.8811 - val_sparse_categorical_accuracy: 0.6893\n",
      "Epoch 11/30\n",
      "13226/13226 [==============================] - 7s 533us/step - loss: 0.5927 - sparse_categorical_accuracy: 0.7595 - val_loss: 0.8466 - val_sparse_categorical_accuracy: 0.6907\n",
      "Epoch 12/30\n",
      "13226/13226 [==============================] - 9s 683us/step - loss: 0.6041 - sparse_categorical_accuracy: 0.7631 - val_loss: 1.0161 - val_sparse_categorical_accuracy: 0.6655\n",
      "Epoch 13/30\n",
      "13226/13226 [==============================] - 8s 581us/step - loss: 0.5748 - sparse_categorical_accuracy: 0.7699 - val_loss: 0.8233 - val_sparse_categorical_accuracy: 0.7012\n",
      "Epoch 14/30\n",
      "13226/13226 [==============================] - 6s 484us/step - loss: 0.5482 - sparse_categorical_accuracy: 0.7773 - val_loss: 0.7937 - val_sparse_categorical_accuracy: 0.6949\n",
      "Epoch 15/30\n",
      "13226/13226 [==============================] - 7s 518us/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7840 - val_loss: 0.8969 - val_sparse_categorical_accuracy: 0.7159\n",
      "Epoch 16/30\n",
      "13226/13226 [==============================] - 7s 512us/step - loss: 0.5365 - sparse_categorical_accuracy: 0.7860 - val_loss: 0.7531 - val_sparse_categorical_accuracy: 0.7222\n",
      "Epoch 17/30\n",
      "13226/13226 [==============================] - 7s 525us/step - loss: 0.5182 - sparse_categorical_accuracy: 0.7967 - val_loss: 0.7495 - val_sparse_categorical_accuracy: 0.7306\n",
      "Epoch 18/30\n",
      "13226/13226 [==============================] - 8s 623us/step - loss: 0.5027 - sparse_categorical_accuracy: 0.7987 - val_loss: 0.8079 - val_sparse_categorical_accuracy: 0.7327\n",
      "Epoch 19/30\n",
      "13226/13226 [==============================] - 8s 640us/step - loss: 0.4824 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.8582 - val_sparse_categorical_accuracy: 0.6998\n",
      "Epoch 20/30\n",
      "13226/13226 [==============================] - 6s 484us/step - loss: 0.4781 - sparse_categorical_accuracy: 0.8141 - val_loss: 0.9568 - val_sparse_categorical_accuracy: 0.6487\n",
      "Epoch 21/30\n",
      "13226/13226 [==============================] - 6s 489us/step - loss: 0.4733 - sparse_categorical_accuracy: 0.8148 - val_loss: 0.6741 - val_sparse_categorical_accuracy: 0.7495\n",
      "Epoch 22/30\n",
      "13226/13226 [==============================] - 9s 647us/step - loss: 0.4628 - sparse_categorical_accuracy: 0.8164 - val_loss: 0.7683 - val_sparse_categorical_accuracy: 0.7089\n",
      "Epoch 23/30\n",
      "13226/13226 [==============================] - 7s 532us/step - loss: 0.4317 - sparse_categorical_accuracy: 0.8331 - val_loss: 0.8502 - val_sparse_categorical_accuracy: 0.7068\n",
      "Epoch 24/30\n",
      "13226/13226 [==============================] - 7s 493us/step - loss: 0.4450 - sparse_categorical_accuracy: 0.8246 - val_loss: 0.6478 - val_sparse_categorical_accuracy: 0.7719\n",
      "Epoch 25/30\n",
      "13226/13226 [==============================] - 7s 495us/step - loss: 0.4222 - sparse_categorical_accuracy: 0.8326 - val_loss: 0.6998 - val_sparse_categorical_accuracy: 0.7551\n",
      "Epoch 26/30\n",
      "13226/13226 [==============================] - 6s 476us/step - loss: 0.4235 - sparse_categorical_accuracy: 0.8322 - val_loss: 0.7700 - val_sparse_categorical_accuracy: 0.7320\n",
      "Epoch 27/30\n",
      "13226/13226 [==============================] - 7s 499us/step - loss: 0.3930 - sparse_categorical_accuracy: 0.8439 - val_loss: 0.7072 - val_sparse_categorical_accuracy: 0.7572\n",
      "Epoch 28/30\n",
      "13226/13226 [==============================] - 6s 474us/step - loss: 0.3993 - sparse_categorical_accuracy: 0.8436 - val_loss: 0.8025 - val_sparse_categorical_accuracy: 0.7201\n",
      "Epoch 29/30\n",
      "13226/13226 [==============================] - 6s 478us/step - loss: 0.3913 - sparse_categorical_accuracy: 0.8455 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.7593\n",
      "Epoch 30/30\n",
      "13226/13226 [==============================] - 6s 488us/step - loss: 0.3815 - sparse_categorical_accuracy: 0.8510 - val_loss: 0.7432 - val_sparse_categorical_accuracy: 0.7600\n",
      "Train on 921 samples, validate on 1657 samples\n",
      "Epoch 1/1\n",
      "921/921 [==============================] - 1s 684us/step - loss: 1.9974 - sparse_categorical_accuracy: 0.7492 - val_loss: 8.0572 - val_sparse_categorical_accuracy: 0.1376\n",
      "Performances after Epoch: 1\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 1.000000\n",
      "Train on 921 samples, validate on 1657 samples\n",
      "Epoch 1/9\n",
      "921/921 [==============================] - 1s 724us/step - loss: 0.0030 - sparse_categorical_accuracy: 1.0000 - val_loss: 9.0869 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 2/9\n",
      "921/921 [==============================] - 1s 748us/step - loss: 0.0024 - sparse_categorical_accuracy: 1.0000 - val_loss: 9.3425 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 3/9\n",
      "921/921 [==============================] - 1s 695us/step - loss: 0.0016 - sparse_categorical_accuracy: 1.0000 - val_loss: 9.4836 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 4/9\n",
      "921/921 [==============================] - 1s 688us/step - loss: 0.0011 - sparse_categorical_accuracy: 1.0000 - val_loss: 9.5806 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 5/9\n",
      "921/921 [==============================] - 1s 712us/step - loss: 0.0014 - sparse_categorical_accuracy: 1.0000 - val_loss: 9.6710 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 6/9\n",
      "921/921 [==============================] - 1s 714us/step - loss: 9.8672e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 9.7535 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 7/9\n",
      "921/921 [==============================] - 1s 781us/step - loss: 8.9354e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 9.8200 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 8/9\n",
      "921/921 [==============================] - 1s 728us/step - loss: 8.9586e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 9.8877 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 9/9\n",
      "921/921 [==============================] - 1s 705us/step - loss: 7.8898e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 9.9493 - val_sparse_categorical_accuracy: 0.1376\n",
      "Performances after Epoch: 10\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 1.000000\n",
      "Train on 921 samples, validate on 1657 samples\n",
      "Epoch 1/20\n",
      "921/921 [==============================] - 1s 725us/step - loss: 6.7011e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.0043 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 2/20\n",
      "921/921 [==============================] - 1s 730us/step - loss: 7.4133e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.0587 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "921/921 [==============================] - 1s 730us/step - loss: 6.7769e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.1094 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 4/20\n",
      "921/921 [==============================] - 1s 786us/step - loss: 6.3183e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.1591 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 5/20\n",
      "921/921 [==============================] - 1s 745us/step - loss: 5.7292e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.2032 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 6/20\n",
      "921/921 [==============================] - 1s 738us/step - loss: 5.4355e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.2437 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 7/20\n",
      "921/921 [==============================] - 1s 672us/step - loss: 5.0584e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.2797 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 8/20\n",
      "921/921 [==============================] - 1s 741us/step - loss: 5.1744e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.3191 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 9/20\n",
      "921/921 [==============================] - 1s 701us/step - loss: 5.9136e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.3582 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 10/20\n",
      "921/921 [==============================] - 1s 693us/step - loss: 4.5566e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.3947 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 11/20\n",
      "921/921 [==============================] - 1s 737us/step - loss: 4.3761e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.4307 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 12/20\n",
      "921/921 [==============================] - 1s 714us/step - loss: 4.1139e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.4646 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 13/20\n",
      "921/921 [==============================] - 1s 695us/step - loss: 3.9002e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.4969 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 14/20\n",
      "921/921 [==============================] - 1s 703us/step - loss: 4.1496e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.5288 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 15/20\n",
      "921/921 [==============================] - 1s 760us/step - loss: 4.1721e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.5611 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 16/20\n",
      "921/921 [==============================] - 1s 763us/step - loss: 3.4267e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.5902 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 17/20\n",
      "921/921 [==============================] - 1s 822us/step - loss: 3.4441e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.6190 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 18/20\n",
      "921/921 [==============================] - 1s 790us/step - loss: 3.5112e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.6463 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 19/20\n",
      "921/921 [==============================] - 1s 788us/step - loss: 3.1557e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.6733 - val_sparse_categorical_accuracy: 0.1376\n",
      "Epoch 20/20\n",
      "921/921 [==============================] - 1s 1ms/step - loss: 3.5619e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.7004 - val_sparse_categorical_accuracy: 0.1376\n",
      "Performances after Epoch: 30\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 1.000000\n"
     ]
    }
   ],
   "source": [
    "class_num_D2=4\n",
    "print(\"==== Adding One More Class ====\")\n",
    "print(\"class num D2: %d\" %(class_num_D2))\n",
    "X_train_D1, y_train_D1, X_train_D2, y_train_D2, X_test_D1, y_test_D1, X_test_D2, y_test_D2 = makeDataD2OneClass(class_num_D2, X_train, y_train, X_test, y_test)\n",
    "model = vanilaLSTMs()\n",
    "model.fit(X_train_D1, y_train_D1, validation_data=(X_test_D1, y_test_D1),\n",
    "                    epochs=30,batch_size=64)\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=1,batch_size=64)\n",
    "print(\"Performances after Epoch: 1\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=9,batch_size=64)\n",
    "print(\"Performances after Epoch: 10\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=20,batch_size=64)\n",
    "print(\"Performances after Epoch: 30\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Adding One More Class ====\n",
      "class num D2: 8\n",
      "Train on 13657 samples, validate on 1618 samples\n",
      "Epoch 1/30\n",
      "13657/13657 [==============================] - 9s 646us/step - loss: 1.6986 - sparse_categorical_accuracy: 0.3996 - val_loss: 1.6807 - val_sparse_categorical_accuracy: 0.4178\n",
      "Epoch 2/30\n",
      "13657/13657 [==============================] - 7s 500us/step - loss: 1.1956 - sparse_categorical_accuracy: 0.5304 - val_loss: 1.5508 - val_sparse_categorical_accuracy: 0.4821\n",
      "Epoch 3/30\n",
      "13657/13657 [==============================] - 7s 484us/step - loss: 1.0070 - sparse_categorical_accuracy: 0.5961 - val_loss: 1.4518 - val_sparse_categorical_accuracy: 0.4623\n",
      "Epoch 4/30\n",
      "13657/13657 [==============================] - 7s 495us/step - loss: 0.9078 - sparse_categorical_accuracy: 0.6339 - val_loss: 1.2189 - val_sparse_categorical_accuracy: 0.5389\n",
      "Epoch 5/30\n",
      "13657/13657 [==============================] - 7s 546us/step - loss: 0.8275 - sparse_categorical_accuracy: 0.6616 - val_loss: 1.2853 - val_sparse_categorical_accuracy: 0.5482\n",
      "Epoch 6/30\n",
      "13657/13657 [==============================] - 8s 606us/step - loss: 0.7687 - sparse_categorical_accuracy: 0.6832 - val_loss: 1.0712 - val_sparse_categorical_accuracy: 0.5970\n",
      "Epoch 7/30\n",
      "13657/13657 [==============================] - 7s 493us/step - loss: 0.7336 - sparse_categorical_accuracy: 0.7020 - val_loss: 1.0932 - val_sparse_categorical_accuracy: 0.5964\n",
      "Epoch 8/30\n",
      "13657/13657 [==============================] - 9s 638us/step - loss: 0.6876 - sparse_categorical_accuracy: 0.7223 - val_loss: 1.1031 - val_sparse_categorical_accuracy: 0.5692\n",
      "Epoch 9/30\n",
      "13657/13657 [==============================] - 7s 493us/step - loss: 0.6522 - sparse_categorical_accuracy: 0.7382 - val_loss: 1.0305 - val_sparse_categorical_accuracy: 0.6026\n",
      "Epoch 10/30\n",
      "13657/13657 [==============================] - 7s 503us/step - loss: 0.6112 - sparse_categorical_accuracy: 0.7508 - val_loss: 1.0608 - val_sparse_categorical_accuracy: 0.6199\n",
      "Epoch 11/30\n",
      "13657/13657 [==============================] - 7s 492us/step - loss: 0.6046 - sparse_categorical_accuracy: 0.7547 - val_loss: 0.8163 - val_sparse_categorical_accuracy: 0.6972\n",
      "Epoch 12/30\n",
      "13657/13657 [==============================] - 6s 470us/step - loss: 0.5478 - sparse_categorical_accuracy: 0.7754 - val_loss: 0.8864 - val_sparse_categorical_accuracy: 0.6496\n",
      "Epoch 13/30\n",
      "13657/13657 [==============================] - 6s 472us/step - loss: 0.5620 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.8620 - val_sparse_categorical_accuracy: 0.6712\n",
      "Epoch 14/30\n",
      "13657/13657 [==============================] - 6s 473us/step - loss: 0.5287 - sparse_categorical_accuracy: 0.7861 - val_loss: 0.8332 - val_sparse_categorical_accuracy: 0.6823\n",
      "Epoch 15/30\n",
      "13657/13657 [==============================] - 7s 513us/step - loss: 0.5181 - sparse_categorical_accuracy: 0.7904 - val_loss: 0.7666 - val_sparse_categorical_accuracy: 0.7231\n",
      "Epoch 16/30\n",
      "13657/13657 [==============================] - 7s 518us/step - loss: 0.4987 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.8258 - val_sparse_categorical_accuracy: 0.6811\n",
      "Epoch 17/30\n",
      "13657/13657 [==============================] - 8s 599us/step - loss: 0.4911 - sparse_categorical_accuracy: 0.8043 - val_loss: 1.0043 - val_sparse_categorical_accuracy: 0.6533\n",
      "Epoch 18/30\n",
      "13657/13657 [==============================] - 7s 517us/step - loss: 0.4672 - sparse_categorical_accuracy: 0.8104 - val_loss: 0.8924 - val_sparse_categorical_accuracy: 0.6842\n",
      "Epoch 19/30\n",
      "13657/13657 [==============================] - 7s 488us/step - loss: 0.4477 - sparse_categorical_accuracy: 0.8208 - val_loss: 0.7734 - val_sparse_categorical_accuracy: 0.7194\n",
      "Epoch 20/30\n",
      "13657/13657 [==============================] - 8s 560us/step - loss: 0.4663 - sparse_categorical_accuracy: 0.8146 - val_loss: 0.8190 - val_sparse_categorical_accuracy: 0.7151\n",
      "Epoch 21/30\n",
      "13657/13657 [==============================] - 7s 479us/step - loss: 0.4241 - sparse_categorical_accuracy: 0.8301 - val_loss: 0.7841 - val_sparse_categorical_accuracy: 0.7169\n",
      "Epoch 22/30\n",
      "13657/13657 [==============================] - 7s 520us/step - loss: 0.4453 - sparse_categorical_accuracy: 0.8215 - val_loss: 0.8671 - val_sparse_categorical_accuracy: 0.7021\n",
      "Epoch 23/30\n",
      "13657/13657 [==============================] - 8s 559us/step - loss: 0.4226 - sparse_categorical_accuracy: 0.8278 - val_loss: 0.7098 - val_sparse_categorical_accuracy: 0.7454\n",
      "Epoch 24/30\n",
      "13657/13657 [==============================] - 7s 484us/step - loss: 0.4043 - sparse_categorical_accuracy: 0.8391 - val_loss: 0.7511 - val_sparse_categorical_accuracy: 0.7373\n",
      "Epoch 25/30\n",
      "13657/13657 [==============================] - 6s 475us/step - loss: 0.3996 - sparse_categorical_accuracy: 0.8393 - val_loss: 0.7257 - val_sparse_categorical_accuracy: 0.7404\n",
      "Epoch 26/30\n",
      "13657/13657 [==============================] - 7s 521us/step - loss: 0.3981 - sparse_categorical_accuracy: 0.8399 - val_loss: 0.9181 - val_sparse_categorical_accuracy: 0.6737\n",
      "Epoch 27/30\n",
      "13657/13657 [==============================] - 7s 518us/step - loss: 0.4032 - sparse_categorical_accuracy: 0.8422 - val_loss: 0.7353 - val_sparse_categorical_accuracy: 0.7349\n",
      "Epoch 28/30\n",
      "13657/13657 [==============================] - 6s 476us/step - loss: 0.3882 - sparse_categorical_accuracy: 0.8458 - val_loss: 0.7396 - val_sparse_categorical_accuracy: 0.7497\n",
      "Epoch 29/30\n",
      "13657/13657 [==============================] - 7s 503us/step - loss: 0.3519 - sparse_categorical_accuracy: 0.8605 - val_loss: 0.6879 - val_sparse_categorical_accuracy: 0.7596\n",
      "Epoch 30/30\n",
      "13657/13657 [==============================] - 7s 476us/step - loss: 0.3564 - sparse_categorical_accuracy: 0.8554 - val_loss: 0.8035 - val_sparse_categorical_accuracy: 0.7083\n",
      "Train on 490 samples, validate on 1657 samples\n",
      "Epoch 1/1\n",
      "490/490 [==============================] - 0s 894us/step - loss: 2.7055 - sparse_categorical_accuracy: 0.5857 - val_loss: 5.3533 - val_sparse_categorical_accuracy: 0.0235\n",
      "Performances after Epoch: 1\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 1.000000\n",
      "Train on 490 samples, validate on 1657 samples\n",
      "Epoch 1/9\n",
      "490/490 [==============================] - 1s 1ms/step - loss: 0.0293 - sparse_categorical_accuracy: 1.0000 - val_loss: 8.3867 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 2/9\n",
      "490/490 [==============================] - 1s 1ms/step - loss: 0.0047 - sparse_categorical_accuracy: 1.0000 - val_loss: 9.6340 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 3/9\n",
      "490/490 [==============================] - 1s 1ms/step - loss: 0.0021 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.2032 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 4/9\n",
      "490/490 [==============================] - 0s 958us/step - loss: 0.0016 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.4896 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 5/9\n",
      "490/490 [==============================] - 0s 1ms/step - loss: 0.0013 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.6541 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 6/9\n",
      "490/490 [==============================] - 1s 1ms/step - loss: 0.0012 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.7651 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 7/9\n",
      "490/490 [==============================] - 1s 1ms/step - loss: 8.6759e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.8439 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 8/9\n",
      "490/490 [==============================] - 0s 1ms/step - loss: 7.5527e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.9046 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 9/9\n",
      "490/490 [==============================] - 0s 1ms/step - loss: 7.6534e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.9570 - val_sparse_categorical_accuracy: 0.0235\n",
      "Performances after Epoch: 10\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 1.000000\n",
      "Train on 490 samples, validate on 1657 samples\n",
      "Epoch 1/20\n",
      "490/490 [==============================] - 0s 1ms/step - loss: 8.6311e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.0066 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 2/20\n",
      "490/490 [==============================] - 0s 907us/step - loss: 7.0978e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.0520 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490/490 [==============================] - 0s 908us/step - loss: 7.3538e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.0971 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 4/20\n",
      "490/490 [==============================] - 0s 858us/step - loss: 7.6480e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.1415 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 5/20\n",
      "490/490 [==============================] - 0s 930us/step - loss: 6.2557e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.1832 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 6/20\n",
      "490/490 [==============================] - 0s 904us/step - loss: 6.9739e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.2245 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 7/20\n",
      "490/490 [==============================] - 0s 903us/step - loss: 6.8222e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.2642 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 8/20\n",
      "490/490 [==============================] - 0s 876us/step - loss: 6.3405e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.3022 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 9/20\n",
      "490/490 [==============================] - 0s 943us/step - loss: 5.2825e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.3377 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 10/20\n",
      "490/490 [==============================] - 0s 847us/step - loss: 5.2409e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.3705 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 11/20\n",
      "490/490 [==============================] - 0s 999us/step - loss: 5.3320e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.4022 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 12/20\n",
      "490/490 [==============================] - 0s 854us/step - loss: 6.0217e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.4339 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 13/20\n",
      "490/490 [==============================] - 0s 921us/step - loss: 5.6914e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.4673 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 14/20\n",
      "490/490 [==============================] - 0s 919us/step - loss: 5.3219e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.4990 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 15/20\n",
      "490/490 [==============================] - 0s 940us/step - loss: 4.9369e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.5304 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 16/20\n",
      "490/490 [==============================] - 0s 937us/step - loss: 5.3632e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.5615 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 17/20\n",
      "490/490 [==============================] - 0s 910us/step - loss: 4.0596e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.5893 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 18/20\n",
      "490/490 [==============================] - 0s 899us/step - loss: 7.2222e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.6192 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 19/20\n",
      "490/490 [==============================] - 0s 867us/step - loss: 3.7748e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.6472 - val_sparse_categorical_accuracy: 0.0235\n",
      "Epoch 20/20\n",
      "490/490 [==============================] - 0s 970us/step - loss: 4.0959e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.6723 - val_sparse_categorical_accuracy: 0.0235\n",
      "Performances after Epoch: 30\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 1.000000\n"
     ]
    }
   ],
   "source": [
    "class_num_D2=8\n",
    "print(\"==== Adding One More Class ====\")\n",
    "print(\"class num D2: %d\" %(class_num_D2))\n",
    "X_train_D1, y_train_D1, X_train_D2, y_train_D2, X_test_D1, y_test_D1, X_test_D2, y_test_D2 = makeDataD2OneClass(class_num_D2, X_train, y_train, X_test, y_test)\n",
    "model = vanilaLSTMs()\n",
    "model.fit(X_train_D1, y_train_D1, validation_data=(X_test_D1, y_test_D1),\n",
    "                    epochs=30,batch_size=64)\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=1,batch_size=64)\n",
    "print(\"Performances after Epoch: 1\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=9,batch_size=64)\n",
    "print(\"Performances after Epoch: 10\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=20,batch_size=64)\n",
    "print(\"Performances after Epoch: 30\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Adding One More Class ====\n",
      "class num D2: 14\n",
      "Train on 13243 samples, validate on 1558 samples\n",
      "Epoch 1/30\n",
      "13243/13243 [==============================] - 10s 720us/step - loss: 1.7785 - sparse_categorical_accuracy: 0.3828 - val_loss: 1.8131 - val_sparse_categorical_accuracy: 0.3780\n",
      "Epoch 2/30\n",
      "13243/13243 [==============================] - 7s 521us/step - loss: 1.3089 - sparse_categorical_accuracy: 0.4981 - val_loss: 1.5351 - val_sparse_categorical_accuracy: 0.4551\n",
      "Epoch 3/30\n",
      "13243/13243 [==============================] - 7s 530us/step - loss: 1.1219 - sparse_categorical_accuracy: 0.5589 - val_loss: 1.4606 - val_sparse_categorical_accuracy: 0.4775\n",
      "Epoch 4/30\n",
      "13243/13243 [==============================] - 8s 616us/step - loss: 1.0026 - sparse_categorical_accuracy: 0.5977 - val_loss: 1.1855 - val_sparse_categorical_accuracy: 0.5385\n",
      "Epoch 5/30\n",
      "13243/13243 [==============================] - 14s 1ms/step - loss: 0.9269 - sparse_categorical_accuracy: 0.6181 - val_loss: 1.2497 - val_sparse_categorical_accuracy: 0.5334\n",
      "Epoch 6/30\n",
      "13243/13243 [==============================] - 17s 1ms/step - loss: 0.8355 - sparse_categorical_accuracy: 0.6520 - val_loss: 1.0802 - val_sparse_categorical_accuracy: 0.5623\n",
      "Epoch 7/30\n",
      "13243/13243 [==============================] - 14s 1ms/step - loss: 0.8046 - sparse_categorical_accuracy: 0.6726 - val_loss: 1.0390 - val_sparse_categorical_accuracy: 0.5931\n",
      "Epoch 8/30\n",
      "13243/13243 [==============================] - 15s 1ms/step - loss: 0.7654 - sparse_categorical_accuracy: 0.6810 - val_loss: 1.0374 - val_sparse_categorical_accuracy: 0.6245\n",
      "Epoch 9/30\n",
      "13243/13243 [==============================] - 14s 1ms/step - loss: 0.7498 - sparse_categorical_accuracy: 0.6992 - val_loss: 1.0241 - val_sparse_categorical_accuracy: 0.6130\n",
      "Epoch 10/30\n",
      "13243/13243 [==============================] - 15s 1ms/step - loss: 0.6934 - sparse_categorical_accuracy: 0.7131 - val_loss: 0.9962 - val_sparse_categorical_accuracy: 0.6245\n",
      "Epoch 11/30\n",
      "13243/13243 [==============================] - 16s 1ms/step - loss: 0.7039 - sparse_categorical_accuracy: 0.7156 - val_loss: 0.8933 - val_sparse_categorical_accuracy: 0.6682\n",
      "Epoch 12/30\n",
      "13243/13243 [==============================] - 13s 970us/step - loss: 0.6696 - sparse_categorical_accuracy: 0.7246 - val_loss: 0.9713 - val_sparse_categorical_accuracy: 0.6335\n",
      "Epoch 13/30\n",
      "13243/13243 [==============================] - 13s 958us/step - loss: 0.6374 - sparse_categorical_accuracy: 0.7348 - val_loss: 1.1182 - val_sparse_categorical_accuracy: 0.5700\n",
      "Epoch 14/30\n",
      "13243/13243 [==============================] - 13s 965us/step - loss: 0.6239 - sparse_categorical_accuracy: 0.7439 - val_loss: 1.1319 - val_sparse_categorical_accuracy: 0.5918\n",
      "Epoch 15/30\n",
      "13243/13243 [==============================] - 12s 920us/step - loss: 0.5987 - sparse_categorical_accuracy: 0.7532 - val_loss: 0.8706 - val_sparse_categorical_accuracy: 0.6772\n",
      "Epoch 16/30\n",
      "13243/13243 [==============================] - 14s 1ms/step - loss: 0.5840 - sparse_categorical_accuracy: 0.7627 - val_loss: 0.8644 - val_sparse_categorical_accuracy: 0.6727\n",
      "Epoch 17/30\n",
      "13243/13243 [==============================] - 15s 1ms/step - loss: 0.5812 - sparse_categorical_accuracy: 0.7640 - val_loss: 0.8184 - val_sparse_categorical_accuracy: 0.6983\n",
      "Epoch 18/30\n",
      "13243/13243 [==============================] - 11s 839us/step - loss: 0.5448 - sparse_categorical_accuracy: 0.7842 - val_loss: 0.8928 - val_sparse_categorical_accuracy: 0.6816\n",
      "Epoch 19/30\n",
      "13243/13243 [==============================] - 12s 894us/step - loss: 0.5422 - sparse_categorical_accuracy: 0.7809 - val_loss: 0.7860 - val_sparse_categorical_accuracy: 0.7195\n",
      "Epoch 20/30\n",
      "13243/13243 [==============================] - 12s 936us/step - loss: 0.5371 - sparse_categorical_accuracy: 0.7825 - val_loss: 0.8726 - val_sparse_categorical_accuracy: 0.6919\n",
      "Epoch 21/30\n",
      "13243/13243 [==============================] - 15s 1ms/step - loss: 0.5106 - sparse_categorical_accuracy: 0.7957 - val_loss: 0.8736 - val_sparse_categorical_accuracy: 0.6797\n",
      "Epoch 22/30\n",
      "13243/13243 [==============================] - 12s 929us/step - loss: 0.5060 - sparse_categorical_accuracy: 0.7982 - val_loss: 0.8545 - val_sparse_categorical_accuracy: 0.6842\n",
      "Epoch 23/30\n",
      "13243/13243 [==============================] - 15s 1ms/step - loss: 0.4891 - sparse_categorical_accuracy: 0.8077 - val_loss: 0.8658 - val_sparse_categorical_accuracy: 0.6970\n",
      "Epoch 24/30\n",
      "13243/13243 [==============================] - 15s 1ms/step - loss: 0.4694 - sparse_categorical_accuracy: 0.8106 - val_loss: 0.8666 - val_sparse_categorical_accuracy: 0.7003\n",
      "Epoch 25/30\n",
      "13243/13243 [==============================] - 13s 960us/step - loss: 0.4620 - sparse_categorical_accuracy: 0.8168 - val_loss: 0.7659 - val_sparse_categorical_accuracy: 0.7420\n",
      "Epoch 26/30\n",
      "13243/13243 [==============================] - 13s 958us/step - loss: 0.4595 - sparse_categorical_accuracy: 0.8181 - val_loss: 0.9366 - val_sparse_categorical_accuracy: 0.6874\n",
      "Epoch 27/30\n",
      "13243/13243 [==============================] - 13s 944us/step - loss: 0.4499 - sparse_categorical_accuracy: 0.8230 - val_loss: 0.7992 - val_sparse_categorical_accuracy: 0.7266\n",
      "Epoch 28/30\n",
      "13243/13243 [==============================] - 15s 1ms/step - loss: 0.4350 - sparse_categorical_accuracy: 0.8281 - val_loss: 0.7755 - val_sparse_categorical_accuracy: 0.7291\n",
      "Epoch 29/30\n",
      "13243/13243 [==============================] - 13s 1ms/step - loss: 0.4247 - sparse_categorical_accuracy: 0.8326 - val_loss: 0.7781 - val_sparse_categorical_accuracy: 0.7343\n",
      "Epoch 30/30\n",
      "13243/13243 [==============================] - 15s 1ms/step - loss: 0.4040 - sparse_categorical_accuracy: 0.8416 - val_loss: 0.8474 - val_sparse_categorical_accuracy: 0.7125\n",
      "Train on 904 samples, validate on 1657 samples\n",
      "Epoch 1/1\n",
      "904/904 [==============================] - 2s 2ms/step - loss: 1.6273 - sparse_categorical_accuracy: 0.7290 - val_loss: 9.2843 - val_sparse_categorical_accuracy: 0.0597\n",
      "Performances after Epoch: 1\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 1.000000\n",
      "Train on 904 samples, validate on 1657 samples\n",
      "Epoch 1/9\n",
      "904/904 [==============================] - 2s 2ms/step - loss: 0.0010 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.9253 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 2/9\n",
      "904/904 [==============================] - 2s 2ms/step - loss: 4.3814e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.2606 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 3/9\n",
      "904/904 [==============================] - 2s 2ms/step - loss: 2.9938e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.3558 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 4/9\n",
      "904/904 [==============================] - 2s 2ms/step - loss: 2.8053e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.4020 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 5/9\n",
      "904/904 [==============================] - 1s 2ms/step - loss: 3.2187e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.4386 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 6/9\n",
      "904/904 [==============================] - 1s 2ms/step - loss: 2.4688e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.4725 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 7/9\n",
      "904/904 [==============================] - 2s 2ms/step - loss: 3.2767e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.5086 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 8/9\n",
      "904/904 [==============================] - 2s 2ms/step - loss: 2.5343e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.5420 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 9/9\n",
      "904/904 [==============================] - 1s 1ms/step - loss: 2.5801e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.5724 - val_sparse_categorical_accuracy: 0.0597\n",
      "Performances after Epoch: 10\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 1.000000\n",
      "Train on 904 samples, validate on 1657 samples\n",
      "Epoch 1/20\n",
      "904/904 [==============================] - 2s 2ms/step - loss: 2.2887e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.6017 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 2/20\n",
      "904/904 [==============================] - 2s 2ms/step - loss: 2.4109e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.6306 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "904/904 [==============================] - 2s 2ms/step - loss: 2.3719e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.6586 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 4/20\n",
      "904/904 [==============================] - 2s 2ms/step - loss: 2.4051e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.6867 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 5/20\n",
      "904/904 [==============================] - 2s 2ms/step - loss: 1.9773e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.7144 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 6/20\n",
      "904/904 [==============================] - 2s 2ms/step - loss: 1.8719e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.7400 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 7/20\n",
      "904/904 [==============================] - 2s 2ms/step - loss: 1.8330e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.7647 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 8/20\n",
      "904/904 [==============================] - 1s 2ms/step - loss: 1.9135e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.7888 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 9/20\n",
      "904/904 [==============================] - 2s 2ms/step - loss: 2.0432e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.8148 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 10/20\n",
      "904/904 [==============================] - 1s 1ms/step - loss: 1.9563e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.8416 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 11/20\n",
      "904/904 [==============================] - 1s 1ms/step - loss: 1.7942e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.8666 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 12/20\n",
      "904/904 [==============================] - 2s 2ms/step - loss: 1.6833e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.8942 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 13/20\n",
      "904/904 [==============================] - 2s 2ms/step - loss: 1.6359e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.9171 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 14/20\n",
      "904/904 [==============================] - 2s 2ms/step - loss: 2.1614e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.9425 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 15/20\n",
      "904/904 [==============================] - 1s 2ms/step - loss: 1.7141e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.9687 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 16/20\n",
      "904/904 [==============================] - 1s 2ms/step - loss: 1.6684e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 11.9925 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 17/20\n",
      "904/904 [==============================] - 2s 2ms/step - loss: 1.7806e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.0169 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 18/20\n",
      "904/904 [==============================] - 1s 2ms/step - loss: 1.3871e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.0388 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 19/20\n",
      "904/904 [==============================] - 1s 1ms/step - loss: 1.4464e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.0601 - val_sparse_categorical_accuracy: 0.0597\n",
      "Epoch 20/20\n",
      "904/904 [==============================] - 1s 1ms/step - loss: 1.3986e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 12.0807 - val_sparse_categorical_accuracy: 0.0597\n",
      "Performances after Epoch: 30\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 1.000000\n"
     ]
    }
   ],
   "source": [
    "class_num_D2=14\n",
    "print(\"==== Adding One More Class ====\")\n",
    "print(\"class num D2: %d\" %(class_num_D2))\n",
    "X_train_D1, y_train_D1, X_train_D2, y_train_D2, X_test_D1, y_test_D1, X_test_D2, y_test_D2 = makeDataD2OneClass(class_num_D2, X_train, y_train, X_test, y_test)\n",
    "model = vanilaLSTMs()\n",
    "model.fit(X_train_D1, y_train_D1, validation_data=(X_test_D1, y_test_D1),\n",
    "                    epochs=30,batch_size=64)\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=1,batch_size=64)\n",
    "print(\"Performances after Epoch: 1\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=9,batch_size=64)\n",
    "print(\"Performances after Epoch: 10\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=20,batch_size=64)\n",
    "print(\"Performances after Epoch: 30\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Adding One More Class ====\n",
      "class num D2: 15\n",
      "Train on 10901 samples, validate on 1340 samples\n",
      "Epoch 1/30\n",
      "10901/10901 [==============================] - 14s 1ms/step - loss: 2.0221 - sparse_categorical_accuracy: 0.2545 - val_loss: 1.6792 - val_sparse_categorical_accuracy: 0.3851\n",
      "Epoch 2/30\n",
      "10901/10901 [==============================] - 11s 1ms/step - loss: 1.5555 - sparse_categorical_accuracy: 0.3919 - val_loss: 1.4610 - val_sparse_categorical_accuracy: 0.3963\n",
      "Epoch 3/30\n",
      "10901/10901 [==============================] - 9s 838us/step - loss: 1.3181 - sparse_categorical_accuracy: 0.4665 - val_loss: 1.6257 - val_sparse_categorical_accuracy: 0.3590\n",
      "Epoch 4/30\n",
      "10901/10901 [==============================] - 10s 917us/step - loss: 1.1543 - sparse_categorical_accuracy: 0.5303 - val_loss: 1.3017 - val_sparse_categorical_accuracy: 0.4813\n",
      "Epoch 5/30\n",
      "10901/10901 [==============================] - 11s 968us/step - loss: 1.0803 - sparse_categorical_accuracy: 0.5497 - val_loss: 1.2055 - val_sparse_categorical_accuracy: 0.4940\n",
      "Epoch 6/30\n",
      "10901/10901 [==============================] - 10s 896us/step - loss: 0.9798 - sparse_categorical_accuracy: 0.5887 - val_loss: 1.2321 - val_sparse_categorical_accuracy: 0.5097\n",
      "Epoch 7/30\n",
      "10901/10901 [==============================] - 11s 966us/step - loss: 0.9619 - sparse_categorical_accuracy: 0.5972 - val_loss: 1.2456 - val_sparse_categorical_accuracy: 0.5537\n",
      "Epoch 8/30\n",
      "10901/10901 [==============================] - 11s 979us/step - loss: 0.9026 - sparse_categorical_accuracy: 0.6232 - val_loss: 1.2859 - val_sparse_categorical_accuracy: 0.5127\n",
      "Epoch 9/30\n",
      "10901/10901 [==============================] - 11s 1ms/step - loss: 0.8590 - sparse_categorical_accuracy: 0.6431 - val_loss: 1.0291 - val_sparse_categorical_accuracy: 0.5843\n",
      "Epoch 10/30\n",
      "10901/10901 [==============================] - 12s 1ms/step - loss: 0.8478 - sparse_categorical_accuracy: 0.6585 - val_loss: 1.0448 - val_sparse_categorical_accuracy: 0.6022\n",
      "Epoch 11/30\n",
      "10901/10901 [==============================] - 10s 907us/step - loss: 0.8033 - sparse_categorical_accuracy: 0.6698 - val_loss: 1.0212 - val_sparse_categorical_accuracy: 0.5955\n",
      "Epoch 12/30\n",
      "10901/10901 [==============================] - 9s 829us/step - loss: 0.7898 - sparse_categorical_accuracy: 0.6704 - val_loss: 1.1750 - val_sparse_categorical_accuracy: 0.5731\n",
      "Epoch 13/30\n",
      "10901/10901 [==============================] - 8s 759us/step - loss: 0.7471 - sparse_categorical_accuracy: 0.6938 - val_loss: 1.0091 - val_sparse_categorical_accuracy: 0.6201\n",
      "Epoch 14/30\n",
      "10901/10901 [==============================] - 9s 830us/step - loss: 0.7596 - sparse_categorical_accuracy: 0.6889 - val_loss: 1.1750 - val_sparse_categorical_accuracy: 0.5769\n",
      "Epoch 15/30\n",
      "10901/10901 [==============================] - 11s 1ms/step - loss: 0.7225 - sparse_categorical_accuracy: 0.7060 - val_loss: 1.0157 - val_sparse_categorical_accuracy: 0.6097\n",
      "Epoch 16/30\n",
      "10901/10901 [==============================] - 10s 921us/step - loss: 0.7227 - sparse_categorical_accuracy: 0.7064 - val_loss: 0.8967 - val_sparse_categorical_accuracy: 0.6485\n",
      "Epoch 17/30\n",
      "10901/10901 [==============================] - 9s 801us/step - loss: 0.6911 - sparse_categorical_accuracy: 0.7200 - val_loss: 0.9993 - val_sparse_categorical_accuracy: 0.6313\n",
      "Epoch 18/30\n",
      "10901/10901 [==============================] - 9s 786us/step - loss: 0.6641 - sparse_categorical_accuracy: 0.7294 - val_loss: 0.9473 - val_sparse_categorical_accuracy: 0.6590\n",
      "Epoch 19/30\n",
      "10901/10901 [==============================] - 9s 786us/step - loss: 0.6482 - sparse_categorical_accuracy: 0.7353 - val_loss: 0.9078 - val_sparse_categorical_accuracy: 0.6597\n",
      "Epoch 20/30\n",
      "10901/10901 [==============================] - 8s 759us/step - loss: 0.6180 - sparse_categorical_accuracy: 0.7535 - val_loss: 0.9325 - val_sparse_categorical_accuracy: 0.6500\n",
      "Epoch 21/30\n",
      "10901/10901 [==============================] - 9s 800us/step - loss: 0.5922 - sparse_categorical_accuracy: 0.7595 - val_loss: 0.9604 - val_sparse_categorical_accuracy: 0.6634\n",
      "Epoch 22/30\n",
      "10901/10901 [==============================] - 8s 760us/step - loss: 0.5859 - sparse_categorical_accuracy: 0.7657 - val_loss: 0.9009 - val_sparse_categorical_accuracy: 0.6522\n",
      "Epoch 23/30\n",
      "10901/10901 [==============================] - 9s 839us/step - loss: 0.6109 - sparse_categorical_accuracy: 0.7555 - val_loss: 0.8273 - val_sparse_categorical_accuracy: 0.6918\n",
      "Epoch 24/30\n",
      "10901/10901 [==============================] - 11s 1ms/step - loss: 0.5595 - sparse_categorical_accuracy: 0.7762 - val_loss: 0.9519 - val_sparse_categorical_accuracy: 0.6507\n",
      "Epoch 25/30\n",
      "10901/10901 [==============================] - 12s 1ms/step - loss: 0.5744 - sparse_categorical_accuracy: 0.7664 - val_loss: 0.8788 - val_sparse_categorical_accuracy: 0.6873\n",
      "Epoch 26/30\n",
      "10901/10901 [==============================] - 10s 895us/step - loss: 0.5463 - sparse_categorical_accuracy: 0.7783 - val_loss: 0.9486 - val_sparse_categorical_accuracy: 0.6679\n",
      "Epoch 27/30\n",
      "10901/10901 [==============================] - 8s 773us/step - loss: 0.5245 - sparse_categorical_accuracy: 0.7906 - val_loss: 0.8952 - val_sparse_categorical_accuracy: 0.6694\n",
      "Epoch 28/30\n",
      "10901/10901 [==============================] - 8s 773us/step - loss: 0.5367 - sparse_categorical_accuracy: 0.7837 - val_loss: 0.9022 - val_sparse_categorical_accuracy: 0.6664\n",
      "Epoch 29/30\n",
      "10901/10901 [==============================] - 8s 776us/step - loss: 0.5200 - sparse_categorical_accuracy: 0.7883 - val_loss: 0.8809 - val_sparse_categorical_accuracy: 0.6873\n",
      "Epoch 30/30\n",
      "10901/10901 [==============================] - 8s 759us/step - loss: 0.5206 - sparse_categorical_accuracy: 0.7939 - val_loss: 0.9271 - val_sparse_categorical_accuracy: 0.6716\n",
      "Train on 3246 samples, validate on 1657 samples\n",
      "Epoch 1/1\n",
      "3246/3246 [==============================] - 3s 843us/step - loss: 0.4072 - sparse_categorical_accuracy: 0.9396 - val_loss: 9.4869 - val_sparse_categorical_accuracy: 0.1913\n",
      "Performances after Epoch: 1\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 1.000000\n",
      "Train on 3246 samples, validate on 1657 samples\n",
      "Epoch 1/9\n",
      "3246/3246 [==============================] - 3s 839us/step - loss: 1.5998e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 9.5969 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 2/9\n",
      "3246/3246 [==============================] - 3s 847us/step - loss: 1.3821e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 9.6672 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 3/9\n",
      "3246/3246 [==============================] - 3s 829us/step - loss: 1.3120e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 9.7328 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 4/9\n",
      "3246/3246 [==============================] - 3s 836us/step - loss: 1.2373e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 9.7969 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 5/9\n",
      "3246/3246 [==============================] - 3s 807us/step - loss: 1.2397e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 9.8612 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 6/9\n",
      "3246/3246 [==============================] - 3s 836us/step - loss: 1.1387e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 9.9258 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 7/9\n",
      "3246/3246 [==============================] - 3s 817us/step - loss: 1.0541e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 9.9840 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 8/9\n",
      "3246/3246 [==============================] - 3s 818us/step - loss: 9.0373e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.0382 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 9/9\n",
      "3246/3246 [==============================] - 3s 823us/step - loss: 8.8251e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.0894 - val_sparse_categorical_accuracy: 0.1913\n",
      "Performances after Epoch: 10\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 1.000000\n",
      "Train on 3246 samples, validate on 1657 samples\n",
      "Epoch 1/20\n",
      "3246/3246 [==============================] - 3s 989us/step - loss: 8.3381e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.1401 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 2/20\n",
      "3246/3246 [==============================] - 3s 922us/step - loss: 8.0201e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.1903 - val_sparse_categorical_accuracy: 0.1913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "3246/3246 [==============================] - 3s 964us/step - loss: 7.2241e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.2363 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 4/20\n",
      "3246/3246 [==============================] - 3s 960us/step - loss: 7.3508e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.2826 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 5/20\n",
      "3246/3246 [==============================] - 3s 881us/step - loss: 7.1636e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.3309 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 6/20\n",
      "3246/3246 [==============================] - 3s 958us/step - loss: 6.3827e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.3778 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 7/20\n",
      "3246/3246 [==============================] - 3s 982us/step - loss: 5.6742e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.4184 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 8/20\n",
      "3246/3246 [==============================] - 3s 923us/step - loss: 6.2198e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.4644 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 9/20\n",
      "3246/3246 [==============================] - 3s 901us/step - loss: 6.2258e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.5168 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 10/20\n",
      "3246/3246 [==============================] - 3s 962us/step - loss: 5.4362e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.5607 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 11/20\n",
      "3246/3246 [==============================] - 3s 1ms/step - loss: 5.0569e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.6030 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 12/20\n",
      "3246/3246 [==============================] - 3s 879us/step - loss: 5.2230e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.6476 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 13/20\n",
      "3246/3246 [==============================] - 3s 872us/step - loss: 5.0256e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.6927 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 14/20\n",
      "3246/3246 [==============================] - 3s 867us/step - loss: 4.3834e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.7332 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 15/20\n",
      "3246/3246 [==============================] - 3s 853us/step - loss: 4.5991e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.7767 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 16/20\n",
      "3246/3246 [==============================] - 3s 857us/step - loss: 4.3897e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.8195 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 17/20\n",
      "3246/3246 [==============================] - 3s 838us/step - loss: 3.9388e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.8609 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 18/20\n",
      "3246/3246 [==============================] - 3s 825us/step - loss: 3.7344e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.9007 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 19/20\n",
      "3246/3246 [==============================] - 3s 825us/step - loss: 3.3524e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.9393 - val_sparse_categorical_accuracy: 0.1913\n",
      "Epoch 20/20\n",
      "3246/3246 [==============================] - 3s 820us/step - loss: 3.1580e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 10.9762 - val_sparse_categorical_accuracy: 0.1913\n",
      "Performances after Epoch: 30\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 1.000000\n"
     ]
    }
   ],
   "source": [
    "class_num_D2=15\n",
    "print(\"==== Adding One More Class ====\")\n",
    "print(\"class num D2: %d\" %(class_num_D2))\n",
    "X_train_D1, y_train_D1, X_train_D2, y_train_D2, X_test_D1, y_test_D1, X_test_D2, y_test_D2 = makeDataD2OneClass(class_num_D2, X_train, y_train, X_test, y_test)\n",
    "model = vanilaLSTMs()\n",
    "model.fit(X_train_D1, y_train_D1, validation_data=(X_test_D1, y_test_D1),\n",
    "                    epochs=30,batch_size=64)\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=1,batch_size=64)\n",
    "print(\"Performances after Epoch: 1\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=9,batch_size=64)\n",
    "print(\"Performances after Epoch: 10\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=20,batch_size=64)\n",
    "print(\"Performances after Epoch: 30\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6958 samples, validate on 900 samples\n",
      "Epoch 1/30\n",
      "6958/6958 [==============================] - 6s 811us/step - loss: 1.7175 - sparse_categorical_accuracy: 0.2823 - val_loss: 1.5340 - val_sparse_categorical_accuracy: 0.3822\n",
      "Epoch 2/30\n",
      "6958/6958 [==============================] - 4s 557us/step - loss: 1.2685 - sparse_categorical_accuracy: 0.4003 - val_loss: 1.4047 - val_sparse_categorical_accuracy: 0.4011\n",
      "Epoch 3/30\n",
      "6958/6958 [==============================] - 4s 524us/step - loss: 1.2081 - sparse_categorical_accuracy: 0.4395 - val_loss: 1.2176 - val_sparse_categorical_accuracy: 0.4800\n",
      "Epoch 4/30\n",
      "6958/6958 [==============================] - 4s 525us/step - loss: 1.1081 - sparse_categorical_accuracy: 0.4931 - val_loss: 1.2115 - val_sparse_categorical_accuracy: 0.4222\n",
      "Epoch 5/30\n",
      "6958/6958 [==============================] - 4s 559us/step - loss: 1.0406 - sparse_categorical_accuracy: 0.5277 - val_loss: 1.0925 - val_sparse_categorical_accuracy: 0.5078\n",
      "Epoch 6/30\n",
      "6958/6958 [==============================] - 4s 588us/step - loss: 0.9729 - sparse_categorical_accuracy: 0.5555 - val_loss: 0.9932 - val_sparse_categorical_accuracy: 0.5522\n",
      "Epoch 7/30\n",
      "6958/6958 [==============================] - 4s 621us/step - loss: 0.9461 - sparse_categorical_accuracy: 0.5664 - val_loss: 1.1522 - val_sparse_categorical_accuracy: 0.4811\n",
      "Epoch 8/30\n",
      "6958/6958 [==============================] - 4s 627us/step - loss: 0.8648 - sparse_categorical_accuracy: 0.6104 - val_loss: 0.8666 - val_sparse_categorical_accuracy: 0.6267\n",
      "Epoch 9/30\n",
      "6958/6958 [==============================] - 4s 549us/step - loss: 0.8072 - sparse_categorical_accuracy: 0.6482 - val_loss: 0.9067 - val_sparse_categorical_accuracy: 0.6189\n",
      "Epoch 10/30\n",
      "6958/6958 [==============================] - 4s 635us/step - loss: 0.7556 - sparse_categorical_accuracy: 0.6660 - val_loss: 0.8721 - val_sparse_categorical_accuracy: 0.6122\n",
      "Epoch 11/30\n",
      "6958/6958 [==============================] - 4s 597us/step - loss: 0.7479 - sparse_categorical_accuracy: 0.6758 - val_loss: 0.9137 - val_sparse_categorical_accuracy: 0.5756\n",
      "Epoch 12/30\n",
      "6958/6958 [==============================] - 4s 566us/step - loss: 0.7360 - sparse_categorical_accuracy: 0.6835 - val_loss: 1.0492 - val_sparse_categorical_accuracy: 0.5978\n",
      "Epoch 13/30\n",
      "6958/6958 [==============================] - 4s 558us/step - loss: 0.7089 - sparse_categorical_accuracy: 0.6968 - val_loss: 0.9965 - val_sparse_categorical_accuracy: 0.5678\n",
      "Epoch 14/30\n",
      "6958/6958 [==============================] - 4s 556us/step - loss: 0.6565 - sparse_categorical_accuracy: 0.7127 - val_loss: 0.8506 - val_sparse_categorical_accuracy: 0.6267\n",
      "Epoch 15/30\n",
      "6958/6958 [==============================] - 4s 560us/step - loss: 0.6484 - sparse_categorical_accuracy: 0.7243 - val_loss: 0.7760 - val_sparse_categorical_accuracy: 0.6733\n",
      "Epoch 16/30\n",
      "6958/6958 [==============================] - 4s 547us/step - loss: 0.6096 - sparse_categorical_accuracy: 0.7420 - val_loss: 0.6935 - val_sparse_categorical_accuracy: 0.6878\n",
      "Epoch 17/30\n",
      "6958/6958 [==============================] - 4s 570us/step - loss: 0.6161 - sparse_categorical_accuracy: 0.7453 - val_loss: 0.7659 - val_sparse_categorical_accuracy: 0.6822\n",
      "Epoch 18/30\n",
      "6958/6958 [==============================] - 4s 554us/step - loss: 0.5692 - sparse_categorical_accuracy: 0.7613 - val_loss: 0.9321 - val_sparse_categorical_accuracy: 0.6233\n",
      "Epoch 19/30\n",
      "6958/6958 [==============================] - 4s 545us/step - loss: 0.5686 - sparse_categorical_accuracy: 0.7653 - val_loss: 0.7188 - val_sparse_categorical_accuracy: 0.6878\n",
      "Epoch 20/30\n",
      "6958/6958 [==============================] - 4s 598us/step - loss: 0.5509 - sparse_categorical_accuracy: 0.7721 - val_loss: 0.7981 - val_sparse_categorical_accuracy: 0.6567\n",
      "Epoch 21/30\n",
      "6958/6958 [==============================] - 4s 596us/step - loss: 0.5389 - sparse_categorical_accuracy: 0.7767 - val_loss: 0.7484 - val_sparse_categorical_accuracy: 0.6678\n",
      "Epoch 22/30\n",
      "6958/6958 [==============================] - 4s 579us/step - loss: 0.5243 - sparse_categorical_accuracy: 0.7851 - val_loss: 0.6888 - val_sparse_categorical_accuracy: 0.7167\n",
      "Epoch 23/30\n",
      "6958/6958 [==============================] - 4s 563us/step - loss: 0.4899 - sparse_categorical_accuracy: 0.8011 - val_loss: 0.6208 - val_sparse_categorical_accuracy: 0.7389\n",
      "Epoch 24/30\n",
      "6958/6958 [==============================] - 4s 554us/step - loss: 0.4719 - sparse_categorical_accuracy: 0.8093 - val_loss: 0.7129 - val_sparse_categorical_accuracy: 0.7067\n",
      "Epoch 25/30\n",
      "6958/6958 [==============================] - 4s 586us/step - loss: 0.4698 - sparse_categorical_accuracy: 0.8090 - val_loss: 0.7047 - val_sparse_categorical_accuracy: 0.7222\n",
      "Epoch 26/30\n",
      "6958/6958 [==============================] - 4s 614us/step - loss: 0.4410 - sparse_categorical_accuracy: 0.8222 - val_loss: 0.7561 - val_sparse_categorical_accuracy: 0.7033\n",
      "Epoch 27/30\n",
      "6958/6958 [==============================] - 4s 593us/step - loss: 0.4663 - sparse_categorical_accuracy: 0.8094 - val_loss: 0.7270 - val_sparse_categorical_accuracy: 0.7022\n",
      "Epoch 28/30\n",
      "6958/6958 [==============================] - 4s 566us/step - loss: 0.4274 - sparse_categorical_accuracy: 0.8297 - val_loss: 0.6256 - val_sparse_categorical_accuracy: 0.7411\n",
      "Epoch 29/30\n",
      "6958/6958 [==============================] - 4s 550us/step - loss: 0.4272 - sparse_categorical_accuracy: 0.8329 - val_loss: 0.9940 - val_sparse_categorical_accuracy: 0.6011\n",
      "Epoch 30/30\n",
      "6958/6958 [==============================] - 4s 599us/step - loss: 0.4343 - sparse_categorical_accuracy: 0.8291 - val_loss: 0.7629 - val_sparse_categorical_accuracy: 0.6911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c4a552978>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_D1, y_train_D1, validation_data=(X_test_D1, y_test_D1),\n",
    "                    epochs=30,batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7189 samples, validate on 1657 samples\n",
      "Epoch 1/30\n",
      "7189/7189 [==============================] - 4s 586us/step - loss: 1.2322 - sparse_categorical_accuracy: 0.5958 - val_loss: 4.7684 - val_sparse_categorical_accuracy: 0.2824\n",
      "Epoch 2/30\n",
      "7189/7189 [==============================] - 4s 551us/step - loss: 0.6821 - sparse_categorical_accuracy: 0.7140 - val_loss: 4.9061 - val_sparse_categorical_accuracy: 0.2993\n",
      "Epoch 3/30\n",
      "7189/7189 [==============================] - 4s 549us/step - loss: 0.6060 - sparse_categorical_accuracy: 0.7499 - val_loss: 4.3866 - val_sparse_categorical_accuracy: 0.3096\n",
      "Epoch 4/30\n",
      "7189/7189 [==============================] - 4s 537us/step - loss: 0.5111 - sparse_categorical_accuracy: 0.7841 - val_loss: 4.6187 - val_sparse_categorical_accuracy: 0.3368\n",
      "Epoch 5/30\n",
      "7189/7189 [==============================] - 4s 582us/step - loss: 0.4907 - sparse_categorical_accuracy: 0.7950 - val_loss: 4.6365 - val_sparse_categorical_accuracy: 0.3392\n",
      "Epoch 6/30\n",
      "7189/7189 [==============================] - 4s 543us/step - loss: 0.4869 - sparse_categorical_accuracy: 0.7911 - val_loss: 4.9040 - val_sparse_categorical_accuracy: 0.3301\n",
      "Epoch 7/30\n",
      "7189/7189 [==============================] - 4s 534us/step - loss: 0.4607 - sparse_categorical_accuracy: 0.8066 - val_loss: 4.0946 - val_sparse_categorical_accuracy: 0.3476\n",
      "Epoch 8/30\n",
      "7189/7189 [==============================] - 4s 543us/step - loss: 0.4557 - sparse_categorical_accuracy: 0.8043 - val_loss: 4.4798 - val_sparse_categorical_accuracy: 0.3567\n",
      "Epoch 9/30\n",
      "7189/7189 [==============================] - 4s 549us/step - loss: 0.4270 - sparse_categorical_accuracy: 0.8181 - val_loss: 4.9388 - val_sparse_categorical_accuracy: 0.3488\n",
      "Epoch 10/30\n",
      "7189/7189 [==============================] - 4s 543us/step - loss: 0.4100 - sparse_categorical_accuracy: 0.8224 - val_loss: 4.1220 - val_sparse_categorical_accuracy: 0.3543\n",
      "Epoch 11/30\n",
      "7189/7189 [==============================] - 4s 551us/step - loss: 0.4152 - sparse_categorical_accuracy: 0.8249 - val_loss: 4.5674 - val_sparse_categorical_accuracy: 0.3633\n",
      "Epoch 12/30\n",
      "7189/7189 [==============================] - 4s 554us/step - loss: 0.3983 - sparse_categorical_accuracy: 0.8353 - val_loss: 4.5509 - val_sparse_categorical_accuracy: 0.3537\n",
      "Epoch 13/30\n",
      "7189/7189 [==============================] - 4s 538us/step - loss: 0.3924 - sparse_categorical_accuracy: 0.8359 - val_loss: 4.5643 - val_sparse_categorical_accuracy: 0.3543\n",
      "Epoch 14/30\n",
      "7189/7189 [==============================] - 4s 554us/step - loss: 0.3922 - sparse_categorical_accuracy: 0.8339 - val_loss: 4.6756 - val_sparse_categorical_accuracy: 0.3639\n",
      "Epoch 15/30\n",
      "7189/7189 [==============================] - 4s 566us/step - loss: 0.3980 - sparse_categorical_accuracy: 0.8313 - val_loss: 4.1990 - val_sparse_categorical_accuracy: 0.3705\n",
      "Epoch 16/30\n",
      "7189/7189 [==============================] - 4s 567us/step - loss: 0.3617 - sparse_categorical_accuracy: 0.8478 - val_loss: 4.5009 - val_sparse_categorical_accuracy: 0.3597\n",
      "Epoch 17/30\n",
      "7189/7189 [==============================] - 4s 600us/step - loss: 0.3763 - sparse_categorical_accuracy: 0.8406 - val_loss: 4.7303 - val_sparse_categorical_accuracy: 0.3603\n",
      "Epoch 18/30\n",
      "7189/7189 [==============================] - 4s 555us/step - loss: 0.3483 - sparse_categorical_accuracy: 0.8531 - val_loss: 5.1101 - val_sparse_categorical_accuracy: 0.3730\n",
      "Epoch 19/30\n",
      "7189/7189 [==============================] - 4s 558us/step - loss: 0.3361 - sparse_categorical_accuracy: 0.8590 - val_loss: 4.8011 - val_sparse_categorical_accuracy: 0.3802\n",
      "Epoch 20/30\n",
      "7189/7189 [==============================] - 4s 596us/step - loss: 0.3538 - sparse_categorical_accuracy: 0.8520 - val_loss: 4.2395 - val_sparse_categorical_accuracy: 0.3567\n",
      "Epoch 21/30\n",
      "7189/7189 [==============================] - 4s 566us/step - loss: 0.3308 - sparse_categorical_accuracy: 0.8570 - val_loss: 4.9020 - val_sparse_categorical_accuracy: 0.3657\n",
      "Epoch 22/30\n",
      "7189/7189 [==============================] - 4s 602us/step - loss: 0.3651 - sparse_categorical_accuracy: 0.8468 - val_loss: 4.8725 - val_sparse_categorical_accuracy: 0.3669\n",
      "Epoch 23/30\n",
      "7189/7189 [==============================] - 4s 606us/step - loss: 0.3369 - sparse_categorical_accuracy: 0.8609 - val_loss: 4.3770 - val_sparse_categorical_accuracy: 0.3621\n",
      "Epoch 24/30\n",
      "7189/7189 [==============================] - 4s 582us/step - loss: 0.3399 - sparse_categorical_accuracy: 0.8592 - val_loss: 4.7340 - val_sparse_categorical_accuracy: 0.3651\n",
      "Epoch 25/30\n",
      "7189/7189 [==============================] - 4s 554us/step - loss: 0.3114 - sparse_categorical_accuracy: 0.8680 - val_loss: 4.9599 - val_sparse_categorical_accuracy: 0.3494\n",
      "Epoch 26/30\n",
      "7189/7189 [==============================] - 4s 559us/step - loss: 0.3203 - sparse_categorical_accuracy: 0.8683 - val_loss: 4.2716 - val_sparse_categorical_accuracy: 0.3754\n",
      "Epoch 27/30\n",
      "7189/7189 [==============================] - 4s 566us/step - loss: 0.3333 - sparse_categorical_accuracy: 0.8617 - val_loss: 4.5709 - val_sparse_categorical_accuracy: 0.3681\n",
      "Epoch 28/30\n",
      "7189/7189 [==============================] - 4s 590us/step - loss: 0.3570 - sparse_categorical_accuracy: 0.8538 - val_loss: 4.6795 - val_sparse_categorical_accuracy: 0.3591\n",
      "Epoch 29/30\n",
      "7189/7189 [==============================] - 4s 616us/step - loss: 0.3074 - sparse_categorical_accuracy: 0.8716 - val_loss: 4.7603 - val_sparse_categorical_accuracy: 0.3718\n",
      "Epoch 30/30\n",
      "7189/7189 [==============================] - 4s 590us/step - loss: 0.3076 - sparse_categorical_accuracy: 0.8722 - val_loss: 5.1050 - val_sparse_categorical_accuracy: 0.3772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c4a552860>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=30,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = np.argmax(model.predict(X_test_D1), axis=1)\n",
    "accuracy_score(y_test_D1, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8256274768824307"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = np.argmax(model.predict(X_test_D2), axis=1)\n",
    "accuracy_score(y_test_D2, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3771876885938443"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "accuracy_score(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = 113 # (# features)\n",
    "num_classes = 17\n",
    "\n",
    "# params\n",
    "timesteps_l = [24]\n",
    "num_stack_l = [2]\n",
    "hidden_layer_size_l = [64]\n",
    "for timesteps in timesteps_l:\n",
    "    for num_stack in num_stack_l:\n",
    "        for hidden_layer_size in hidden_layer_size_l:\n",
    "            # auc_l = runKerasModels('yelp',num_stack, hidden_layer_size, [X_test, y_test])\n",
    "            hist_l = runKerasModels('D1',num_stack, hidden_layer_size, [X_train, y_train])\n",
    "            print(\"final result: # stacks: %d, hidden_layer_size: %d, mean acc: %f, prec: %f, rec: %f, f1: %f\" %(num_stack,hidden_layer_size,np.mean(hist_l[0]),np.mean(hist_l[1]),np.mean(hist_l[2]),np.mean(hist_l[3])))\n",
    "#             print(hist_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[3] + [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py354)",
   "language": "python",
   "name": "py354"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
