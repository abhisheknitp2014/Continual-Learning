{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279.35290160430094\n"
     ]
    }
   ],
   "source": [
    "import sys,os,json\n",
    "import collections,math\n",
    "import time,datetime,pytz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "# from textblob import TextBlob\n",
    "# from polyglot.detect import Detector\n",
    "import operator\n",
    "# import PlotUtil\n",
    "from scipy.stats import linregress\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# warnings.filterwarnings(action='once')\n",
    "# import foursq_helper as foursq\n",
    "# from yelp_helper import *\n",
    "\n",
    "############################################\n",
    "########## Plot Style Declaration ##########\n",
    "# Set the style globally\n",
    "# Alternatives include bmh, fivethirtyeight, ggplot,\n",
    "# dark_background, seaborn-deep, etc\n",
    "# plt.style.use('ggplot')\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "plt.rcParams['font.family'] = 'times new roman'\n",
    "# plt.rcParams['font.serif'] = 'Ubuntu'\n",
    "# plt.rcParams['font.monospace'] = 'Ubuntu Mono'\n",
    "plt.rcParams['font.size'] = 15\n",
    "plt.rcParams['axes.labelsize'] = 15\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titlesize'] = 15\n",
    "plt.rcParams['xtick.labelsize'] = 15\n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "plt.rcParams['figure.titlesize'] = 15\n",
    "plt.rcParams['lines.linewidth'] = 3\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "##########################################\n",
    "########## data set declaration ##########\n",
    "path_processed = \"data/processed/\"\n",
    "path_final = \"data/final/\"\n",
    "\n",
    "##################################\n",
    "########## End of Setup ##########\n",
    "\n",
    "##### Geographical Change #####\n",
    "import geopy\n",
    "from geopy import distance as geopy_distance\n",
    "coords_1 = (52.2296756, 21.0122287)\n",
    "coords_2 = (52.406374, 16.9251681)\n",
    "print (geopy.distance.distance(coords_1, coords_2).km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/opp_X_train.npy\", X_train)\n",
    "np.save(\"data/opp_X_test.npy\", X_test)\n",
    "np.save(\"data/opp_y_train.npy\", y_train)\n",
    "np.save(\"data/opp_y_test.npy\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"data/opp_X_train.npy\")\n",
    "X_test = np.load(\"data/opp_X_test.npy\")\n",
    "y_train = np.load(\"data/opp_y_train.npy\")\n",
    "y_test = np.load(\"data/opp_y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/opp_X_train_D1.npy\", X_train_D1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14147, 24, 113)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Implementation !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from matplotlib import pyplot\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.metrics import fbeta_score\n",
    "from keras import backend as K\n",
    "\n",
    "def auroc(y_true, y_pred):\n",
    "    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = LabelEncoder().fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9894,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 32348,\n",
       "         1: 864,\n",
       "         2: 887,\n",
       "         3: 806,\n",
       "         4: 846,\n",
       "         5: 921,\n",
       "         6: 850,\n",
       "         7: 666,\n",
       "         8: 628,\n",
       "         9: 490,\n",
       "         10: 413,\n",
       "         11: 457,\n",
       "         12: 416,\n",
       "         13: 566,\n",
       "         14: 564,\n",
       "         15: 904,\n",
       "         16: 3246,\n",
       "         17: 623})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[y_train[:]>0]\n",
    "y_train = y_train[y_train[:]>0]\n",
    "y_train = y_train[:] - 1\n",
    "\n",
    "X_test = X_test[y_test[:]>0]\n",
    "y_test = y_test[y_test[:]>0]\n",
    "y_test = y_test[:] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 864,\n",
       "         1: 887,\n",
       "         2: 806,\n",
       "         3: 846,\n",
       "         4: 921,\n",
       "         5: 850,\n",
       "         6: 666,\n",
       "         7: 628,\n",
       "         8: 490,\n",
       "         9: 413,\n",
       "         10: 457,\n",
       "         11: 416,\n",
       "         12: 566,\n",
       "         13: 564,\n",
       "         14: 904,\n",
       "         15: 3246,\n",
       "         16: 623})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14147, 24, 113)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDataD2OneClass(class_num_D2, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    X_train_D1 = X_train[y_train[:] != class_num_D2]\n",
    "    X_train_D2 = X_train[y_train[:] == class_num_D2]\n",
    "\n",
    "    y_train_D1 = y_train[y_train[:] != class_num_D2]\n",
    "    y_train_D2 = y_train[y_train[:] == class_num_D2]\n",
    "\n",
    "    X_test_D1 = X_test[y_test[:] != class_num_D2]\n",
    "    X_test_D2 = X_test[y_test[:] == class_num_D2]\n",
    "\n",
    "    y_test_D1 = y_test[y_test[:] != class_num_D2]\n",
    "    y_test_D2 = y_test[y_test[:] == class_num_D2]\n",
    "    \n",
    "    return X_train_D1, y_train_D1, X_train_D2, y_train_D2, X_test_D1, y_test_D1, X_test_D2, y_test_D2\n",
    "\n",
    "# [True if s in class_l else False for s in y_train]\n",
    "def makeDataD2HalfClasses(class_dict_D1, class_dict_D2, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    X_train_D1 = X_train[[True if x in class_dict_D1 else False for x in y_train]]\n",
    "    X_train_D2 = X_train[[True if x in class_dict_D2 else False for x in y_train]]\n",
    "\n",
    "    y_train_D1 = y_train[[True if x in class_dict_D1 else False for x in y_train]]\n",
    "    y_train_D2 = y_train[[True if x in class_dict_D2 else False for x in y_train]]\n",
    "\n",
    "    X_test_D1 = X_test[[True if x in class_dict_D1 else False for x in y_test]]\n",
    "    X_test_D2 = X_test[[True if x in class_dict_D2 else False for x in y_test]]\n",
    "\n",
    "    y_test_D1 = y_test[[True if x in class_dict_D1 else False for x in y_test]]\n",
    "    y_test_D2 = y_test[[True if x in class_dict_D2 else False for x in y_test]]\n",
    "    \n",
    "    return X_train_D1, y_train_D1, X_train_D2, y_train_D2, X_test_D1, y_test_D1, X_test_D2, y_test_D2\n",
    "\n",
    "def makeClassDictD1(class_dict_D2, num_classes):\n",
    "    class_list = []\n",
    "    for i in range(num_classes):\n",
    "        if i not in class_dict_D2:\n",
    "            class_list.append(i)\n",
    "    return set(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilaLSTMs():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hidden_layer_size,input_shape=(timesteps, data_dim),init='glorot_normal'))  # return a single vector of dimension 32\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation='softmax',init='glorot_normal'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['sparse_categorical_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = 113 # (# features)\n",
    "num_classes = 17\n",
    "\n",
    "# params\n",
    "timesteps = 24\n",
    "num_stack = 1\n",
    "hidden_layer_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Adding Half More Classes ====\n",
      "class dict D1:  {9, 10, 11, 12, 13, 14, 15, 16}\n",
      "class dict D2:  {0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
      "WARNING:tensorflow:From /Users/ydkwon/anaconda2/envs/py354/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/ydkwon/anaconda2/envs/py354/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/ydkwon/anaconda2/envs/py354/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 7189 samples, validate on 757 samples\n",
      "Epoch 1/30\n",
      "7189/7189 [==============================] - 9s 1ms/step - loss: 1.2317 - sparse_categorical_accuracy: 0.5574 - val_loss: 1.1894 - val_sparse_categorical_accuracy: 0.5139\n",
      "Epoch 2/30\n",
      "7189/7189 [==============================] - 8s 1ms/step - loss: 0.8011 - sparse_categorical_accuracy: 0.6820 - val_loss: 1.3218 - val_sparse_categorical_accuracy: 0.5601\n",
      "Epoch 3/30\n",
      "7189/7189 [==============================] - 9s 1ms/step - loss: 0.6974 - sparse_categorical_accuracy: 0.7200 - val_loss: 0.8464 - val_sparse_categorical_accuracy: 0.6988\n",
      "Epoch 4/30\n",
      "7189/7189 [==============================] - 8s 1ms/step - loss: 0.6224 - sparse_categorical_accuracy: 0.7328 - val_loss: 0.9712 - val_sparse_categorical_accuracy: 0.6843\n",
      "Epoch 5/30\n",
      "7189/7189 [==============================] - 7s 1ms/step - loss: 0.6114 - sparse_categorical_accuracy: 0.7464 - val_loss: 0.7696 - val_sparse_categorical_accuracy: 0.7252\n",
      "Epoch 6/30\n",
      "7189/7189 [==============================] - 7s 1ms/step - loss: 0.5461 - sparse_categorical_accuracy: 0.7677 - val_loss: 1.1851 - val_sparse_categorical_accuracy: 0.5839\n",
      "Epoch 7/30\n",
      "7189/7189 [==============================] - 8s 1ms/step - loss: 0.5287 - sparse_categorical_accuracy: 0.7733 - val_loss: 0.8158 - val_sparse_categorical_accuracy: 0.6816\n",
      "Epoch 8/30\n",
      "7189/7189 [==============================] - 7s 1ms/step - loss: 0.5152 - sparse_categorical_accuracy: 0.7755 - val_loss: 0.8205 - val_sparse_categorical_accuracy: 0.6988\n",
      "Epoch 9/30\n",
      "7189/7189 [==============================] - 7s 1ms/step - loss: 0.5221 - sparse_categorical_accuracy: 0.7787 - val_loss: 0.6914 - val_sparse_categorical_accuracy: 0.7609\n",
      "Epoch 10/30\n",
      "7189/7189 [==============================] - 8s 1ms/step - loss: 0.4869 - sparse_categorical_accuracy: 0.7916 - val_loss: 0.6964 - val_sparse_categorical_accuracy: 0.7662\n",
      "Epoch 11/30\n",
      "7189/7189 [==============================] - 8s 1ms/step - loss: 0.4494 - sparse_categorical_accuracy: 0.8065 - val_loss: 0.7394 - val_sparse_categorical_accuracy: 0.7371\n",
      "Epoch 12/30\n",
      "7189/7189 [==============================] - 8s 1ms/step - loss: 0.4745 - sparse_categorical_accuracy: 0.7957 - val_loss: 0.6491 - val_sparse_categorical_accuracy: 0.7794\n",
      "Epoch 13/30\n",
      "7189/7189 [==============================] - 9s 1ms/step - loss: 0.4428 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.8322 - val_sparse_categorical_accuracy: 0.7160\n",
      "Epoch 14/30\n",
      "7189/7189 [==============================] - 7s 1ms/step - loss: 0.4374 - sparse_categorical_accuracy: 0.8096 - val_loss: 0.6831 - val_sparse_categorical_accuracy: 0.7688\n",
      "Epoch 15/30\n",
      "7189/7189 [==============================] - 7s 939us/step - loss: 0.4091 - sparse_categorical_accuracy: 0.8189 - val_loss: 0.5624 - val_sparse_categorical_accuracy: 0.8085\n",
      "Epoch 16/30\n",
      "7189/7189 [==============================] - 7s 930us/step - loss: 0.4123 - sparse_categorical_accuracy: 0.8226 - val_loss: 0.7160 - val_sparse_categorical_accuracy: 0.7530\n",
      "Epoch 17/30\n",
      "7189/7189 [==============================] - 7s 917us/step - loss: 0.4077 - sparse_categorical_accuracy: 0.8231 - val_loss: 0.6119 - val_sparse_categorical_accuracy: 0.7834\n",
      "Epoch 18/30\n",
      "7189/7189 [==============================] - 7s 928us/step - loss: 0.4120 - sparse_categorical_accuracy: 0.8208 - val_loss: 0.6313 - val_sparse_categorical_accuracy: 0.7794\n",
      "Epoch 19/30\n",
      "7189/7189 [==============================] - 7s 941us/step - loss: 0.4072 - sparse_categorical_accuracy: 0.8239 - val_loss: 0.6567 - val_sparse_categorical_accuracy: 0.7794\n",
      "Epoch 20/30\n",
      "7189/7189 [==============================] - 7s 931us/step - loss: 0.3934 - sparse_categorical_accuracy: 0.8238 - val_loss: 0.7046 - val_sparse_categorical_accuracy: 0.7728\n",
      "Epoch 21/30\n",
      "7189/7189 [==============================] - 6s 861us/step - loss: 0.4069 - sparse_categorical_accuracy: 0.8213 - val_loss: 0.6525 - val_sparse_categorical_accuracy: 0.7768\n",
      "Epoch 22/30\n",
      "7189/7189 [==============================] - 7s 967us/step - loss: 0.3689 - sparse_categorical_accuracy: 0.8384 - val_loss: 0.6249 - val_sparse_categorical_accuracy: 0.8005\n",
      "Epoch 23/30\n",
      "7189/7189 [==============================] - 8s 1ms/step - loss: 0.3782 - sparse_categorical_accuracy: 0.8349 - val_loss: 0.7445 - val_sparse_categorical_accuracy: 0.7292\n",
      "Epoch 24/30\n",
      "7189/7189 [==============================] - 9s 1ms/step - loss: 0.3746 - sparse_categorical_accuracy: 0.8382 - val_loss: 1.1214 - val_sparse_categorical_accuracy: 0.6777\n",
      "Epoch 25/30\n",
      "7189/7189 [==============================] - 7s 1ms/step - loss: 0.3682 - sparse_categorical_accuracy: 0.8395 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.7913\n",
      "Epoch 26/30\n",
      "7189/7189 [==============================] - 6s 815us/step - loss: 0.3733 - sparse_categorical_accuracy: 0.8386 - val_loss: 0.5201 - val_sparse_categorical_accuracy: 0.8124\n",
      "Epoch 27/30\n",
      "7189/7189 [==============================] - 6s 777us/step - loss: 0.3599 - sparse_categorical_accuracy: 0.8396 - val_loss: 0.5587 - val_sparse_categorical_accuracy: 0.8111\n",
      "Epoch 28/30\n",
      "7189/7189 [==============================] - 6s 818us/step - loss: 0.3369 - sparse_categorical_accuracy: 0.8516 - val_loss: 0.6340 - val_sparse_categorical_accuracy: 0.7701\n",
      "Epoch 29/30\n",
      "7189/7189 [==============================] - 7s 982us/step - loss: 0.3542 - sparse_categorical_accuracy: 0.8452 - val_loss: 0.8344 - val_sparse_categorical_accuracy: 0.6988\n",
      "Epoch 30/30\n",
      "7189/7189 [==============================] - 6s 860us/step - loss: 0.3405 - sparse_categorical_accuracy: 0.8524 - val_loss: 0.5349 - val_sparse_categorical_accuracy: 0.8375\n",
      "Train on 6958 samples, validate on 1657 samples\n",
      "Epoch 1/1\n",
      "6958/6958 [==============================] - 9s 1ms/step - loss: 1.8454 - sparse_categorical_accuracy: 0.3002 - val_loss: 4.4363 - val_sparse_categorical_accuracy: 0.1720\n",
      "Performances after Epoch: 1\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 0.316667\n",
      "Train on 6958 samples, validate on 1657 samples\n",
      "Epoch 1/9\n",
      "6958/6958 [==============================] - 8s 1ms/step - loss: 1.2615 - sparse_categorical_accuracy: 0.4360 - val_loss: 4.1535 - val_sparse_categorical_accuracy: 0.2511\n",
      "Epoch 2/9\n",
      "6958/6958 [==============================] - 7s 986us/step - loss: 1.0866 - sparse_categorical_accuracy: 0.5080 - val_loss: 4.5160 - val_sparse_categorical_accuracy: 0.2523\n",
      "Epoch 3/9\n",
      "6958/6958 [==============================] - 6s 886us/step - loss: 0.9938 - sparse_categorical_accuracy: 0.5421 - val_loss: 4.4173 - val_sparse_categorical_accuracy: 0.2764\n",
      "Epoch 4/9\n",
      "6958/6958 [==============================] - 7s 988us/step - loss: 0.9464 - sparse_categorical_accuracy: 0.5714 - val_loss: 4.4674 - val_sparse_categorical_accuracy: 0.2619\n",
      "Epoch 5/9\n",
      "6958/6958 [==============================] - 9s 1ms/step - loss: 0.9054 - sparse_categorical_accuracy: 0.5954 - val_loss: 4.5394 - val_sparse_categorical_accuracy: 0.2873\n",
      "Epoch 6/9\n",
      "6958/6958 [==============================] - 9s 1ms/step - loss: 0.8668 - sparse_categorical_accuracy: 0.6117 - val_loss: 4.4853 - val_sparse_categorical_accuracy: 0.3156\n",
      "Epoch 7/9\n",
      "6958/6958 [==============================] - 7s 981us/step - loss: 0.8314 - sparse_categorical_accuracy: 0.6383 - val_loss: 4.4352 - val_sparse_categorical_accuracy: 0.3162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/9\n",
      "6958/6958 [==============================] - 7s 960us/step - loss: 0.7983 - sparse_categorical_accuracy: 0.6523 - val_loss: 4.6468 - val_sparse_categorical_accuracy: 0.2511\n",
      "Epoch 9/9\n",
      "6958/6958 [==============================] - 7s 997us/step - loss: 0.7805 - sparse_categorical_accuracy: 0.6625 - val_loss: 4.5279 - val_sparse_categorical_accuracy: 0.3380\n",
      "Performances after Epoch: 10\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 0.622222\n",
      "Train on 6958 samples, validate on 1657 samples\n",
      "Epoch 1/20\n",
      "6958/6958 [==============================] - 7s 955us/step - loss: 0.7374 - sparse_categorical_accuracy: 0.6845 - val_loss: 4.4421 - val_sparse_categorical_accuracy: 0.2637\n",
      "Epoch 2/20\n",
      "6958/6958 [==============================] - 7s 1ms/step - loss: 0.7588 - sparse_categorical_accuracy: 0.6786 - val_loss: 4.2811 - val_sparse_categorical_accuracy: 0.3102\n",
      "Epoch 3/20\n",
      "6958/6958 [==============================] - 6s 879us/step - loss: 0.7119 - sparse_categorical_accuracy: 0.6919 - val_loss: 4.3665 - val_sparse_categorical_accuracy: 0.3482\n",
      "Epoch 4/20\n",
      "6958/6958 [==============================] - 8s 1ms/step - loss: 0.6891 - sparse_categorical_accuracy: 0.7077 - val_loss: 4.5212 - val_sparse_categorical_accuracy: 0.3295\n",
      "Epoch 5/20\n",
      "6958/6958 [==============================] - 8s 1ms/step - loss: 0.6772 - sparse_categorical_accuracy: 0.7144 - val_loss: 4.5339 - val_sparse_categorical_accuracy: 0.3712\n",
      "Epoch 6/20\n",
      "6958/6958 [==============================] - 7s 1ms/step - loss: 0.6530 - sparse_categorical_accuracy: 0.7304 - val_loss: 4.5934 - val_sparse_categorical_accuracy: 0.3518\n",
      "Epoch 7/20\n",
      "6958/6958 [==============================] - 7s 1ms/step - loss: 0.6651 - sparse_categorical_accuracy: 0.7169 - val_loss: 4.6208 - val_sparse_categorical_accuracy: 0.3603\n",
      "Epoch 8/20\n",
      "6958/6958 [==============================] - 7s 984us/step - loss: 0.5961 - sparse_categorical_accuracy: 0.7518 - val_loss: 4.7259 - val_sparse_categorical_accuracy: 0.3645\n",
      "Epoch 9/20\n",
      "6958/6958 [==============================] - 8s 1ms/step - loss: 0.6011 - sparse_categorical_accuracy: 0.7481 - val_loss: 4.9215 - val_sparse_categorical_accuracy: 0.3253\n",
      "Epoch 10/20\n",
      "6958/6958 [==============================] - 8s 1ms/step - loss: 0.5785 - sparse_categorical_accuracy: 0.7544 - val_loss: 4.6820 - val_sparse_categorical_accuracy: 0.3621\n",
      "Epoch 11/20\n",
      "6958/6958 [==============================] - 8s 1ms/step - loss: 0.5702 - sparse_categorical_accuracy: 0.7698 - val_loss: 4.7836 - val_sparse_categorical_accuracy: 0.3754\n",
      "Epoch 12/20\n",
      "6958/6958 [==============================] - 9s 1ms/step - loss: 0.5643 - sparse_categorical_accuracy: 0.7682 - val_loss: 4.5818 - val_sparse_categorical_accuracy: 0.3874\n",
      "Epoch 13/20\n",
      "6958/6958 [==============================] - 8s 1ms/step - loss: 0.5603 - sparse_categorical_accuracy: 0.7690 - val_loss: 5.0158 - val_sparse_categorical_accuracy: 0.3736\n",
      "Epoch 14/20\n",
      "6958/6958 [==============================] - 8s 1ms/step - loss: 0.5408 - sparse_categorical_accuracy: 0.7767 - val_loss: 4.6936 - val_sparse_categorical_accuracy: 0.3844\n",
      "Epoch 15/20\n",
      "6958/6958 [==============================] - 8s 1ms/step - loss: 0.5160 - sparse_categorical_accuracy: 0.7919 - val_loss: 4.7379 - val_sparse_categorical_accuracy: 0.3796\n",
      "Epoch 16/20\n",
      "6958/6958 [==============================] - 6s 812us/step - loss: 0.5090 - sparse_categorical_accuracy: 0.7918 - val_loss: 5.1722 - val_sparse_categorical_accuracy: 0.3663\n",
      "Epoch 17/20\n",
      "6958/6958 [==============================] - 5s 717us/step - loss: 0.5403 - sparse_categorical_accuracy: 0.7771 - val_loss: 4.7855 - val_sparse_categorical_accuracy: 0.3754\n",
      "Epoch 18/20\n",
      "6958/6958 [==============================] - 7s 975us/step - loss: 0.5068 - sparse_categorical_accuracy: 0.7889 - val_loss: 4.9460 - val_sparse_categorical_accuracy: 0.3699\n",
      "Epoch 19/20\n",
      "6958/6958 [==============================] - 7s 954us/step - loss: 0.4752 - sparse_categorical_accuracy: 0.8054 - val_loss: 5.0310 - val_sparse_categorical_accuracy: 0.3434\n",
      "Epoch 20/20\n",
      "6958/6958 [==============================] - 8s 1ms/step - loss: 0.4826 - sparse_categorical_accuracy: 0.8040 - val_loss: 4.9000 - val_sparse_categorical_accuracy: 0.4037\n",
      "Performances after Epoch: 30\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 0.743333\n"
     ]
    }
   ],
   "source": [
    "class_dict_D2 = {0,1,2,3,4,5,6,7,8}\n",
    "class_dict_D1 = makeClassDictD1(class_dict_D2, num_classes)\n",
    "print(\"==== Adding Half More Classes ====\")\n",
    "print(\"class dict D1: \", class_dict_D1)\n",
    "print(\"class dict D2: \", class_dict_D2)\n",
    "X_train_D1, y_train_D1, X_train_D2, y_train_D2, X_test_D1, y_test_D1, X_test_D2, y_test_D2 = makeDataD2HalfClasses(class_dict_D1, class_dict_D2, X_train, y_train, X_test, y_test)\n",
    "model = vanilaLSTMs()\n",
    "model.fit(X_train_D1, y_train_D1, validation_data=(X_test_D1, y_test_D1),\n",
    "                    epochs=30,batch_size=64)\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=1,batch_size=64)\n",
    "print(\"Performances after Epoch: 1\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=9,batch_size=64)\n",
    "print(\"Performances after Epoch: 10\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=20,batch_size=64)\n",
    "print(\"Performances after Epoch: 30\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Adding Half More Classes ====\n",
      "class dict D1:  {0, 1, 2, 3, 4, 5, 6, 7, 8}\n",
      "class dict D2:  {9, 10, 11, 12, 13, 14, 15, 16}\n",
      "Train on 6958 samples, validate on 900 samples\n",
      "Epoch 1/30\n",
      "6958/6958 [==============================] - 8s 1ms/step - loss: 1.7994 - sparse_categorical_accuracy: 0.2639 - val_loss: 1.5429 - val_sparse_categorical_accuracy: 0.2544\n",
      "Epoch 2/30\n",
      "6958/6958 [==============================] - 6s 903us/step - loss: 1.3379 - sparse_categorical_accuracy: 0.3977 - val_loss: 1.6019 - val_sparse_categorical_accuracy: 0.3800\n",
      "Epoch 3/30\n",
      "6958/6958 [==============================] - 7s 975us/step - loss: 1.2219 - sparse_categorical_accuracy: 0.4363 - val_loss: 1.2602 - val_sparse_categorical_accuracy: 0.4611\n",
      "Epoch 4/30\n",
      "6958/6958 [==============================] - 6s 912us/step - loss: 1.1671 - sparse_categorical_accuracy: 0.4665 - val_loss: 1.1850 - val_sparse_categorical_accuracy: 0.5067\n",
      "Epoch 5/30\n",
      "6958/6958 [==============================] - 6s 876us/step - loss: 1.0807 - sparse_categorical_accuracy: 0.5082 - val_loss: 1.2277 - val_sparse_categorical_accuracy: 0.5067\n",
      "Epoch 6/30\n",
      "6958/6958 [==============================] - 7s 956us/step - loss: 1.0287 - sparse_categorical_accuracy: 0.5410 - val_loss: 1.1184 - val_sparse_categorical_accuracy: 0.4900\n",
      "Epoch 7/30\n",
      "6958/6958 [==============================] - 6s 928us/step - loss: 0.9490 - sparse_categorical_accuracy: 0.5744 - val_loss: 1.0121 - val_sparse_categorical_accuracy: 0.5800\n",
      "Epoch 8/30\n",
      "6958/6958 [==============================] - 6s 928us/step - loss: 0.9403 - sparse_categorical_accuracy: 0.5755 - val_loss: 1.0086 - val_sparse_categorical_accuracy: 0.5744\n",
      "Epoch 9/30\n",
      "6958/6958 [==============================] - 7s 1ms/step - loss: 0.8758 - sparse_categorical_accuracy: 0.6089 - val_loss: 1.0058 - val_sparse_categorical_accuracy: 0.5922\n",
      "Epoch 10/30\n",
      "6958/6958 [==============================] - 7s 1ms/step - loss: 0.8305 - sparse_categorical_accuracy: 0.6407 - val_loss: 0.9666 - val_sparse_categorical_accuracy: 0.6067\n",
      "Epoch 11/30\n",
      "6958/6958 [==============================] - 8s 1ms/step - loss: 0.8046 - sparse_categorical_accuracy: 0.6552 - val_loss: 0.7948 - val_sparse_categorical_accuracy: 0.6744\n",
      "Epoch 12/30\n",
      "6958/6958 [==============================] - 6s 894us/step - loss: 0.7932 - sparse_categorical_accuracy: 0.6485 - val_loss: 0.8182 - val_sparse_categorical_accuracy: 0.6589\n",
      "Epoch 13/30\n",
      "6958/6958 [==============================] - 6s 897us/step - loss: 0.7345 - sparse_categorical_accuracy: 0.6821 - val_loss: 0.8005 - val_sparse_categorical_accuracy: 0.6400\n",
      "Epoch 14/30\n",
      "6958/6958 [==============================] - 6s 906us/step - loss: 0.6987 - sparse_categorical_accuracy: 0.7037 - val_loss: 0.7961 - val_sparse_categorical_accuracy: 0.6656\n",
      "Epoch 15/30\n",
      "6958/6958 [==============================] - 5s 748us/step - loss: 0.6927 - sparse_categorical_accuracy: 0.7019 - val_loss: 0.7645 - val_sparse_categorical_accuracy: 0.6767\n",
      "Epoch 16/30\n",
      "6958/6958 [==============================] - 5s 743us/step - loss: 0.6578 - sparse_categorical_accuracy: 0.7225 - val_loss: 0.7328 - val_sparse_categorical_accuracy: 0.7033\n",
      "Epoch 17/30\n",
      "6958/6958 [==============================] - 5s 749us/step - loss: 0.6716 - sparse_categorical_accuracy: 0.7160 - val_loss: 0.8171 - val_sparse_categorical_accuracy: 0.6289\n",
      "Epoch 18/30\n",
      "6958/6958 [==============================] - 6s 851us/step - loss: 0.6380 - sparse_categorical_accuracy: 0.7258 - val_loss: 0.8266 - val_sparse_categorical_accuracy: 0.6678\n",
      "Epoch 19/30\n",
      "6958/6958 [==============================] - 8s 1ms/step - loss: 0.6044 - sparse_categorical_accuracy: 0.7456 - val_loss: 0.7033 - val_sparse_categorical_accuracy: 0.7089\n",
      "Epoch 20/30\n",
      "6958/6958 [==============================] - 6s 889us/step - loss: 0.5803 - sparse_categorical_accuracy: 0.7575 - val_loss: 0.6924 - val_sparse_categorical_accuracy: 0.7167\n",
      "Epoch 21/30\n",
      "6958/6958 [==============================] - 7s 940us/step - loss: 0.5497 - sparse_categorical_accuracy: 0.7742 - val_loss: 0.8679 - val_sparse_categorical_accuracy: 0.6378\n",
      "Epoch 22/30\n",
      "6958/6958 [==============================] - 5s 784us/step - loss: 0.5786 - sparse_categorical_accuracy: 0.7588 - val_loss: 0.6575 - val_sparse_categorical_accuracy: 0.7311\n",
      "Epoch 23/30\n",
      "6958/6958 [==============================] - 6s 808us/step - loss: 0.5241 - sparse_categorical_accuracy: 0.7824 - val_loss: 0.6776 - val_sparse_categorical_accuracy: 0.7200\n",
      "Epoch 24/30\n",
      "6958/6958 [==============================] - 5s 765us/step - loss: 0.5086 - sparse_categorical_accuracy: 0.7902 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.7267\n",
      "Epoch 25/30\n",
      "6958/6958 [==============================] - 5s 786us/step - loss: 0.5052 - sparse_categorical_accuracy: 0.7884 - val_loss: 0.7558 - val_sparse_categorical_accuracy: 0.6878\n",
      "Epoch 26/30\n",
      "6958/6958 [==============================] - 5s 764us/step - loss: 0.4813 - sparse_categorical_accuracy: 0.8037 - val_loss: 0.6001 - val_sparse_categorical_accuracy: 0.7556\n",
      "Epoch 27/30\n",
      "6958/6958 [==============================] - 5s 757us/step - loss: 0.4894 - sparse_categorical_accuracy: 0.8001 - val_loss: 0.7157 - val_sparse_categorical_accuracy: 0.7178\n",
      "Epoch 28/30\n",
      "6958/6958 [==============================] - 5s 744us/step - loss: 0.4636 - sparse_categorical_accuracy: 0.8126 - val_loss: 0.8093 - val_sparse_categorical_accuracy: 0.6733\n",
      "Epoch 29/30\n",
      "6958/6958 [==============================] - 6s 803us/step - loss: 0.4509 - sparse_categorical_accuracy: 0.8109 - val_loss: 0.6049 - val_sparse_categorical_accuracy: 0.7456\n",
      "Epoch 30/30\n",
      "6958/6958 [==============================] - 5s 751us/step - loss: 0.4421 - sparse_categorical_accuracy: 0.8186 - val_loss: 0.6634 - val_sparse_categorical_accuracy: 0.7200\n",
      "Train on 7189 samples, validate on 1657 samples\n",
      "Epoch 1/1\n",
      "7189/7189 [==============================] - 6s 774us/step - loss: 1.2664 - sparse_categorical_accuracy: 0.5877 - val_loss: 4.9438 - val_sparse_categorical_accuracy: 0.2740\n",
      "Performances after Epoch: 1\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 0.599736\n",
      "Train on 7189 samples, validate on 1657 samples\n",
      "Epoch 1/9\n",
      "7189/7189 [==============================] - 6s 869us/step - loss: 0.6756 - sparse_categorical_accuracy: 0.7175 - val_loss: 4.9526 - val_sparse_categorical_accuracy: 0.2589\n",
      "Epoch 2/9\n",
      "7189/7189 [==============================] - 7s 1ms/step - loss: 0.6341 - sparse_categorical_accuracy: 0.7409 - val_loss: 4.7019 - val_sparse_categorical_accuracy: 0.3199\n",
      "Epoch 3/9\n",
      "7189/7189 [==============================] - 7s 1ms/step - loss: 0.5235 - sparse_categorical_accuracy: 0.7813 - val_loss: 4.3870 - val_sparse_categorical_accuracy: 0.3205\n",
      "Epoch 4/9\n",
      "7189/7189 [==============================] - 8s 1ms/step - loss: 0.4953 - sparse_categorical_accuracy: 0.7958 - val_loss: 4.0064 - val_sparse_categorical_accuracy: 0.3295\n",
      "Epoch 5/9\n",
      "7189/7189 [==============================] - 7s 988us/step - loss: 0.4728 - sparse_categorical_accuracy: 0.7972 - val_loss: 4.2700 - val_sparse_categorical_accuracy: 0.3361\n",
      "Epoch 6/9\n",
      "7189/7189 [==============================] - 6s 800us/step - loss: 0.4612 - sparse_categorical_accuracy: 0.8089 - val_loss: 4.0466 - val_sparse_categorical_accuracy: 0.3241\n",
      "Epoch 7/9\n",
      "7189/7189 [==============================] - 6s 775us/step - loss: 0.4594 - sparse_categorical_accuracy: 0.8055 - val_loss: 4.0745 - val_sparse_categorical_accuracy: 0.3422\n",
      "Epoch 8/9\n",
      "7189/7189 [==============================] - 6s 786us/step - loss: 0.4279 - sparse_categorical_accuracy: 0.8186 - val_loss: 4.3244 - val_sparse_categorical_accuracy: 0.3500\n",
      "Epoch 9/9\n",
      "7189/7189 [==============================] - 6s 784us/step - loss: 0.4084 - sparse_categorical_accuracy: 0.8272 - val_loss: 4.1329 - val_sparse_categorical_accuracy: 0.3476\n",
      "Performances after Epoch: 10\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 0.760898\n",
      "Train on 7189 samples, validate on 1657 samples\n",
      "Epoch 1/20\n",
      "7189/7189 [==============================] - 6s 790us/step - loss: 0.4198 - sparse_categorical_accuracy: 0.8221 - val_loss: 4.2446 - val_sparse_categorical_accuracy: 0.3506\n",
      "Epoch 2/20\n",
      "7189/7189 [==============================] - 5s 764us/step - loss: 0.3857 - sparse_categorical_accuracy: 0.8366 - val_loss: 4.4594 - val_sparse_categorical_accuracy: 0.3579\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7189/7189 [==============================] - 6s 768us/step - loss: 0.4114 - sparse_categorical_accuracy: 0.8264 - val_loss: 4.6440 - val_sparse_categorical_accuracy: 0.3518\n",
      "Epoch 4/20\n",
      "7189/7189 [==============================] - 5s 764us/step - loss: 0.3643 - sparse_categorical_accuracy: 0.8487 - val_loss: 4.7212 - val_sparse_categorical_accuracy: 0.3331\n",
      "Epoch 5/20\n",
      "7189/7189 [==============================] - 6s 770us/step - loss: 0.3667 - sparse_categorical_accuracy: 0.8457 - val_loss: 4.4708 - val_sparse_categorical_accuracy: 0.3585\n",
      "Epoch 6/20\n",
      "7189/7189 [==============================] - 5s 761us/step - loss: 0.3852 - sparse_categorical_accuracy: 0.8360 - val_loss: 4.6103 - val_sparse_categorical_accuracy: 0.3530\n",
      "Epoch 7/20\n",
      "7189/7189 [==============================] - 5s 762us/step - loss: 0.4077 - sparse_categorical_accuracy: 0.8221 - val_loss: 4.0302 - val_sparse_categorical_accuracy: 0.3150\n",
      "Epoch 8/20\n",
      "7189/7189 [==============================] - 6s 807us/step - loss: 0.3551 - sparse_categorical_accuracy: 0.8445 - val_loss: 4.5560 - val_sparse_categorical_accuracy: 0.3675\n",
      "Epoch 9/20\n",
      "7189/7189 [==============================] - 6s 866us/step - loss: 0.3318 - sparse_categorical_accuracy: 0.8649 - val_loss: 4.3495 - val_sparse_categorical_accuracy: 0.3669\n",
      "Epoch 10/20\n",
      "7189/7189 [==============================] - 6s 868us/step - loss: 0.3431 - sparse_categorical_accuracy: 0.8563 - val_loss: 4.1162 - val_sparse_categorical_accuracy: 0.3494\n",
      "Epoch 11/20\n",
      "7189/7189 [==============================] - 6s 878us/step - loss: 0.3262 - sparse_categorical_accuracy: 0.8616 - val_loss: 4.2329 - val_sparse_categorical_accuracy: 0.3567\n",
      "Epoch 12/20\n",
      "7189/7189 [==============================] - 6s 855us/step - loss: 0.3444 - sparse_categorical_accuracy: 0.8537 - val_loss: 4.7025 - val_sparse_categorical_accuracy: 0.3609\n",
      "Epoch 13/20\n",
      "7189/7189 [==============================] - 7s 905us/step - loss: 0.3490 - sparse_categorical_accuracy: 0.8553 - val_loss: 4.8174 - val_sparse_categorical_accuracy: 0.3766\n",
      "Epoch 14/20\n",
      "7189/7189 [==============================] - 6s 827us/step - loss: 0.3148 - sparse_categorical_accuracy: 0.8684 - val_loss: 4.5088 - val_sparse_categorical_accuracy: 0.3651\n",
      "Epoch 15/20\n",
      "7189/7189 [==============================] - 6s 800us/step - loss: 0.3410 - sparse_categorical_accuracy: 0.8601 - val_loss: 4.7751 - val_sparse_categorical_accuracy: 0.3681\n",
      "Epoch 16/20\n",
      "7189/7189 [==============================] - 6s 785us/step - loss: 0.3089 - sparse_categorical_accuracy: 0.8687 - val_loss: 4.3494 - val_sparse_categorical_accuracy: 0.3766\n",
      "Epoch 17/20\n",
      "7189/7189 [==============================] - 5s 761us/step - loss: 0.3283 - sparse_categorical_accuracy: 0.8627 - val_loss: 4.2832 - val_sparse_categorical_accuracy: 0.3693\n",
      "Epoch 18/20\n",
      "7189/7189 [==============================] - 6s 778us/step - loss: 0.2937 - sparse_categorical_accuracy: 0.8802 - val_loss: 4.6059 - val_sparse_categorical_accuracy: 0.3705\n",
      "Epoch 19/20\n",
      "7189/7189 [==============================] - 6s 773us/step - loss: 0.3059 - sparse_categorical_accuracy: 0.8781 - val_loss: 4.4308 - val_sparse_categorical_accuracy: 0.3573\n",
      "Epoch 20/20\n",
      "7189/7189 [==============================] - 6s 774us/step - loss: 0.3084 - sparse_categorical_accuracy: 0.8713 - val_loss: 4.7247 - val_sparse_categorical_accuracy: 0.3657\n",
      "Performances after Epoch: 30\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 0.800528\n"
     ]
    }
   ],
   "source": [
    "class_dict_D2 = {9,10,11,12,13,14,15,16}\n",
    "class_dict_D1 = makeClassDictD1(class_dict_D2, num_classes)\n",
    "print(\"==== Adding Half More Classes ====\")\n",
    "print(\"class dict D1: \", class_dict_D1)\n",
    "print(\"class dict D2: \", class_dict_D2)\n",
    "X_train_D1, y_train_D1, X_train_D2, y_train_D2, X_test_D1, y_test_D1, X_test_D2, y_test_D2 = makeDataD2HalfClasses(class_dict_D1, class_dict_D2, X_train, y_train, X_test, y_test)\n",
    "model = vanilaLSTMs()\n",
    "model.fit(X_train_D1, y_train_D1, validation_data=(X_test_D1, y_test_D1),\n",
    "                    epochs=30,batch_size=64)\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=1,batch_size=64)\n",
    "print(\"Performances after Epoch: 1\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=9,batch_size=64)\n",
    "print(\"Performances after Epoch: 10\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=20,batch_size=64)\n",
    "print(\"Performances after Epoch: 30\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Adding Half More Classes ====\n",
      "class dict D1:  {1, 3, 5, 7, 9, 11, 13, 15}\n",
      "class dict D2:  {0, 2, 4, 6, 8, 10, 12, 14, 16}\n",
      "Train on 7850 samples, validate on 861 samples\n",
      "Epoch 1/30\n",
      "7850/7850 [==============================] - 7s 916us/step - loss: 1.1915 - sparse_categorical_accuracy: 0.5559 - val_loss: 1.2393 - val_sparse_categorical_accuracy: 0.5668\n",
      "Epoch 2/30\n",
      "7850/7850 [==============================] - 6s 763us/step - loss: 0.7629 - sparse_categorical_accuracy: 0.6780 - val_loss: 1.0707 - val_sparse_categorical_accuracy: 0.5691\n",
      "Epoch 3/30\n",
      "7850/7850 [==============================] - 6s 742us/step - loss: 0.6801 - sparse_categorical_accuracy: 0.7028 - val_loss: 0.8887 - val_sparse_categorical_accuracy: 0.6341\n",
      "Epoch 4/30\n",
      "7850/7850 [==============================] - 6s 744us/step - loss: 0.5605 - sparse_categorical_accuracy: 0.7650 - val_loss: 0.8103 - val_sparse_categorical_accuracy: 0.7027\n",
      "Epoch 5/30\n",
      "7850/7850 [==============================] - 6s 745us/step - loss: 0.5467 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.7142 - val_sparse_categorical_accuracy: 0.7073\n",
      "Epoch 6/30\n",
      "7850/7850 [==============================] - 6s 758us/step - loss: 0.5091 - sparse_categorical_accuracy: 0.7859 - val_loss: 0.8649 - val_sparse_categorical_accuracy: 0.6736\n",
      "Epoch 7/30\n",
      "7850/7850 [==============================] - 6s 744us/step - loss: 0.4861 - sparse_categorical_accuracy: 0.7994 - val_loss: 0.7505 - val_sparse_categorical_accuracy: 0.6945\n",
      "Epoch 8/30\n",
      "7850/7850 [==============================] - 6s 745us/step - loss: 0.4578 - sparse_categorical_accuracy: 0.8164 - val_loss: 0.7194 - val_sparse_categorical_accuracy: 0.7305\n",
      "Epoch 9/30\n",
      "7850/7850 [==============================] - 6s 739us/step - loss: 0.4411 - sparse_categorical_accuracy: 0.8213 - val_loss: 0.6358 - val_sparse_categorical_accuracy: 0.7503\n",
      "Epoch 10/30\n",
      "7850/7850 [==============================] - 6s 742us/step - loss: 0.4160 - sparse_categorical_accuracy: 0.8330 - val_loss: 0.7740 - val_sparse_categorical_accuracy: 0.7085\n",
      "Epoch 11/30\n",
      "7850/7850 [==============================] - 6s 745us/step - loss: 0.3804 - sparse_categorical_accuracy: 0.8454 - val_loss: 0.5592 - val_sparse_categorical_accuracy: 0.7758\n",
      "Epoch 12/30\n",
      "7850/7850 [==============================] - 6s 776us/step - loss: 0.3950 - sparse_categorical_accuracy: 0.8399 - val_loss: 0.6486 - val_sparse_categorical_accuracy: 0.7573\n",
      "Epoch 13/30\n",
      "7850/7850 [==============================] - 6s 766us/step - loss: 0.3675 - sparse_categorical_accuracy: 0.8517 - val_loss: 0.5943 - val_sparse_categorical_accuracy: 0.7747\n",
      "Epoch 14/30\n",
      "7850/7850 [==============================] - 6s 759us/step - loss: 0.3421 - sparse_categorical_accuracy: 0.8642 - val_loss: 0.5045 - val_sparse_categorical_accuracy: 0.8084\n",
      "Epoch 15/30\n",
      "7850/7850 [==============================] - 6s 793us/step - loss: 0.3370 - sparse_categorical_accuracy: 0.8676 - val_loss: 0.4770 - val_sparse_categorical_accuracy: 0.8107\n",
      "Epoch 16/30\n",
      "7850/7850 [==============================] - 6s 802us/step - loss: 0.3056 - sparse_categorical_accuracy: 0.8776 - val_loss: 0.4805 - val_sparse_categorical_accuracy: 0.8130\n",
      "Epoch 17/30\n",
      "7850/7850 [==============================] - 6s 791us/step - loss: 0.3298 - sparse_categorical_accuracy: 0.8688 - val_loss: 0.5275 - val_sparse_categorical_accuracy: 0.8188\n",
      "Epoch 18/30\n",
      "7850/7850 [==============================] - 6s 807us/step - loss: 0.3266 - sparse_categorical_accuracy: 0.8717 - val_loss: 0.4767 - val_sparse_categorical_accuracy: 0.8269\n",
      "Epoch 19/30\n",
      "7850/7850 [==============================] - 7s 844us/step - loss: 0.3043 - sparse_categorical_accuracy: 0.8768 - val_loss: 0.4353 - val_sparse_categorical_accuracy: 0.8328\n",
      "Epoch 20/30\n",
      "7850/7850 [==============================] - 7s 862us/step - loss: 0.2739 - sparse_categorical_accuracy: 0.8967 - val_loss: 0.4288 - val_sparse_categorical_accuracy: 0.8595\n",
      "Epoch 21/30\n",
      "7850/7850 [==============================] - 7s 936us/step - loss: 0.2894 - sparse_categorical_accuracy: 0.8847 - val_loss: 0.5379 - val_sparse_categorical_accuracy: 0.8014\n",
      "Epoch 22/30\n",
      "7850/7850 [==============================] - 8s 1ms/step - loss: 0.2561 - sparse_categorical_accuracy: 0.9003 - val_loss: 0.4120 - val_sparse_categorical_accuracy: 0.8513\n",
      "Epoch 23/30\n",
      "7850/7850 [==============================] - 8s 1ms/step - loss: 0.2547 - sparse_categorical_accuracy: 0.9022 - val_loss: 0.4646 - val_sparse_categorical_accuracy: 0.8316\n",
      "Epoch 24/30\n",
      "7850/7850 [==============================] - 7s 937us/step - loss: 0.2647 - sparse_categorical_accuracy: 0.8961 - val_loss: 0.4151 - val_sparse_categorical_accuracy: 0.8571\n",
      "Epoch 25/30\n",
      "7850/7850 [==============================] - 10s 1ms/step - loss: 0.2498 - sparse_categorical_accuracy: 0.9017 - val_loss: 0.3913 - val_sparse_categorical_accuracy: 0.8606\n",
      "Epoch 26/30\n",
      "7850/7850 [==============================] - 6s 802us/step - loss: 0.2117 - sparse_categorical_accuracy: 0.9219 - val_loss: 0.4157 - val_sparse_categorical_accuracy: 0.8467\n",
      "Epoch 27/30\n",
      "7850/7850 [==============================] - 6s 793us/step - loss: 0.2229 - sparse_categorical_accuracy: 0.9141 - val_loss: 0.4683 - val_sparse_categorical_accuracy: 0.8386\n",
      "Epoch 28/30\n",
      "7850/7850 [==============================] - 6s 781us/step - loss: 0.2217 - sparse_categorical_accuracy: 0.9158 - val_loss: 0.4248 - val_sparse_categorical_accuracy: 0.8525\n",
      "Epoch 29/30\n",
      "7850/7850 [==============================] - 12s 2ms/step - loss: 0.2363 - sparse_categorical_accuracy: 0.9098 - val_loss: 0.6222 - val_sparse_categorical_accuracy: 0.7828\n",
      "Epoch 30/30\n",
      "7850/7850 [==============================] - 9s 1ms/step - loss: 0.2202 - sparse_categorical_accuracy: 0.9148 - val_loss: 0.4011 - val_sparse_categorical_accuracy: 0.8815\n",
      "Train on 6297 samples, validate on 1657 samples\n",
      "Epoch 1/1\n",
      "6297/6297 [==============================] - 7s 1ms/step - loss: 1.8873 - sparse_categorical_accuracy: 0.3240 - val_loss: 4.4671 - val_sparse_categorical_accuracy: 0.2770\n",
      "Performances after Epoch: 1\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 0.576633\n",
      "Train on 6297 samples, validate on 1657 samples\n",
      "Epoch 1/9\n",
      "6297/6297 [==============================] - 6s 887us/step - loss: 1.0820 - sparse_categorical_accuracy: 0.5703 - val_loss: 4.2717 - val_sparse_categorical_accuracy: 0.2432\n",
      "Epoch 2/9\n",
      "6297/6297 [==============================] - 5s 854us/step - loss: 0.8856 - sparse_categorical_accuracy: 0.6552 - val_loss: 4.1785 - val_sparse_categorical_accuracy: 0.3168\n",
      "Epoch 3/9\n",
      "6297/6297 [==============================] - 5s 854us/step - loss: 0.7487 - sparse_categorical_accuracy: 0.7118 - val_loss: 4.2210 - val_sparse_categorical_accuracy: 0.3512\n",
      "Epoch 4/9\n",
      "6297/6297 [==============================] - 5s 860us/step - loss: 0.6153 - sparse_categorical_accuracy: 0.7673 - val_loss: 4.3205 - val_sparse_categorical_accuracy: 0.3126\n",
      "Epoch 5/9\n",
      "6297/6297 [==============================] - 5s 850us/step - loss: 0.5940 - sparse_categorical_accuracy: 0.7756 - val_loss: 4.3977 - val_sparse_categorical_accuracy: 0.3549\n",
      "Epoch 6/9\n",
      "6297/6297 [==============================] - 5s 861us/step - loss: 0.5410 - sparse_categorical_accuracy: 0.7939 - val_loss: 4.1226 - val_sparse_categorical_accuracy: 0.3681\n",
      "Epoch 7/9\n",
      "6297/6297 [==============================] - 8s 1ms/step - loss: 0.4890 - sparse_categorical_accuracy: 0.8186 - val_loss: 4.5906 - val_sparse_categorical_accuracy: 0.3591\n",
      "Epoch 8/9\n",
      "6297/6297 [==============================] - 7s 1ms/step - loss: 0.4703 - sparse_categorical_accuracy: 0.8232 - val_loss: 4.8554 - val_sparse_categorical_accuracy: 0.3368\n",
      "Epoch 9/9\n",
      "6297/6297 [==============================] - 5s 863us/step - loss: 0.4587 - sparse_categorical_accuracy: 0.8258 - val_loss: 4.5924 - val_sparse_categorical_accuracy: 0.3410\n",
      "Performances after Epoch: 10\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 0.709799\n",
      "Train on 6297 samples, validate on 1657 samples\n",
      "Epoch 1/20\n",
      "6297/6297 [==============================] - 5s 860us/step - loss: 0.4460 - sparse_categorical_accuracy: 0.8301 - val_loss: 4.6926 - val_sparse_categorical_accuracy: 0.3549\n",
      "Epoch 2/20\n",
      "6297/6297 [==============================] - 5s 855us/step - loss: 0.4112 - sparse_categorical_accuracy: 0.8490 - val_loss: 4.7942 - val_sparse_categorical_accuracy: 0.3669\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6297/6297 [==============================] - 5s 851us/step - loss: 0.4025 - sparse_categorical_accuracy: 0.8491 - val_loss: 4.8364 - val_sparse_categorical_accuracy: 0.3500\n",
      "Epoch 4/20\n",
      "6297/6297 [==============================] - 5s 848us/step - loss: 0.4253 - sparse_categorical_accuracy: 0.8418 - val_loss: 4.4396 - val_sparse_categorical_accuracy: 0.3162\n",
      "Epoch 5/20\n",
      "6297/6297 [==============================] - 7s 1ms/step - loss: 0.3495 - sparse_categorical_accuracy: 0.8722 - val_loss: 4.7724 - val_sparse_categorical_accuracy: 0.3621\n",
      "Epoch 6/20\n",
      "6297/6297 [==============================] - 7s 1ms/step - loss: 0.3518 - sparse_categorical_accuracy: 0.8745 - val_loss: 4.8621 - val_sparse_categorical_accuracy: 0.3543\n",
      "Epoch 7/20\n",
      "6297/6297 [==============================] - 5s 859us/step - loss: 0.3712 - sparse_categorical_accuracy: 0.8655 - val_loss: 4.8322 - val_sparse_categorical_accuracy: 0.3784\n",
      "Epoch 8/20\n",
      "6297/6297 [==============================] - 5s 850us/step - loss: 0.3424 - sparse_categorical_accuracy: 0.8780 - val_loss: 4.7914 - val_sparse_categorical_accuracy: 0.3778\n",
      "Epoch 9/20\n",
      "6297/6297 [==============================] - 5s 862us/step - loss: 0.3486 - sparse_categorical_accuracy: 0.8710 - val_loss: 4.9583 - val_sparse_categorical_accuracy: 0.3874\n",
      "Epoch 10/20\n",
      "6297/6297 [==============================] - 5s 853us/step - loss: 0.3459 - sparse_categorical_accuracy: 0.8741 - val_loss: 4.7878 - val_sparse_categorical_accuracy: 0.3772\n",
      "Epoch 11/20\n",
      "6297/6297 [==============================] - 5s 861us/step - loss: 0.2784 - sparse_categorical_accuracy: 0.9014 - val_loss: 4.9011 - val_sparse_categorical_accuracy: 0.3766\n",
      "Epoch 12/20\n",
      "6297/6297 [==============================] - 5s 852us/step - loss: 0.3096 - sparse_categorical_accuracy: 0.8890 - val_loss: 4.7615 - val_sparse_categorical_accuracy: 0.3826\n",
      "Epoch 13/20\n",
      "6297/6297 [==============================] - 5s 865us/step - loss: 0.2793 - sparse_categorical_accuracy: 0.8982 - val_loss: 5.2859 - val_sparse_categorical_accuracy: 0.3766\n",
      "Epoch 14/20\n",
      "6297/6297 [==============================] - 5s 873us/step - loss: 0.2980 - sparse_categorical_accuracy: 0.8933 - val_loss: 4.9655 - val_sparse_categorical_accuracy: 0.3826\n",
      "Epoch 15/20\n",
      "6297/6297 [==============================] - 5s 860us/step - loss: 0.2906 - sparse_categorical_accuracy: 0.8982 - val_loss: 4.7734 - val_sparse_categorical_accuracy: 0.3687\n",
      "Epoch 16/20\n",
      "6297/6297 [==============================] - 5s 858us/step - loss: 0.2816 - sparse_categorical_accuracy: 0.9009 - val_loss: 5.1479 - val_sparse_categorical_accuracy: 0.3802\n",
      "Epoch 17/20\n",
      "6297/6297 [==============================] - 5s 844us/step - loss: 0.2824 - sparse_categorical_accuracy: 0.8985 - val_loss: 4.9233 - val_sparse_categorical_accuracy: 0.3929\n",
      "Epoch 18/20\n",
      "6297/6297 [==============================] - 6s 875us/step - loss: 0.2822 - sparse_categorical_accuracy: 0.8993 - val_loss: 5.3334 - val_sparse_categorical_accuracy: 0.3856\n",
      "Epoch 19/20\n",
      "6297/6297 [==============================] - 9s 1ms/step - loss: 0.2676 - sparse_categorical_accuracy: 0.9017 - val_loss: 5.1362 - val_sparse_categorical_accuracy: 0.3911\n",
      "Epoch 20/20\n",
      "6297/6297 [==============================] - 5s 861us/step - loss: 0.2554 - sparse_categorical_accuracy: 0.9079 - val_loss: 5.2287 - val_sparse_categorical_accuracy: 0.4007\n",
      "Performances after Epoch: 30\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 0.834171\n"
     ]
    }
   ],
   "source": [
    "class_dict_D2 = {0,2,4,6,8,10,12,14,16}\n",
    "class_dict_D1 = makeClassDictD1(class_dict_D2, num_classes)\n",
    "print(\"==== Adding Half More Classes ====\")\n",
    "print(\"class dict D1: \", class_dict_D1)\n",
    "print(\"class dict D2: \", class_dict_D2)\n",
    "X_train_D1, y_train_D1, X_train_D2, y_train_D2, X_test_D1, y_test_D1, X_test_D2, y_test_D2 = makeDataD2HalfClasses(class_dict_D1, class_dict_D2, X_train, y_train, X_test, y_test)\n",
    "model = vanilaLSTMs()\n",
    "model.fit(X_train_D1, y_train_D1, validation_data=(X_test_D1, y_test_D1),\n",
    "                    epochs=30,batch_size=64)\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=1,batch_size=64)\n",
    "print(\"Performances after Epoch: 1\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=9,batch_size=64)\n",
    "print(\"Performances after Epoch: 10\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=20,batch_size=64)\n",
    "print(\"Performances after Epoch: 30\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Adding Half More Classes ====\n",
      "class dict D1:  {0, 2, 4, 6, 8, 10, 12, 14, 16}\n",
      "class dict D2:  {1, 3, 5, 7, 9, 11, 13, 15}\n",
      "Train on 6297 samples, validate on 796 samples\n",
      "Epoch 1/30\n",
      "6297/6297 [==============================] - 7s 1ms/step - loss: 1.8309 - sparse_categorical_accuracy: 0.2868 - val_loss: 1.4458 - val_sparse_categorical_accuracy: 0.5101\n",
      "Epoch 2/30\n",
      "6297/6297 [==============================] - 5s 826us/step - loss: 1.4024 - sparse_categorical_accuracy: 0.4359 - val_loss: 1.3533 - val_sparse_categorical_accuracy: 0.5025\n",
      "Epoch 3/30\n",
      "6297/6297 [==============================] - 5s 830us/step - loss: 1.1791 - sparse_categorical_accuracy: 0.5206 - val_loss: 1.4285 - val_sparse_categorical_accuracy: 0.4636\n",
      "Epoch 4/30\n",
      "6297/6297 [==============================] - 5s 835us/step - loss: 1.0040 - sparse_categorical_accuracy: 0.5865 - val_loss: 1.2096 - val_sparse_categorical_accuracy: 0.5214\n",
      "Epoch 5/30\n",
      "6297/6297 [==============================] - 6s 1ms/step - loss: 0.9053 - sparse_categorical_accuracy: 0.6311 - val_loss: 1.1116 - val_sparse_categorical_accuracy: 0.5302\n",
      "Epoch 6/30\n",
      "6297/6297 [==============================] - 8s 1ms/step - loss: 0.8512 - sparse_categorical_accuracy: 0.6549 - val_loss: 1.1749 - val_sparse_categorical_accuracy: 0.5854\n",
      "Epoch 7/30\n",
      "6297/6297 [==============================] - 5s 829us/step - loss: 0.7569 - sparse_categorical_accuracy: 0.6852 - val_loss: 0.8964 - val_sparse_categorical_accuracy: 0.6646\n",
      "Epoch 8/30\n",
      "6297/6297 [==============================] - 5s 826us/step - loss: 0.6822 - sparse_categorical_accuracy: 0.7230 - val_loss: 0.8222 - val_sparse_categorical_accuracy: 0.6470\n",
      "Epoch 9/30\n",
      "6297/6297 [==============================] - 5s 821us/step - loss: 0.6121 - sparse_categorical_accuracy: 0.7532 - val_loss: 0.8809 - val_sparse_categorical_accuracy: 0.6608\n",
      "Epoch 10/30\n",
      "6297/6297 [==============================] - 6s 923us/step - loss: 0.6042 - sparse_categorical_accuracy: 0.7593 - val_loss: 0.8000 - val_sparse_categorical_accuracy: 0.6997\n",
      "Epoch 11/30\n",
      "6297/6297 [==============================] - 5s 840us/step - loss: 0.5544 - sparse_categorical_accuracy: 0.7823 - val_loss: 0.8480 - val_sparse_categorical_accuracy: 0.6533\n",
      "Epoch 12/30\n",
      "6297/6297 [==============================] - 5s 821us/step - loss: 0.5556 - sparse_categorical_accuracy: 0.7781 - val_loss: 0.7993 - val_sparse_categorical_accuracy: 0.6595\n",
      "Epoch 13/30\n",
      "6297/6297 [==============================] - 5s 853us/step - loss: 0.4822 - sparse_categorical_accuracy: 0.8125 - val_loss: 0.7745 - val_sparse_categorical_accuracy: 0.7048\n",
      "Epoch 14/30\n",
      "6297/6297 [==============================] - 5s 809us/step - loss: 0.4666 - sparse_categorical_accuracy: 0.8212 - val_loss: 0.7757 - val_sparse_categorical_accuracy: 0.6897\n",
      "Epoch 15/30\n",
      "6297/6297 [==============================] - 5s 817us/step - loss: 0.4618 - sparse_categorical_accuracy: 0.8231 - val_loss: 0.7032 - val_sparse_categorical_accuracy: 0.7286\n",
      "Epoch 16/30\n",
      "6297/6297 [==============================] - 5s 831us/step - loss: 0.4684 - sparse_categorical_accuracy: 0.8150 - val_loss: 0.9335 - val_sparse_categorical_accuracy: 0.6482\n",
      "Epoch 17/30\n",
      "6297/6297 [==============================] - 5s 870us/step - loss: 0.4368 - sparse_categorical_accuracy: 0.8345 - val_loss: 0.6750 - val_sparse_categorical_accuracy: 0.7312\n",
      "Epoch 18/30\n",
      "6297/6297 [==============================] - 5s 826us/step - loss: 0.4336 - sparse_categorical_accuracy: 0.8307 - val_loss: 0.7846 - val_sparse_categorical_accuracy: 0.6696\n",
      "Epoch 19/30\n",
      "6297/6297 [==============================] - 7s 1ms/step - loss: 0.4052 - sparse_categorical_accuracy: 0.8426 - val_loss: 0.7019 - val_sparse_categorical_accuracy: 0.7425\n",
      "Epoch 20/30\n",
      "6297/6297 [==============================] - 7s 1ms/step - loss: 0.3754 - sparse_categorical_accuracy: 0.8572 - val_loss: 0.7288 - val_sparse_categorical_accuracy: 0.7312\n",
      "Epoch 21/30\n",
      "6297/6297 [==============================] - 5s 832us/step - loss: 0.4149 - sparse_categorical_accuracy: 0.8463 - val_loss: 0.6007 - val_sparse_categorical_accuracy: 0.7789\n",
      "Epoch 22/30\n",
      "6297/6297 [==============================] - 5s 842us/step - loss: 0.3584 - sparse_categorical_accuracy: 0.8595 - val_loss: 0.5978 - val_sparse_categorical_accuracy: 0.7827\n",
      "Epoch 23/30\n",
      "6297/6297 [==============================] - 5s 819us/step - loss: 0.3265 - sparse_categorical_accuracy: 0.8806 - val_loss: 0.8592 - val_sparse_categorical_accuracy: 0.6809\n",
      "Epoch 24/30\n",
      "6297/6297 [==============================] - 5s 827us/step - loss: 0.3485 - sparse_categorical_accuracy: 0.8728 - val_loss: 0.6048 - val_sparse_categorical_accuracy: 0.7902\n",
      "Epoch 25/30\n",
      "6297/6297 [==============================] - 5s 850us/step - loss: 0.3836 - sparse_categorical_accuracy: 0.8550 - val_loss: 0.5885 - val_sparse_categorical_accuracy: 0.7764\n",
      "Epoch 26/30\n",
      "6297/6297 [==============================] - 5s 831us/step - loss: 0.3483 - sparse_categorical_accuracy: 0.8699 - val_loss: 0.7027 - val_sparse_categorical_accuracy: 0.7286\n",
      "Epoch 27/30\n",
      "6297/6297 [==============================] - 9s 1ms/step - loss: 0.3137 - sparse_categorical_accuracy: 0.8772 - val_loss: 0.6166 - val_sparse_categorical_accuracy: 0.7663\n",
      "Epoch 28/30\n",
      "6297/6297 [==============================] - 5s 827us/step - loss: 0.3074 - sparse_categorical_accuracy: 0.8841 - val_loss: 1.0824 - val_sparse_categorical_accuracy: 0.6294\n",
      "Epoch 29/30\n",
      "6297/6297 [==============================] - 5s 837us/step - loss: 0.3128 - sparse_categorical_accuracy: 0.8825 - val_loss: 0.5482 - val_sparse_categorical_accuracy: 0.7952\n",
      "Epoch 30/30\n",
      "6297/6297 [==============================] - 5s 825us/step - loss: 0.3213 - sparse_categorical_accuracy: 0.8818 - val_loss: 0.7390 - val_sparse_categorical_accuracy: 0.7211\n",
      "Train on 7850 samples, validate on 1657 samples\n",
      "Epoch 1/1\n",
      "7850/7850 [==============================] - 7s 840us/step - loss: 1.1172 - sparse_categorical_accuracy: 0.6236 - val_loss: 3.7000 - val_sparse_categorical_accuracy: 0.3361\n",
      "Performances after Epoch: 1\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 0.646922\n",
      "Train on 7850 samples, validate on 1657 samples\n",
      "Epoch 1/9\n",
      "7850/7850 [==============================] - 7s 843us/step - loss: 0.5571 - sparse_categorical_accuracy: 0.7710 - val_loss: 3.8687 - val_sparse_categorical_accuracy: 0.3597\n",
      "Epoch 2/9\n",
      "7850/7850 [==============================] - 7s 834us/step - loss: 0.4592 - sparse_categorical_accuracy: 0.8079 - val_loss: 4.0991 - val_sparse_categorical_accuracy: 0.3995\n",
      "Epoch 3/9\n",
      "7850/7850 [==============================] - 7s 839us/step - loss: 0.4646 - sparse_categorical_accuracy: 0.8108 - val_loss: 3.8350 - val_sparse_categorical_accuracy: 0.3953\n",
      "Epoch 4/9\n",
      "7850/7850 [==============================] - 6s 827us/step - loss: 0.3771 - sparse_categorical_accuracy: 0.8515 - val_loss: 3.8876 - val_sparse_categorical_accuracy: 0.4140\n",
      "Epoch 5/9\n",
      "7850/7850 [==============================] - 7s 849us/step - loss: 0.3732 - sparse_categorical_accuracy: 0.8511 - val_loss: 3.7899 - val_sparse_categorical_accuracy: 0.4212\n",
      "Epoch 6/9\n",
      "7850/7850 [==============================] - 7s 857us/step - loss: 0.3584 - sparse_categorical_accuracy: 0.8600 - val_loss: 3.7881 - val_sparse_categorical_accuracy: 0.3917\n",
      "Epoch 7/9\n",
      "7850/7850 [==============================] - 7s 924us/step - loss: 0.3282 - sparse_categorical_accuracy: 0.8696 - val_loss: 3.8649 - val_sparse_categorical_accuracy: 0.4188\n",
      "Epoch 8/9\n",
      "7850/7850 [==============================] - 10s 1ms/step - loss: 0.3264 - sparse_categorical_accuracy: 0.8736 - val_loss: 3.7711 - val_sparse_categorical_accuracy: 0.4134\n",
      "Epoch 9/9\n",
      "7850/7850 [==============================] - 7s 854us/step - loss: 0.3292 - sparse_categorical_accuracy: 0.8696 - val_loss: 3.8893 - val_sparse_categorical_accuracy: 0.4225\n",
      "Performances after Epoch: 10\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 0.813008\n",
      "Train on 7850 samples, validate on 1657 samples\n",
      "Epoch 1/20\n",
      "7850/7850 [==============================] - 7s 845us/step - loss: 0.2973 - sparse_categorical_accuracy: 0.8856 - val_loss: 4.0604 - val_sparse_categorical_accuracy: 0.4116\n",
      "Epoch 2/20\n",
      "7850/7850 [==============================] - 7s 849us/step - loss: 0.2793 - sparse_categorical_accuracy: 0.8934 - val_loss: 3.8376 - val_sparse_categorical_accuracy: 0.4098\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7850/7850 [==============================] - 7s 843us/step - loss: 0.2730 - sparse_categorical_accuracy: 0.8964 - val_loss: 3.9625 - val_sparse_categorical_accuracy: 0.4448\n",
      "Epoch 4/20\n",
      "7850/7850 [==============================] - 8s 1ms/step - loss: 0.2451 - sparse_categorical_accuracy: 0.9089 - val_loss: 3.9045 - val_sparse_categorical_accuracy: 0.4406\n",
      "Epoch 5/20\n",
      "7850/7850 [==============================] - 9s 1ms/step - loss: 0.2662 - sparse_categorical_accuracy: 0.9025 - val_loss: 3.9545 - val_sparse_categorical_accuracy: 0.4400\n",
      "Epoch 6/20\n",
      "7850/7850 [==============================] - 7s 847us/step - loss: 0.2216 - sparse_categorical_accuracy: 0.9158 - val_loss: 4.0333 - val_sparse_categorical_accuracy: 0.4381\n",
      "Epoch 7/20\n",
      "7850/7850 [==============================] - 7s 836us/step - loss: 0.2398 - sparse_categorical_accuracy: 0.9104 - val_loss: 4.3036 - val_sparse_categorical_accuracy: 0.4550\n",
      "Epoch 8/20\n",
      "7850/7850 [==============================] - 7s 850us/step - loss: 0.2281 - sparse_categorical_accuracy: 0.9152 - val_loss: 4.0934 - val_sparse_categorical_accuracy: 0.4532\n",
      "Epoch 9/20\n",
      "7850/7850 [==============================] - 7s 862us/step - loss: 0.2821 - sparse_categorical_accuracy: 0.8983 - val_loss: 4.0754 - val_sparse_categorical_accuracy: 0.4315\n",
      "Epoch 10/20\n",
      "7850/7850 [==============================] - 7s 831us/step - loss: 0.2032 - sparse_categorical_accuracy: 0.9301 - val_loss: 3.8966 - val_sparse_categorical_accuracy: 0.4327\n",
      "Epoch 11/20\n",
      "7850/7850 [==============================] - 7s 843us/step - loss: 0.2059 - sparse_categorical_accuracy: 0.9213 - val_loss: 3.9338 - val_sparse_categorical_accuracy: 0.4430\n",
      "Epoch 12/20\n",
      "7850/7850 [==============================] - 7s 841us/step - loss: 0.2068 - sparse_categorical_accuracy: 0.9219 - val_loss: 4.2470 - val_sparse_categorical_accuracy: 0.4508\n",
      "Epoch 13/20\n",
      "7850/7850 [==============================] - 7s 841us/step - loss: 0.1970 - sparse_categorical_accuracy: 0.9255 - val_loss: 3.8428 - val_sparse_categorical_accuracy: 0.4581\n",
      "Epoch 14/20\n",
      "7850/7850 [==============================] - 7s 840us/step - loss: 0.1848 - sparse_categorical_accuracy: 0.9311 - val_loss: 4.3924 - val_sparse_categorical_accuracy: 0.4520\n",
      "Epoch 15/20\n",
      "7850/7850 [==============================] - 8s 1ms/step - loss: 0.1906 - sparse_categorical_accuracy: 0.9303 - val_loss: 4.5405 - val_sparse_categorical_accuracy: 0.4285\n",
      "Epoch 16/20\n",
      "7850/7850 [==============================] - 9s 1ms/step - loss: 0.1859 - sparse_categorical_accuracy: 0.9324 - val_loss: 4.2523 - val_sparse_categorical_accuracy: 0.4683\n",
      "Epoch 17/20\n",
      "7850/7850 [==============================] - 7s 859us/step - loss: 0.1609 - sparse_categorical_accuracy: 0.9441 - val_loss: 4.3983 - val_sparse_categorical_accuracy: 0.4647\n",
      "Epoch 18/20\n",
      "7850/7850 [==============================] - 7s 853us/step - loss: 0.1968 - sparse_categorical_accuracy: 0.9310 - val_loss: 4.4209 - val_sparse_categorical_accuracy: 0.4653\n",
      "Epoch 19/20\n",
      "7850/7850 [==============================] - 7s 855us/step - loss: 0.1752 - sparse_categorical_accuracy: 0.9371 - val_loss: 4.6169 - val_sparse_categorical_accuracy: 0.4617\n",
      "Epoch 20/20\n",
      "7850/7850 [==============================] - 7s 835us/step - loss: 0.1597 - sparse_categorical_accuracy: 0.9441 - val_loss: 4.3345 - val_sparse_categorical_accuracy: 0.4617\n",
      "Performances after Epoch: 30\n",
      "acc_D1: 0.000000\n",
      "acc_D2: 0.888502\n"
     ]
    }
   ],
   "source": [
    "class_dict_D2 = {1,3,5,7,9,11,13,15}\n",
    "class_dict_D1 = makeClassDictD1(class_dict_D2, num_classes)\n",
    "print(\"==== Adding Half More Classes ====\")\n",
    "print(\"class dict D1: \", class_dict_D1)\n",
    "print(\"class dict D2: \", class_dict_D2)\n",
    "X_train_D1, y_train_D1, X_train_D2, y_train_D2, X_test_D1, y_test_D1, X_test_D2, y_test_D2 = makeDataD2HalfClasses(class_dict_D1, class_dict_D2, X_train, y_train, X_test, y_test)\n",
    "model = vanilaLSTMs()\n",
    "model.fit(X_train_D1, y_train_D1, validation_data=(X_test_D1, y_test_D1),\n",
    "                    epochs=30,batch_size=64)\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=1,batch_size=64)\n",
    "print(\"Performances after Epoch: 1\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=9,batch_size=64)\n",
    "print(\"Performances after Epoch: 10\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))\n",
    "model.fit(X_train_D2, y_train_D2, validation_data=(X_test, y_test),\n",
    "                    epochs=20,batch_size=64)\n",
    "print(\"Performances after Epoch: 30\")\n",
    "print(\"acc_D1: %f\" %(accuracy_score(y_test_D1, np.argmax(model.predict(X_test_D1), axis=1))))\n",
    "print(\"acc_D2: %f\" %(accuracy_score(y_test_D2, np.argmax(model.predict(X_test_D2), axis=1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbeta(y_true, y_pred, threshold_shift=0):\n",
    "    beta = 2\n",
    "\n",
    "    # just in case of hipster activation at the final layer\n",
    "    y_pred = K.clip(y_pred, 0, 1)\n",
    "\n",
    "    # shifting the prediction threshold from .5 if needed\n",
    "    y_pred_bin = K.round(y_pred + threshold_shift)\n",
    "\n",
    "    tp = K.sum(K.round(y_true * y_pred_bin), axis=1) + K.epsilon()\n",
    "    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)), axis=1)\n",
    "    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    beta_squared = beta ** 2\n",
    "    return K.mean((beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPrepare(rand, df_l):\n",
    "\ttrain_ratio = 0.9\n",
    "\tX_temp, y_res = df_l[0], df_l[1]\n",
    "\tcut = int(X_temp.shape[0] * train_ratio)\n",
    "    \n",
    "\t#labelencoder_y_1 = LabelEncoder()\n",
    "\t#y_res = labelencoder_y_1.fit_transform(y_res)\n",
    "    \n",
    "\ttrain_y = y_res[:cut]\n",
    "\ttest_y = y_res[cut:]\n",
    "\ttrain_X = X_temp[:cut]\n",
    "\ttest_X = X_temp[cut:]\n",
    "\n",
    "\t# train_X = StandardScaler().fit_transform(train_X)\n",
    "\t# test_X = StandardScaler().fit_transform(test_X)\n",
    "\n",
    "\ttrain_X = np.reshape(train_X, (len(train_X),timesteps,-1) )\n",
    "\ttest_X = np.reshape(test_X, (len(test_X),timesteps,-1) )\n",
    "\n",
    "\treturn train_X, train_y, test_X, test_y\n",
    "\n",
    "def runKerasModels(data_name, num_stack, hidden_layer_size, df_l):\n",
    "\tauc_l = []\n",
    "\thist_acc = []\n",
    "\thist_prec = []\n",
    "\thist_rec = []\n",
    "\thist_f1 = []\n",
    "\tpath_name = 'data/mlresultsV_sanity/'\n",
    "\tfor rand in range(1):\n",
    "\t\tbest_model_name = path_name+data_name+'_'+str(rand)+'_best_model_'+str(timesteps)+'0_'+str(num_stack)+'_'+str(hidden_layer_size)+'.h5'\n",
    "\t\ttrain_X, train_y, test_X, test_y = dataPrepare(rand, df_l)\n",
    "\t\tprint(train_X.shape, train_y.shape)\n",
    "        # X = [input_size, timesteps, data_dim]\n",
    "        # y = [input_size, num_classes]\n",
    "\t\tif num_stack == 1:\n",
    "\t\t\t# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "\t\t\tmodel = Sequential()\n",
    "\t\t\tmodel.add(LSTM(hidden_layer_size,input_shape=(timesteps, data_dim),init='glorot_normal'))  # return a single vector of dimension 32\n",
    "\t\t\tmodel.add(Dropout(0.2))\n",
    "\t\t\tmodel.add(Dense(num_classes, activation='softmax', init='glorot_normal'))\n",
    "\t\telif num_stack == 2:\n",
    "\t\t\tmodel = Sequential()\n",
    "\t\t\tmodel.add(LSTM(hidden_layer_size,return_sequences=True,input_shape=(timesteps, data_dim),init='glorot_normal'))  # returns a sequence of vectors of dimension 32\n",
    "\t\t\tmodel.add(LSTM(hidden_layer_size,init='glorot_normal'))  # return a single vector of dimension 32\n",
    "\t\t\tmodel.add(Dropout(0.2))\n",
    "\t\t\tmodel.add(Dense(num_classes, activation='softmax',init='glorot_normal'))\n",
    "\t\telif num_stack == 4:\n",
    "\t\t\tmodel = Sequential()\n",
    "\t\t\tmodel.add(LSTM(hidden_layer_size,return_sequences=True,input_shape=(timesteps, data_dim),init='glorot_normal'))  # returns a sequence of vectors of dimension 32\n",
    "\t\t\tmodel.add(LSTM(hidden_layer_size,return_sequences=True,init='glorot_normal'))  # returns a sequence of vectors of dimension 32\n",
    "\t\t\tmodel.add(LSTM(hidden_layer_size,return_sequences=True,init='glorot_normal'))  # returns a sequence of vectors of dimension 32\n",
    "\t\t\tmodel.add(LSTM(hidden_layer_size,init='glorot_normal'))  # return a single vector of dimension 32\n",
    "\t\t\tmodel.add(Dropout(0.2))\n",
    "\t\t\tmodel.add(Dense(num_classes, activation='softmax',init='glorot_normal'))\n",
    "\t\telse:\n",
    "\t\t\tprint(\"specify the number of stacks\")\n",
    "\t\t# model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "# \t\tmodel.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=[fbeta])\n",
    "\t\tmodel.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['sparse_categorical_accuracy'])\n",
    "\t\t# simple early stopping\n",
    "\t\tes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=60)\n",
    "\t\tmc = ModelCheckpoint(best_model_name, monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\t\thistory = model.fit(train_X, train_y, validation_data=(test_X, test_y),epochs=10,batch_size=64,verbose=0, callbacks=[es, mc])\n",
    "\t\tsaved_model = load_model(best_model_name)\n",
    "\t\ttest_pred = np.argmax(saved_model.predict(test_X), axis=1)\n",
    "\t\tacc = accuracy_score(test_y, test_pred)\n",
    "\t\tprfs = precision_recall_fscore_support(test_y, test_pred)\n",
    "\t\tprint(\"Epoch \", t, \"acc / prec / recall / f1 / supp : \", acc,\" \", prfs)\n",
    "\t\thist_acc.append(acc)\n",
    "\t\thist_prec.append(prfs[0])\n",
    "\t\thist_rec.append(prfs[1])\n",
    "\t\thist_f1.append(prfs[2])        \n",
    "# \t\tauc_score = roc_auc_score(test_y, saved_model.predict(test_X, verbose=0))\n",
    "# \t\tauc_l.append(auc_score)\n",
    "# \t\tprint('AUC score: %f' %(auc_score))\n",
    "\treturn hist_acc, hist_prec, hist_rec, hist_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9894, 24, 113)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12732, 24, 113) (12732,)\n",
      "Epoch  0 acc / prec / recall / f1 / supp :  0.059363957597173146   (array([0.05936396, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        ]), array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0.11207472, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        ]), array([ 84,  96,  58,  64, 165, 147,  53,  62,  37,  30,  31,  29,  47,\n",
      "        62,  47, 363,  40]))\n",
      "final result: # stacks: 2, hidden_layer_size: 64, mean acc: 0.059364, prec: 0.003492, rec: 0.058824, f1: 0.006593\n"
     ]
    }
   ],
   "source": [
    "data_dim = 113 # (# features)\n",
    "num_classes = 17\n",
    "\n",
    "# params\n",
    "timesteps_l = [24]\n",
    "num_stack_l = [2]\n",
    "hidden_layer_size_l = [64]\n",
    "for timesteps in timesteps_l:\n",
    "    for num_stack in num_stack_l:\n",
    "        for hidden_layer_size in hidden_layer_size_l:\n",
    "            # auc_l = runKerasModels('yelp',num_stack, hidden_layer_size, [X_test, y_test])\n",
    "            hist_l = runKerasModels('yelp',num_stack, hidden_layer_size, [X_train, y_train])\n",
    "            print(\"final result: # stacks: %d, hidden_layer_size: %d, mean acc: %f, prec: %f, rec: %f, f1: %f\" %(num_stack,hidden_layer_size,np.mean(hist_l[0]),np.mean(hist_l[1]),np.mean(hist_l[2]),np.mean(hist_l[3])))\n",
    "#             print(hist_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist_acc, label=\"testing acc\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist_p, label=\"testing prec\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist_r, label=\"testing recall\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist_f, label=\"testing f1\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "f1_score() missing 2 required positional arguments: 'labels' and 'predictions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-42e7a3ed96fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glorot_normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: f1_score() missing 2 required positional arguments: 'labels' and 'predictions'"
     ]
    }
   ],
   "source": [
    "data_dim = 113 # (# features)\n",
    "num_classes = 17\n",
    "\n",
    "# params\n",
    "timesteps = 24\n",
    "num_stack = 1\n",
    "hidden_layer_size = 128\n",
    "\n",
    "# train_X, train_y, test_X, test_y = dataPrepare(1, [X_train_D1, y_train_D1])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(hidden_layer_size,input_shape=(timesteps, data_dim),init='glorot_normal'))  # return a single vector of dimension 32\n",
    "# model.add(LSTM(hidden_layer_size,return_sequences=True,input_shape=(timesteps, data_dim),init='glorot_normal'))  # returns a sequence of vectors of dimension 32\n",
    "# model.add(LSTM(hidden_layer_size,init='glorot_normal'))  # return a single vector of dimension 32\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax',init='glorot_normal'))\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=tf.contrib.metrics.f1_score())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch implementation .... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "from argparse import ArgumentParser\n",
    "import numpy as np\n",
    "import torch\n",
    "from data import get_dataset, DATASET_CONFIGS\n",
    "from train import train\n",
    "from model import MLP\n",
    "import utils\n",
    "\n",
    "#####################\n",
    "# Set parameters\n",
    "#####################\n",
    "\n",
    "# Data params\n",
    "noise_var = 0\n",
    "num_datapoints = 100\n",
    "test_size = 0.2\n",
    "num_train = int((1-test_size) * num_datapoints)\n",
    "\n",
    "# Network params\n",
    "input_size = 20\n",
    "# If `per_element` is True, then LSTM reads in one timestep at a time.\n",
    "per_element = True\n",
    "if per_element:\n",
    "    lstm_input_size = 1\n",
    "else:\n",
    "    lstm_input_size = input_size\n",
    "# size of hidden layers\n",
    "h1 = 32\n",
    "output_dim = 1\n",
    "num_layers = 2\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 20\n",
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(113, 128)\n",
       "  (linear): Linear(in_features=128, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################\n",
    "# Build model\n",
    "#####################\n",
    "\n",
    "# Here we define our model as a class\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=1,\n",
    "                    num_layers=2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
    "\n",
    "        # Define the output layer\n",
    "        self.linear = nn.Linear(self.hidden_dim, output_dim)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # This is what we'll initialise our hidden state as\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Forward pass through LSTM layer\n",
    "        # shape of lstm_out: [input_size, batch_size, hidden_dim]\n",
    "        # shape of self.hidden: (a, b), where a and b both \n",
    "        # have shape (num_layers, batch_size, hidden_dim).\n",
    "        lstm_out, self.hidden = self.lstm(input.view(len(input), self.batch_size, -1))\n",
    "        \n",
    "        # Only take the output from the final timetep\n",
    "        # Can pass on the entirety of lstm_out to the next layer if it is a seq2seq prediction\n",
    "        y_pred = self.linear(lstm_out[-1].view(self.batch_size, -1))\n",
    "        return y_pred.view(-1)\n",
    "\n",
    "model = LSTM(data_dim, hidden_layer_size, batch_size=64, output_dim=17, num_layers=1)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14147, 24, 113)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "view() takes at most 2 arguments (3 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-0eaed7d1c932>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py354/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-e8175a2e9937>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# shape of self.hidden: (a, b), where a and b both\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# have shape (num_layers, batch_size, hidden_dim).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Only take the output from the final timetep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: view() takes at most 2 arguments (3 given)"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "# Train model\n",
    "#####################\n",
    "from sklearn.metrics import *\n",
    "hist = np.zeros(num_epochs)\n",
    "hist_acc = np.zeros(num_epochs)\n",
    "hist_p = np.zeros(num_epochs)\n",
    "hist_r = np.zeros(num_epochs)\n",
    "hist_f = np.zeros(num_epochs)\n",
    "\n",
    "\n",
    "\n",
    "num_train = int(X_test.shape[0]*0.8)\n",
    "X_train_ = X_test[:num_train,:,:]\n",
    "y_train_ = y_test[:num_train]\n",
    "\n",
    "X_test_ = X_test[num_train:,:,:]\n",
    "y_test_ = y_test[num_train:]\n",
    "\n",
    "num_epoches = 30\n",
    "for t in range(num_epochs):\n",
    "    # Initialise hidden state\n",
    "    # Don't do this if you want your LSTM to be stateful\n",
    "    # model.hidden = model.init_hidden()\n",
    "    \n",
    "    # Forward pass\n",
    "    y_pred = model(X_train)\n",
    "\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    # Zero out gradient, else they will accumulate between epochs\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimiser.step()\n",
    "    \n",
    "    if t % 1 == 0:\n",
    "        print(\"Epoch \", t, \"CrossEntropyLoss: \", loss.item())\n",
    "        y_pred = model(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prfs = precision_recall_fscore_support(y_train, y_pred)\n",
    "        print(\"Epoch \", t, \"acc / prec / recall / f1 / supp : \", acc,\" \", prfs)\n",
    "        hist_acc[t] = acc\n",
    "        hist_p[t] = prfs[0]\n",
    "        hist_r[t] = prfs[1]\n",
    "        hist_f[t] = prfs[2]\n",
    "    hist[t] = loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Plot preds and performance\n",
    "#####################\n",
    "\n",
    "plt.plot(y_pred.detach().numpy(), label=\"Preds\")\n",
    "plt.plot(y_train.detach().numpy(), label=\"Data\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist, label=\"Training loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist_acc, label=\"testing acc\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist_p, label=\"testing prec\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist_r, label=\"testing recall\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist_f, label=\"testing f1\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py354)",
   "language": "python",
   "name": "py354"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
