{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,json\n",
    "import collections,math\n",
    "import time,datetime,pytz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy import interpolate, io\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import operator\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Emotion Recognition Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion-fbank data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fbank = 'data/audio-emotion/Emotions-fbanks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMOTION_BOREDOM-1_CL001-CD2.plp.txt\n",
      "EMOTION_NEUTRAL-TETE-1_GG002_CD1.plp.txt\n",
      "EMOTION_NEUTRAL-NOR-1_JG001-CD3.plp.txt\n",
      "EMOTION_NEUTRAL-CON-2_MK002-CD4.plp.txt\n",
      "EMOTION_HOTANGER-1_GG001-CD2.plp.txt\n",
      "EMOTION_DISGUST-1_CC001_CD1.plp.txt\n",
      "EMOTION_SADNESS-1_CL001-CD2.plp.txt\n",
      "EMOTION_HAPPY-1_MM001-CD5.plp.txt\n",
      "EMOTION_PANIC-1_CC001_CD1.plp.txt\n",
      "EMOTION_BOREDOM-1_CC001_CD1.plp.txt\n",
      "EMOTION_NEUTRAL-TETE-1_MM002-CD5.plp.txt\n",
      "EMOTION_BOREDOM-1_JG001-CD3.plp.txt\n",
      "EMOTION_HOTANGER-1_MK001-CD2.plp.txt\n",
      "EMOTION_PASSIVE-1_MM002-CD5.plp.txt\n",
      "EMOTION_DOMINANT-1_MF002-CD3.plp.txt\n",
      "EMOTION_NEUTRAL-TETE-2_CC002_CD1.plp.txt\n",
      "EMOTION_INTEREST-1_JG001-CD3.plp.txt\n",
      "EMOTION_NEUTRAL-CON-1_MK002-CD4.plp.txt\n",
      "EMOTION_SADNESS-1_JG001-CD3.plp.txt\n",
      "EMOTION_ELATION-1_MF001-CD4.plp.txt\n",
      "EMOTION_HOTANGER-1_MF001-CD4.plp.txt\n",
      "EMOTION_NEUTRAL-DIS-1_GG002_CD1.plp.txt\n",
      "EMOTION_DISGUST-1_MM001-CD5.plp.txt\n",
      "EMOTION_PANIC-1_GG001-CD2.plp.txt\n",
      "EMOTION_NEUTRAL-CON-1_CC002_CD1.plp.txt\n",
      "EMOTION_HOTANGER-1_JG001-CD3.plp.txt\n",
      "EMOTION_PASSIVE-1_MF002-CD3.plp.txt\n",
      "EMOTION_NEUTRAL-NOR-1_GG001-CD2.plp.txt\n",
      "EMOTION_PANIC-1_CL001-CD2.plp.txt\n",
      "EMOTION_BOREDOM-1_MK001-CD2.plp.txt\n",
      "EMOTION_NEUTRAL-DIS-1_MM002-CD5.plp.txt\n",
      "EMOTION_NEUTRAL-DIS-1_JG002-CD3.plp.txt\n",
      "EMOTION_DISGUST-1_JG001-CD3.plp.txt\n",
      "EMOTION_SADNESS-1_MF001-CD4.plp.txt\n",
      "EMOTION_SADNESS-1_CC001_CD1.plp.txt\n",
      "EMOTION_HAPPY-1_GG001-CD2.plp.txt\n",
      "EMOTION_NEUTRAL-DIS-1_MG000-CD4.plp.txt\n",
      "EMOTION_NEUTRAL-DIS-3_CC002_CD1.plp.txt\n",
      "EMOTION_HAPPY-1_CL001-CD2.plp.txt\n",
      "EMOTION_NEUTRAL-DIS-3_JG002-CD3.plp.txt\n",
      "EMOTION_BOREDOM-1_MF001-CD4.plp.txt\n",
      "EMOTION_NEUTRAL-CON-1_MF002-CD3.plp.txt\n",
      "EMOTION_INTEREST-1_MK001-CD2.plp.txt\n",
      "EMOTION_PASSIVE-1_MK002-CD4.plp.txt\n",
      "EMOTION_HAPPY-1_MK001-CD2.plp.txt\n",
      "EMOTION_ELATION-1_JG001-CD3.plp.txt\n",
      "EMOTION_HAPPY-1_CC001_CD1.plp.txt\n",
      "EMOTION_NEUTRAL-TETE-1_JG002-CD3.plp.txt\n",
      "EMOTION_NEUTRAL-NOR-1_MG000-CD4.plp.txt\n",
      "EMOTION_NEUTRAL-TETE-1_CL002_CD1.plp.txt\n",
      "EMOTION_DOMINANT-1_MK002-CD4.plp.txt\n",
      "EMOTION_DOMINANT-1_JG002-CD3.plp.txt\n",
      "EMOTION_PASSIVE-1_CL002_CD1.plp.txt\n",
      "EMOTION_NEUTRAL-TETE-2_JG002-CD3.plp.txt\n",
      "EMOTION_PANIC-1_MF001-CD4.plp.txt\n",
      "EMOTION_DISGUST-2_GG001-CD2.plp.txt\n",
      "EMOTION_ELATION-1_MK001-CD2.plp.txt\n",
      "EMOTION_PANIC-2_MM001-CD5.plp.txt\n",
      "EMOTION_PASSIVE-1_MG000-CD4.plp.txt\n",
      "EMOTION_NEUTRAL-NOR-1_MK001-CD2.plp.txt\n",
      "EMOTION_SADNESS-1_MM001-CD5.plp.txt\n",
      "EMOTION_HOTANGER-1_MM001-CD5.plp.txt\n",
      "EMOTION_SADNESS-1_MK001-CD2.plp.txt\n",
      "EMOTION_ELATION-1_GG001-CD2.plp.txt\n",
      "EMOTION_PASSIVE-1_GG002_CD1.plp.txt\n",
      "EMOTION_DISGUST-1_CL001-CD2.plp.txt\n",
      "EMOTION_INTEREST-1_GG001-CD2.plp.txt\n",
      "EMOTION_DOMINANT-1_MM002-CD5.plp.txt\n",
      "EMOTION_INTEREST-1_CC001_CD1.plp.txt\n",
      "EMOTION_NEUTRAL-DIS-1_CL002_CD1.plp.txt\n",
      "EMOTION_PASSIVE-1_CC002_CD1.plp.txt\n",
      "EMOTION_INTEREST-1_MF001-CD4.plp.txt\n",
      "EMOTION_ELATION-1_MM001-CD5.plp.txt\n",
      "EMOTION_NEUTRAL-NOR-1_CC001_CD1.plp.txt\n",
      "EMOTION_DOMINANT-1_MG000-CD4.plp.txt\n",
      "EMOTION_NEUTRAL-NOR-1_CL001-CD2.plp.txt\n",
      "EMOTION_BOREDOM-2_MF001-CD4.plp.txt\n",
      "EMOTION_PANIC-1_MM001-CD5.plp.txt\n",
      "EMOTION_ELATION-1_CL001-CD2.plp.txt\n",
      "EMOTION_HOTANGER-1_CL001-CD2.plp.txt\n",
      "EMOTION_PANIC-1_MK001-CD2.plp.txt\n",
      "EMOTION_PASSIVE-1_JG002-CD3.plp.txt\n",
      "EMOTION_NEUTRAL-DIS-1_MF002-CD3.plp.txt\n",
      "EMOTION_HOTANGER-1_CC001_CD1.plp.txt\n",
      "EMOTION_HAPPY-1_JG001-CD3.plp.txt\n",
      "EMOTION_HAPPY-2_MK001-CD2.plp.txt\n",
      "EMOTION_NEUTRAL-CON-1_CL002_CD1.plp.txt\n",
      "EMOTION_NEUTRAL-TETE-1_MG000-CD4.plp.txt\n",
      "EMOTION_BOREDOM-1_GG001-CD2.plp.txt\n",
      "EMOTION_BOREDOM-1_MM001-CD5.plp.txt\n",
      "EMOTION_NEUTRAL-CON-1_MM002-CD5.plp.txt\n",
      "EMOTION_NEUTRAL-NOR-1_MM001-CD5.plp.txt\n",
      "EMOTION_HAPPY-1_MF001-CD4.plp.txt\n",
      "EMOTION_NEUTRAL-NOR-1_JG002-CD3.plp.txt\n",
      "EMOTION_PANIC-1_JG001-CD3.plp.txt\n",
      "EMOTION_DISGUST-1_MK001-CD2.plp.txt\n",
      "EMOTION_DOMINANT-1_CL002_CD1.plp.txt\n",
      "EMOTION_NEUTRAL-CON-1_GG002_CD1.plp.txt\n",
      "EMOTION_INTEREST-1_MM001-CD5.plp.txt\n",
      "EMOTION_NEUTRAL-DIS-2_JG002-CD3.plp.txt\n",
      "EMOTION_DISGUST-1_MF001-CD4.plp.txt\n",
      "EMOTION_DOMINANT-1_CC002_CD1.plp.txt\n",
      "EMOTION_NEUTRAL-TETE-1_MF002-CD3.plp.txt\n",
      "EMOTION_ELATION-1_CC001_CD1.plp.txt\n",
      "EMOTION_INTEREST-1_CL001-CD2.plp.txt\n",
      "EMOTION_NEUTRAL-TETE-1_MK002-CD4.plp.txt\n",
      "EMOTION_NEUTRAL-NOR-1_MF001-CD4.plp.txt\n",
      "EMOTION_SADNESS-1_GG001-CD2.plp.txt\n",
      "EMOTION_DOMINANT-2_JG002-CD3.plp.txt\n",
      "EMOTION_DOMINANT-1_GG002_CD1.plp.txt\n",
      "EMOTION_DISGUST-1_GG001-CD2.plp.txt\n",
      "EMOTION_NEUTRAL-DIS-1_MK002-CD4.plp.txt\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(path_fbank):\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendJsonFromTxt(data, full_path):\n",
    "    with open(full_path, 'r') as f_read:\n",
    "        for line in f_read:\n",
    "            # line_json is list object / and line is str\n",
    "            line_json = json.loads(line)\n",
    "            data.append(line_json) # add [500x24] feature vector\n",
    "    \n",
    "    return None\n",
    "\n",
    "def splitByCV(X, y, rand):\n",
    "    X, y = shuffle(X, y, random_state=rand)\n",
    "\n",
    "    train_ratio = 0.8\n",
    "    valid_ratio = 0.1\n",
    "    cut_train = int(X.shape[0] * train_ratio)\n",
    "    cut_valid = int(X.shape[0] * (train_ratio+valid_ratio))\n",
    "    \n",
    "    X_train = X[:cut_train]\n",
    "    y_train = y[:cut_train]\n",
    "    \n",
    "    X_valid = X[cut_train:cut_valid]\n",
    "    y_valid = y[cut_train:cut_valid]\n",
    "    \n",
    "    X_test = X[cut_valid:]\n",
    "    y_test = y[cut_valid:]\n",
    "    \n",
    "    # change the shape from 3D to 2D [n_samplesx500x24] => [n_samplesx(500*24)]\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0],-1) )\n",
    "    X_valid = np.reshape(X_valid, (X_valid.shape[0],-1) )\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0],-1) )\n",
    "    \n",
    "    X_train = StandardScaler().fit_transform(X_train)\n",
    "    X_valid = StandardScaler().fit_transform(X_valid)\n",
    "    X_test = StandardScaler().fit_transform(X_test)\n",
    "    \n",
    "    # change the shape from 2D to 3D [n_samplesx(500*24)] => [n_samplesx500x24]\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0],500,-1) )\n",
    "    X_valid = np.reshape(X_valid, (X_valid.shape[0],500,-1) )\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0],500,-1) )\n",
    "    \n",
    "    # printout resulting y label count\n",
    "    print('y_train: ', Counter(y_train))\n",
    "    print('y_valid: ', Counter(y_valid))\n",
    "    print('y_test: ', Counter(y_test))\n",
    "    \n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = []\n",
    "data1 = []\n",
    "data2 = []\n",
    "data3 = []\n",
    "data4 = []\n",
    "data5 = []\n",
    "data6 = []\n",
    "data7 = []\n",
    "data8 = []\n",
    "data9 = []\n",
    "data10 = []\n",
    "data11 = []\n",
    "data12 = []\n",
    "data13 = []\n",
    "\n",
    "for filename in os.listdir(path_fbank):\n",
    "    if filename[:11] == 'EMOTION_NEU':\n",
    "        if filename[:19] == 'EMOTION_NEUTRAL-NOR':\n",
    "            appendJsonFromTxt(data0, path_fbank + filename)\n",
    "        elif filename[:19] == 'EMOTION_NEUTRAL-CON':\n",
    "            appendJsonFromTxt(data1, path_fbank + filename)\n",
    "        elif filename[:19] == 'EMOTION_NEUTRAL-DIS':\n",
    "            appendJsonFromTxt(data2, path_fbank + filename)\n",
    "        elif filename[:19] == 'EMOTION_NEUTRAL-TET':\n",
    "            appendJsonFromTxt(data3, path_fbank + filename)\n",
    "    elif filename[:11] == 'EMOTION_BOR':\n",
    "        appendJsonFromTxt(data4, path_fbank + filename)\n",
    "    elif filename[:11] == 'EMOTION_PAS':\n",
    "        appendJsonFromTxt(data5, path_fbank + filename)\n",
    "    elif filename[:11] == 'EMOTION_DIS':\n",
    "        appendJsonFromTxt(data6, path_fbank + filename)\n",
    "    elif filename[:11] == 'EMOTION_DOM':\n",
    "        appendJsonFromTxt(data7, path_fbank + filename)\n",
    "    elif filename[:11] == 'EMOTION_HOT':\n",
    "        appendJsonFromTxt(data8, path_fbank + filename)\n",
    "    elif filename[:11] == 'EMOTION_ELA':\n",
    "        appendJsonFromTxt(data9, path_fbank + filename)\n",
    "    elif filename[:11] == 'EMOTION_INT':\n",
    "        appendJsonFromTxt(data10, path_fbank + filename)\n",
    "    elif filename[:11] == 'EMOTION_HAP':\n",
    "        appendJsonFromTxt(data11, path_fbank + filename)\n",
    "    elif filename[:11] == 'EMOTION_PAN':\n",
    "        appendJsonFromTxt(data12, path_fbank + filename)\n",
    "    elif filename[:11] == 'EMOTION_SAD':\n",
    "        appendJsonFromTxt(data13, path_fbank + filename)\n",
    "    else:\n",
    "        print('this filename was not specified in if statement: ', filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n",
      "198\n",
      "270\n",
      "280\n",
      "127\n",
      "288\n",
      "134\n",
      "249\n",
      "83\n",
      "81\n",
      "115\n",
      "96\n",
      "88\n",
      "123\n"
     ]
    }
   ],
   "source": [
    "print(len(data0))\n",
    "print(len(data1))\n",
    "print(len(data2))\n",
    "print(len(data3))\n",
    "print(len(data4))\n",
    "print(len(data5))\n",
    "print(len(data6))\n",
    "print(len(data7))\n",
    "print(len(data8))\n",
    "print(len(data9))\n",
    "print(len(data10))\n",
    "print(len(data11))\n",
    "print(len(data12))\n",
    "print(len(data13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data0+data1+data2+data3+data4+data5+data6+data7+data8+data9+data10+data11+data12+data13\n",
    "y = [0]*len(data0)+[1]*len(data1)+[2]*len(data2)+[3]*len(data3)+[4]*len(data4)+[5]*len(data5)+\\\n",
    "    [6]*len(data6)+[7]*len(data7)+[8]*len(data8)+[9]*len(data9)+[10]*len(data10)+\\\n",
    "    [11]*len(data11)+[12]*len(data12)+[13]*len(data13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2235 2235 Counter({5: 288, 3: 280, 2: 270, 7: 249, 1: 198, 6: 134, 4: 127, 13: 123, 10: 115, 0: 103, 11: 96, 12: 88, 8: 83, 9: 81})\n"
     ]
    }
   ],
   "source": [
    "print(len(X), len(y), Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train:  Counter({5: 235, 2: 225, 3: 225, 7: 199, 1: 158, 6: 103, 4: 95, 13: 94, 10: 91, 0: 88, 11: 76, 8: 67, 12: 66, 9: 66})\n",
      "y_valid:  Counter({3: 29, 5: 28, 2: 25, 7: 25, 4: 18, 6: 17, 1: 16, 13: 13, 12: 12, 11: 9, 9: 9, 8: 8, 10: 8, 0: 6})\n",
      "y_test:  Counter({3: 26, 5: 25, 7: 25, 1: 24, 2: 20, 10: 16, 13: 16, 4: 14, 6: 14, 11: 11, 12: 10, 0: 9, 8: 8, 9: 6})\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = splitByCV(np.array(X), np.array(y), rand=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1788, 500, 24)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223, 500, 24)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 500, 24)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret_X.shape:  (89400, 24)    ret_y.shape:  (89400,)\n",
      "ret_X.shape[0]/n_samples:  50.0\n",
      "ret_X.shape:  (44700, 24)    ret_y.shape:  (44700,)\n",
      "ret_X.shape[0]/n_samples:  25.0\n",
      "ret_X.shape:  (35760, 24)    ret_y.shape:  (35760,)\n",
      "ret_X.shape[0]/n_samples:  20.0\n",
      "ret_X.shape:  (17880, 24)    ret_y.shape:  (17880,)\n",
      "ret_X.shape[0]/n_samples:  10.0\n",
      "ret_X.shape:  (11150, 24)    ret_y.shape:  (11150,)\n",
      "ret_X.shape[0]/n_samples:  50.0\n",
      "ret_X.shape:  (5575, 24)    ret_y.shape:  (5575,)\n",
      "ret_X.shape[0]/n_samples:  25.0\n",
      "ret_X.shape:  (4460, 24)    ret_y.shape:  (4460,)\n",
      "ret_X.shape[0]/n_samples:  20.0\n",
      "ret_X.shape:  (2230, 24)    ret_y.shape:  (2230,)\n",
      "ret_X.shape[0]/n_samples:  10.0\n",
      "ret_X.shape:  (11200, 24)    ret_y.shape:  (11200,)\n",
      "ret_X.shape[0]/n_samples:  50.0\n",
      "ret_X.shape:  (5600, 24)    ret_y.shape:  (5600,)\n",
      "ret_X.shape[0]/n_samples:  25.0\n",
      "ret_X.shape:  (4480, 24)    ret_y.shape:  (4480,)\n",
      "ret_X.shape[0]/n_samples:  20.0\n",
      "ret_X.shape:  (2240, 24)    ret_y.shape:  (2240,)\n",
      "ret_X.shape[0]/n_samples:  10.0\n"
     ]
    }
   ],
   "source": [
    "X_train_frames10, y_train_frames10 = aggregateDataByFrames(X_train, y_train, 10)\n",
    "X_train_frames20, y_train_frames20 = aggregateDataByFrames(X_train, y_train, 20)\n",
    "X_train_frames25, y_train_frames25 = aggregateDataByFrames(X_train, y_train, 25)\n",
    "X_train_frames50, y_train_frames50 = aggregateDataByFrames(X_train, y_train, 50)\n",
    "\n",
    "X_valid_frames10, y_valid_frames10 = aggregateDataByFrames(X_valid, y_valid, 10)\n",
    "X_valid_frames20, y_valid_frames20 = aggregateDataByFrames(X_valid, y_valid, 20)\n",
    "X_valid_frames25, y_valid_frames25 = aggregateDataByFrames(X_valid, y_valid, 25)\n",
    "X_valid_frames50, y_valid_frames50 = aggregateDataByFrames(X_valid, y_valid, 50)\n",
    "\n",
    "X_test_frames10, y_test_frames10 = aggregateDataByFrames(X_test, y_test, 10)\n",
    "X_test_frames20, y_test_frames20 = aggregateDataByFrames(X_test, y_test, 20)\n",
    "X_test_frames25, y_test_frames25 = aggregateDataByFrames(X_test, y_test, 25)\n",
    "X_test_frames50, y_test_frames50 = aggregateDataByFrames(X_test, y_test, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.savemat(path+'emotion-fbanks-frames10.mat', {'X_train': X_train_frames10, 'y_train': y_train_frames10,\n",
    "       'X_valid': X_valid_frames10, 'y_valid': y_valid_frames10,\n",
    "       'X_test': X_test_frames10, 'y_test': y_test_frames10} )\n",
    "\n",
    "io.savemat(path+'emotion-fbanks-frames20.mat', {'X_train': X_train_frames20, 'y_train': y_train_frames20,\n",
    "       'X_valid': X_valid_frames20, 'y_valid': y_valid_frames20,\n",
    "       'X_test': X_test_frames20, 'y_test': y_test_frames20} )\n",
    "\n",
    "io.savemat(path+'emotion-fbanks-frames25.mat', {'X_train': X_train_frames25, 'y_train': y_train_frames25,\n",
    "       'X_valid': X_valid_frames25, 'y_valid': y_valid_frames25,\n",
    "       'X_test': X_test_frames25, 'y_test': y_test_frames25} )\n",
    "\n",
    "io.savemat(path+'emotion-fbanks-frames50.mat', {'X_train': X_train_frames50, 'y_train': y_train_frames50,\n",
    "       'X_valid': X_valid_frames50, 'y_valid': y_valid_frames50,\n",
    "       'X_test': X_test_frames50, 'y_test': y_test_frames50} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "data50 = io.loadmat(path+'emotion-fbanks-frames50.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion-all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/audio-emotion/Splits/Emotions-all/'\n",
    "path_summary = 'data/audio-emotion/Splits/Emotions-summary/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "X_train = []\n",
    "with open(path_summary+'train.txt', 'r') as f_read:\n",
    "    for line in f_read:\n",
    "        # line_json is list object / and line is str\n",
    "        line_json = json.loads(line)\n",
    "        y_train.append(line_json[0]) # add 1 label\n",
    "        X_train.append(line_json[1]) # add 12K feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1014, 2: 234, 1: 372, 4: 98, 3: 70})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 140, 1: 51, 2: 33, 3: 10, 4: 14})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 112, 1: 43, 2: 25, 3: 8, 4: 11})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = []\n",
    "X_valid = []\n",
    "with open(path+'validation.txt', 'r') as f_read:\n",
    "    for line in f_read:\n",
    "        # line_json is list object / and line is str\n",
    "        line_json = json.loads(line)\n",
    "        y_valid.append(line_json[0]) # add 1 label\n",
    "        X_valid.append(line_json[1]) # add 12K feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "X_test = []\n",
    "with open(path+'test.txt', 'r') as f_read:\n",
    "    for line in f_read:\n",
    "        # line_json is list object / and line is str\n",
    "        line_json = json.loads(line)\n",
    "        y_test.append(line_json[0]) # add 1 label\n",
    "        X_test.append(line_json[1]) # add 12K feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "y_valid = np.array(y_valid)\n",
    "X_valid = np.array(X_valid)\n",
    "\n",
    "y_test = np.array(y_test)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1788,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1788, 12000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape so the data format change [n_samples x 12,000] => [n_samples x 500 frames x 24 log filter banks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 500, 24)\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], 500, 24)\n",
    "X_test = X_test.reshape(X_test.shape[0], 500, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1788, 500, 24)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aggregate those data according to certain number of frames, e.g., 10, 20, 25, 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregateDataByFrames(X, y, frames_th):\n",
    "\t# X = [n_samples x 500 x 24], y = [n_samples, 1], frames_th = frames threshold\n",
    "\tframe_cnt = 0\n",
    "\tret_X = []\n",
    "\tret_y = []\n",
    "\ttemp_X = []\n",
    "\tfor i in range(X.shape[0]):\n",
    "\t\tfor j in range(X.shape[1]):\n",
    "\t\t\tframe_cnt += 1\n",
    "\t\t\ttemp_X.append(X[i,j,:])\n",
    "\t\t\tif frame_cnt >= frames_th:\n",
    "\t\t\t\tret_X.append(np.mean(temp_X, axis=0))\n",
    "\t\t\t\tret_y.append(y[i])\n",
    "\t\t\t\tframe_cnt = 0\n",
    "\t\t\t\ttemp_X = []\n",
    "\tret_X = np.array(ret_X)\n",
    "\tret_y = np.array(ret_y)\n",
    "\tprint('ret_X.shape: ', ret_X.shape, '   ret_y.shape: ', ret_y.shape)\n",
    "\tprint('ret_X.shape[0]/n_samples: ', ret_X.shape[0]/X.shape[0])\n",
    "\treturn ret_X, ret_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret_X.shape:  (89400, 24)    ret_y.shape:  (89400,)\n",
      "ret_X.shape[0]/n_samples:  50.0\n",
      "ret_X.shape:  (44700, 24)    ret_y.shape:  (44700,)\n",
      "ret_X.shape[0]/n_samples:  25.0\n",
      "ret_X.shape:  (35760, 24)    ret_y.shape:  (35760,)\n",
      "ret_X.shape[0]/n_samples:  20.0\n",
      "ret_X.shape:  (17880, 24)    ret_y.shape:  (17880,)\n",
      "ret_X.shape[0]/n_samples:  10.0\n",
      "ret_X.shape:  (12400, 24)    ret_y.shape:  (12400,)\n",
      "ret_X.shape[0]/n_samples:  50.0\n",
      "ret_X.shape:  (6200, 24)    ret_y.shape:  (6200,)\n",
      "ret_X.shape[0]/n_samples:  25.0\n",
      "ret_X.shape:  (4960, 24)    ret_y.shape:  (4960,)\n",
      "ret_X.shape[0]/n_samples:  20.0\n",
      "ret_X.shape:  (2480, 24)    ret_y.shape:  (2480,)\n",
      "ret_X.shape[0]/n_samples:  10.0\n",
      "ret_X.shape:  (9950, 24)    ret_y.shape:  (9950,)\n",
      "ret_X.shape[0]/n_samples:  50.0\n",
      "ret_X.shape:  (4975, 24)    ret_y.shape:  (4975,)\n",
      "ret_X.shape[0]/n_samples:  25.0\n",
      "ret_X.shape:  (3980, 24)    ret_y.shape:  (3980,)\n",
      "ret_X.shape[0]/n_samples:  20.0\n",
      "ret_X.shape:  (1990, 24)    ret_y.shape:  (1990,)\n",
      "ret_X.shape[0]/n_samples:  10.0\n"
     ]
    }
   ],
   "source": [
    "X_train_frames10, y_train_frames10 = aggregateDataByFrames(X_train, y_train, 10)\n",
    "X_train_frames20, y_train_frames20 = aggregateDataByFrames(X_train, y_train, 20)\n",
    "X_train_frames25, y_train_frames25 = aggregateDataByFrames(X_train, y_train, 25)\n",
    "X_train_frames50, y_train_frames50 = aggregateDataByFrames(X_train, y_train, 50)\n",
    "\n",
    "X_valid_frames10, y_valid_frames10 = aggregateDataByFrames(X_valid, y_valid, 10)\n",
    "X_valid_frames20, y_valid_frames20 = aggregateDataByFrames(X_valid, y_valid, 20)\n",
    "X_valid_frames25, y_valid_frames25 = aggregateDataByFrames(X_valid, y_valid, 25)\n",
    "X_valid_frames50, y_valid_frames50 = aggregateDataByFrames(X_valid, y_valid, 50)\n",
    "\n",
    "X_test_frames10, y_test_frames10 = aggregateDataByFrames(X_test, y_test, 10)\n",
    "X_test_frames20, y_test_frames20 = aggregateDataByFrames(X_test, y_test, 20)\n",
    "X_test_frames25, y_test_frames25 = aggregateDataByFrames(X_test, y_test, 25)\n",
    "X_test_frames50, y_test_frames50 = aggregateDataByFrames(X_test, y_test, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the resulting files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.savemat(path+'emotion-all-frames10.mat', {'X_train': X_train_frames10, 'y_train': y_train_frames10,\n",
    "       'X_valid': X_valid_frames10, 'y_valid': y_valid_frames10,\n",
    "       'X_test': X_test_frames10, 'y_test': y_test_frames10} )\n",
    "\n",
    "io.savemat(path+'emotion-all-frames20.mat', {'X_train': X_train_frames20, 'y_train': y_train_frames20,\n",
    "       'X_valid': X_valid_frames20, 'y_valid': y_valid_frames20,\n",
    "       'X_test': X_test_frames20, 'y_test': y_test_frames20} )\n",
    "\n",
    "io.savemat(path+'emotion-all-frames25.mat', {'X_train': X_train_frames25, 'y_train': y_train_frames25,\n",
    "       'X_valid': X_valid_frames25, 'y_valid': y_valid_frames25,\n",
    "       'X_test': X_test_frames25, 'y_test': y_test_frames25} )\n",
    "\n",
    "io.savemat(path+'emotion-all-frames50.mat', {'X_train': X_train_frames50, 'y_train': y_train_frames50,\n",
    "       'X_valid': X_valid_frames50, 'y_valid': y_valid_frames50,\n",
    "       'X_test': X_test_frames50, 'y_test': y_test_frames50} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data50 = io.loadmat(path+'emotion-all-frames50.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 372, 0: 1014, 4: 98, 3: 70, 2: 234})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 18600, 0: 50700, 4: 4900, 3: 3500, 2: 11700})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train_frames10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17880,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_frames50.transpose().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 17880)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data50['y_train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify configurations of available data-sets.\n",
    "DATASET_CONFIGS = {\n",
    "    'mnist': {'features': 32, 'seq': 1, 'classes': 10},\n",
    "    'mnist28': {'features': 28, 'seq': 1, 'classes': 10},\n",
    "    'opportunity': {'features': 113, 'seq': 24, 'classes': 17}, # w/o null class\n",
    "    'hhar-raw': {'features': 6, 'seq': 50, 'classes': 6}, # no null class\n",
    "    'hhar-noaug': {'features': 120, 'seq': 20, 'classes': 6}, # no null class\n",
    "    'hhar-aug': {'features': 120, 'seq': 20, 'classes': 6}, # no null class\n",
    "    'opp_thomas': {'features': 77, 'seq': 30, 'classes': 18}, # w/ null class\n",
    "    'pamap2': {'features': 52, 'seq': 33, 'classes': 12}, # w/o null class\n",
    "    'skoda': {'features': 60, 'seq': 33, 'classes': 10}, # w/ null class\n",
    "    'usc-had': {'features': 6, 'seq': 33, 'classes': 12},\n",
    "    'ninapro-db2-c10': {'features': 12, 'seq': 40, 'classes': 10}, # w/o null class\n",
    "    'ninapro-db3-c10': {'features': 12, 'seq': 40, 'classes': 10}, # w/o null class\n",
    "    'emotion-all-frames10': {'features': 24, 'seq': 50, 'classes': 14},\n",
    "    'emotion-all-frames20': {'features': 24, 'seq': 25, 'classes': 14},\n",
    "    'emotion-all-frames25': {'features': 24, 'seq': 20, 'classes': 14},\n",
    "    'emotion-all-frames50': {'features': 24, 'seq': 10, 'classes': 14}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reference codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for i in range(0,len(a)):\n",
    "    if a[i] != a_sm[i]:\n",
    "        print(a[i], a_sm[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printStats(x):\n",
    "    print('Min: ', x.min())\n",
    "    print('Q25: ', np.percentile(x, q=25))\n",
    "    print('Mean: ', np.mean(x))\n",
    "    print('Q50: ', np.percentile(x, q=50))\n",
    "    print('Q75: ', np.percentile(x, q=75))\n",
    "    print('Max: ', x.max())\n",
    "    print('SD: ', np.std(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py354)",
   "language": "python",
   "name": "py354"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
